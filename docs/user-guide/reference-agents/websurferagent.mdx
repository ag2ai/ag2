---
title: WebSurferAgent
---

If you need an agent that can browse, extract, or interact with the web, [`WebSurferAgent`](/docs/api-reference/autogen/agents/experimental/WebSurferAgent) is a good choice. The agent actions the request(s) given to it by determining what to do on the web and browsing and crawling it, returning the details of what it finds.

The [`WebSurferAgent`](/docs/api-reference/autogen/agents/experimental/WebSurferAgent) has two in-built web tools to choose from:
1. [browser-use](https://github.com/browser-use/browser-use) - uses an actual browser instance (visible or headless), interacting with the web pages in realtime
2. [Crawl4AI](https://github.com/unclecode/crawl4ai) - crawls without a visual browser instance

<Tip>
If you want to add browsing capabilities to your existing agents, see [this notebook for browser-use](/docs/use-cases/notebooks/notebooks/tools_browser_use) and [this notebook for Crawl4AI](/docs/use-cases/notebooks/notebooks/tools_crawl4ai).
</Tip>

<Warning>
[`Browser Use`](https://github.com/browser-use/browser-use) requires **Python 3.11 or higher**.
</Warning>

To get started with [`WebSurferAgent`](/docs/api-reference/autogen/agents/experimental/WebSurferAgent), install AG2 with the `browser-use` and/or `crawl4ai` extras.
```bash
pip install ag2[browser-use]
```
and/or
```bash
pip install ag2[crawl4ai]
```

<Tip>
If you have been using `autogen` or `pyautogen`, all you need to do is upgrade it using:
```bash
pip install -U autogen[browser-use]
```
or
```bash
pip install -U pyautogen[browser-use]
```
as `pyautogen`, `autogen`, and `ag2` are aliases for the same PyPI package.
</Tip>

And then setup Playwright:
```bash
# Installs Playwright and browsers for all OS
playwright install
# Additional command, mandatory for Linux only
playwright install-deps
```

Now, you can create an agent, nominating the web tool:
<Tip>
[`Browser Use`](https://github.com/browser-use/browser-use) supports the following models: [Supported Models](https://docs.browser-use.com/customize/supported-models#supported-models)

We had great experience with `OpenAI`, `Anthropic`, and `Gemini`. However, `DeepSeek` and `Ollama` haven't performed as well.
</Tip>
<Tip>
[`Crawl4AI`](https://github.com/unclecode/crawl4ai) is built on top of [LiteLLM](https://github.com/BerriAI/litellm) and supports the same models as LiteLLM.

We had great experience with `OpenAI`, `Anthropic`, `Gemini` and `Ollama`. However, as of this writing, `DeepSeek` is encountering some issues.
</Tip>

```python
from autogen.agents.experimental import WebSurferAgent

# Put your key in the OPENAI_API_KEY environment variable
llm_config = {"api_type": "openai", "model": "gpt-4o-mini"}

# Create our agent
websurfer = WebSurferAgent(
    name="WebSurfer",
    llm_config=llm_config,
    web_tool="browser_use",
)
# or
websurfer = WebSurferAgent(
    name="WebSurfer",
    llm_config=llm_config,
    web_tool="crawl4ai",
)
```

<Tip>
Crawl4AI doesn't always require an LLM configuration, see [this notebook](/docs/use-cases/notebooks/notebooks/tools_crawl4ai) for examples with and without one.
</Tip>

## Setting Chat Consumption Limits

To prevent excessive token usage and control costs, you can set limits on chat consumption using chat context dependency injection. Here's how to do it:

```python
from autogen.tools import ChatContext
from autogen.agents.experimental import WebSurferAgent

# Configure LLM with token limits
llm_config = {
    "api_type": "openai",
    "model": "gpt-4o-mini",
    "max_tokens": 2000,  # Maximum tokens per response
}

# Create the WebSurferAgent with chat context limits
websurfer = WebSurferAgent(
    name="WebSurfer",
    llm_config=llm_config,
    web_tool="browser_use",
    max_consecutive_auto_reply=3,  # Limit consecutive auto-replies
)

# Create a ChatContext to track and limit messages
chat_context = ChatContext(websurfer)
chat_context.max_messages = 10  # Limit total messages in conversation

# Use the agent with controlled chat consumption
response = websurfer.run(
    "Find the latest news about AG2",
    context=chat_context,
    tools=websurfer.tools
)
```

In this example:
- `max_tokens` in `llm_config` limits tokens per response
- `max_consecutive_auto_reply` prevents infinite conversation loops
- `ChatContext` with `max_messages` limits the total conversation length

<Note>
You can monitor token usage through the ChatContext's `chat_messages` attribute, which maintains a history of all messages and their token counts.
</Note>

Let's browse the web for news on AG2.

import Example from "/snippets/python-examples/websurferagent.mdx";

<Example/>

Let's break it down:

1. Import [`WebSurferAgent`](/docs/api-reference/autogen/agents/experimental/WebSurferAgent) and create an LLM configuration for the browser-use tool to use.

2. We create a configuration dictionary turning off the headless mode (so we can see what's happening) and saving an animated GIF of the process (shown below).

3. Create the agent, nominating the web tool and passing in the LLM and tool configurations.

4. Run the agent, ensuring we pass the agent's tools through to the `run` method so it can add them to the internal executor agent to execute.

![WebSurferAgent in action](./assets/websurferagent_animated.gif)

<div className="edit-url-container">
    <a className="edit-url" href="https://github.com/ag2ai/ag2/edit/main/website/docs/user-guide/reference-agents/websurferagent.mdx" target='_blank'><Icon icon="pen" iconType="solid" size="13px"/> Edit this page</a>
</div>