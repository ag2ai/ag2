---
sidebarTitle: base_client
title: agentchat.realtime_agent.clients.oai.base_client
---

## OpenAIRealtimeClient

```python
@register_realtime_client()
class OpenAIRealtimeClient()
```

(Experimental) Client for OpenAI Realtime API.

### \_\_init\_\_

```python
def __init__(*,
             llm_config: dict[str, Any],
             logger: Optional[Logger] = None) -> None
```

(Experimental) Client for OpenAI Realtime API.

**Arguments**:

- `llm_config` _dict[str, Any]_ - The config for the client.

### logger

```python
@property
def logger() -> Logger
```

Get the logger for the OpenAI Realtime API.

### connection

```python
@property
def connection() -> AsyncRealtimeConnection
```

Get the OpenAI WebSocket connection.

### send\_function\_result

```python
async def send_function_result(call_id: str, result: str) -> None
```

Send the result of a function call to the OpenAI Realtime API.

**Arguments**:

- `call_id` _str_ - The ID of the function call.
- `result` _str_ - The result of the function call.

### send\_text

```python
async def send_text(*, role: Role, text: str) -> None
```

Send a text message to the OpenAI Realtime API.

**Arguments**:

- `role` _str_ - The role of the message.
- `text` _str_ - The text of the message.

### send\_audio

```python
async def send_audio(audio: str) -> None
```

Send audio to the OpenAI Realtime API.

**Arguments**:

- `audio` _str_ - The audio to send.

### truncate\_audio

```python
async def truncate_audio(audio_end_ms: int, content_index: int,
                         item_id: str) -> None
```

Truncate audio in the OpenAI Realtime API.

**Arguments**:

- `audio_end_ms` _int_ - The end of the audio to truncate.
- `content_index` _int_ - The index of the content to truncate.
- `item_id` _str_ - The ID of the item to truncate.

### session\_update

```python
async def session_update(session_options: dict[str, Any]) -> None
```

Send a session update to the OpenAI Realtime API.

**Arguments**:

- `session_options` _dict[str, Any]_ - The session options to update.

### connect

```python
@asynccontextmanager
async def connect() -> AsyncGenerator[None, None]
```

Connect to the OpenAI Realtime API.

### read\_events

```python
async def read_events() -> AsyncGenerator[RealtimeEvent, None]
```

Read messages from the OpenAI Realtime API.

### get\_factory

```python
@classmethod
def get_factory(
        cls, llm_config: dict[str, Any], logger: Logger,
        **kwargs: Any) -> Optional[Callable[[], "RealtimeClientProtocol"]]
```

Create a Realtime API client.

**Arguments**:

- `model` _str_ - The model to create the client for.
- `voice` _str_ - The voice to use.
- `system_message` _str_ - The system message to use.
- `kwargs` _Any_ - Additional arguments.
  

**Returns**:

- `RealtimeClientProtocol` - The Realtime API client is returned if the model matches the pattern

