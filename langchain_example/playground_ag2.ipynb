{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from mcp.types import (\n",
    "    CallToolResult,\n",
    "    EmbeddedResource,\n",
    "    ImageContent,\n",
    "    TextContent,\n",
    ")\n",
    "from mcp.types import (\n",
    "    Tool as MCPTool,\n",
    ")\n",
    "\n",
    "from autogen.agentchat import AssistantAgent\n",
    "from autogen.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit modified langchain_mcp_adapters\n",
    "# https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/langchain_mcp_adapters/tools.py\n",
    "NonTextContent = ImageContent | EmbeddedResource\n",
    "\n",
    "\n",
    "def _convert_call_tool_result(\n",
    "    call_tool_result: CallToolResult,\n",
    ") -> tuple[str | list[str], list[NonTextContent] | None]:\n",
    "    text_contents: list[TextContent] = []\n",
    "    non_text_contents = []\n",
    "    for content in call_tool_result.content:\n",
    "        if isinstance(content, TextContent):\n",
    "            text_contents.append(content)\n",
    "        else:\n",
    "            non_text_contents.append(content)\n",
    "\n",
    "    tool_content: str | list[str] = [content.text for content in text_contents]\n",
    "    if len(text_contents) == 1:\n",
    "        tool_content = tool_content[0]\n",
    "\n",
    "    if call_tool_result.isError:\n",
    "        # raise ToolException(tool_content)\n",
    "        raise ValueError(f\"Tool call failed: {tool_content}\")\n",
    "\n",
    "    return tool_content, non_text_contents or None\n",
    "\n",
    "\n",
    "def convert_mcp_tool_to_ag2_tool(\n",
    "    session: ClientSession,\n",
    "    tool: MCPTool,\n",
    ") -> Tool:\n",
    "    \"\"\"Convert an MCP tool to a LangChain tool.\n",
    "\n",
    "    NOTE: this tool can be executed only in a context of an active MCP client session.\n",
    "\n",
    "    Args:\n",
    "        session: MCP client session\n",
    "        tool: MCP tool to convert\n",
    "\n",
    "    Returns:\n",
    "        a LangChain tool\n",
    "    \"\"\"\n",
    "\n",
    "    async def call_tool(\n",
    "        **arguments: dict[str, Any],\n",
    "    ) -> tuple[str | list[str], list[NonTextContent] | None]:\n",
    "        print(f\"Arguments: {arguments}\")\n",
    "\n",
    "        call_tool_result = await session.call_tool(tool.name, arguments)\n",
    "        return _convert_call_tool_result(call_tool_result)\n",
    "\n",
    "    # return StructuredTool(\n",
    "    #     name=tool.name,\n",
    "    #     description=tool.description or \"\",\n",
    "    #     args_schema=tool.inputSchema,\n",
    "    #     coroutine=call_tool,\n",
    "    #     response_format=\"content_and_artifact\",\n",
    "    # )\n",
    "    return Tool(\n",
    "        name=tool.name,\n",
    "        description=tool.description or \"\",\n",
    "        func_or_tool=call_tool,\n",
    "    )\n",
    "\n",
    "\n",
    "async def load_mcp_tools(session: ClientSession) -> list[Tool]:\n",
    "    \"\"\"Load all available MCP tools and convert them to LangChain tools.\"\"\"\n",
    "    tools = await session.list_tools()\n",
    "    return [convert_mcp_tool_to_ag2_tool(session, tool) for tool in tools.tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len tools: 2\n",
      "Langchain tools 0: add\n",
      "Langchain tools 1: multiply\n",
      "Arguments: {'a': 2, 'b': 5}\n",
      "Result from Langchain tool 0: ('7', None)\n",
      "[{'type': 'function', 'function': {'description': 'Add two numbers', 'name': 'add', 'parameters': {'type': 'object', 'properties': {'arguments': {'type': 'object', 'description': 'arguments'}}, 'required': ['arguments']}}}, {'type': 'function', 'function': {'description': 'Multiply two numbers', 'name': 'multiply', 'parameters': {'type': 'object', 'properties': {'arguments': {'type': 'object', 'description': 'arguments'}}, 'required': ['arguments']}}}]\n"
     ]
    }
   ],
   "source": [
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your math_server.py file\n",
    "    args=[\"math_server.py\"],\n",
    ")\n",
    "\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(f\"Len tools: {len(tools)}\")\n",
    "        print(f\"Langchain tools 0: {tools[0].name}\")\n",
    "        print(f\"Langchain tools 1: {tools[1].name}\")\n",
    "\n",
    "        f_result = await tools[0].func(a=2, b=5)\n",
    "        print(f\"Result from Langchain tool 0: {f_result}\")\n",
    "\n",
    "        agent = AssistantAgent(name=\"assistant\", llm_config={\"model\": \"gpt-4o-mini\", \"api_type\": \"openai\"})\n",
    "        for tool in tools:\n",
    "            tool.register_for_llm(agent)\n",
    "\n",
    "        print(agent.llm_config[\"tools\"])\n",
    "        # agent.run(\n",
    "        #     message=\"Add 123223 and 456789\",\n",
    "        #     tools=tools,\n",
    "        #     max_turns=2,\n",
    "        #     user_input=False,\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
