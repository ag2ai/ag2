# Copyright (c) 2023 - 2025, AG2ai, Inc., AG2ai open-source projects maintainers and core contributors
#
# SPDX-License-Identifier: Apache-2.0

"""
Enhanced Test Script for Parallel Agent System with Detailed Interface Documentation

This script demonstrates and documents the complete interface of the parallel agent system
with three main goals:
1. Core-level distribution of agents across CPU cores
2. Hybrid communication (concurrent.futures for same-core, multiprocessing for cross-core)
3. Real-time context switching between LLMs

Each test section includes detailed explanations of:
- Class purposes and responsibilities
- Method signatures and parameters
- Expected behaviors and outputs
- Interface patterns and usage examples
"""

import os
import sys

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from autogen.agentchat.parallel_agents.communication.message_router import MessageRouter
from autogen.agentchat.parallel_agents.communication.thread_messenger import ThreadMessenger
from autogen.agentchat.parallel_agents.context.context_manager import ContextManager
from autogen.agentchat.parallel_agents.context.llm_pool import LLMPool
from autogen.agentchat.parallel_agents.core.process_manager import ProcessManager


def print_section_header(title: str, description: str = ""):
    """Helper function to print formatted section headers"""
    print("\n" + "=" * 80)
    print(f"ðŸ” {title}")
    if description:
        print(f"ðŸ“ {description}")
    print("=" * 80)


def print_class_docs(class_name: str, purpose: str, methods: list):
    """Helper function to print class documentation"""
    print(f"\nðŸ“š CLASS: {class_name}")
    print(f" PURPOSE: {purpose}")
    print(" METHODS:")
    for method in methods:
        print(f"   â€¢ {method}")


def print_method_call(description: str, call: str, result: str = ""):
    """Helper function to print method call documentation"""
    print(f"\nðŸ”§ {description}")
    print(f"   Code: {call}")
    if result:
        print(f"   Result: {result}")


def test_minimal_parallel_system():
    """Enhanced test script with detailed interface documentation"""

    print_section_header(
        "PARALLEL AGENT SYSTEM INTERFACE DOCUMENTATION & TESTING",
        "Comprehensive demonstration of all system components with detailed explanations",
    )

    # =====================================================================================
    # GOAL 1: CORE-LEVEL DISTRIBUTION DOCUMENTATION & TESTING
    # =====================================================================================

    print_section_header(
        "GOAL 1: CORE-LEVEL DISTRIBUTION OF AGENTS ACROSS CPU CORES",
        "ProcessManager class manages worker processes bound to specific CPU cores",
    )

    print_class_docs(
        "ProcessManager",
        "Manages worker processes for each CPU core with core affinity binding",
        [
            "__init__(num_cores: int = None) - Initialize with specified number of cores",
            "spawn_core_worker(core_id: int) -> mp.Process - Create and bind worker to core",
            "initialize_cores() - Spawn workers for all cores",
            "distribute_task(task_data: dict, target_core: int) - Send task to specific core",
            "get_result(core_id: int, timeout: float = 5.0) - Retrieve result from core",
            "shutdown() - Gracefully shutdown all worker processes",
        ],
    )

    print_method_call(
        "Creating ProcessManager instance with 4 cores",
        "ProcessManager(num_cores=4)",
        "ProcessManager object initialized with core_queues, core_processes, and affinity_manager",
    )

    process_manager = ProcessManager(num_cores=4)

    print_method_call(
        "Initializing all core workers - spawns 4 separate processes",
        "process_manager.initialize_cores()",
        "Each process is bound to its respective CPU core using CoreAffinityManager",
    )

    process_manager.initialize_cores()

    print_method_call(
        "Distributing task to Core 0 - uses multiprocessing.Queue for IPC",
        'process_manager.distribute_task({"task": "test_core_0", "data": "hello"}, target_core=0)',
        "Task queued in Core 0's input queue with auto-generated task_id",
    )

    process_manager.distribute_task({"task": "test_core_0", "data": "hello"}, target_core=0)

    print_method_call(
        "Distributing task to Core 1 - demonstrates cross-core task distribution",
        'process_manager.distribute_task({"task": "test_core_1", "data": "world"}, target_core=1)',
        "Task queued in Core 1's input queue, processed by different worker process",
    )

    process_manager.distribute_task({"task": "test_core_1", "data": "world"}, target_core=1)

    print_method_call(
        "Retrieving result from Core 0 - demonstrates result collection",
        "process_manager.get_result(core_id=0)",
        "Retrieves processed result from Core 0's output queue",
    )

    result_0 = process_manager.get_result(core_id=0)
    result_1 = process_manager.get_result(core_id=1)

    print(f"âœ… Core 0 Result: {result_0}")
    print(f"âœ… Core 1 Result: {result_1}")

    # =====================================================================================
    # GOAL 2: HYBRID COMMUNICATION DOCUMENTATION & TESTING
    # =====================================================================================

    print_section_header(
        "GOAL 2: HYBRID COMMUNICATION SYSTEM",
        "MessageRouter + ThreadMessenger for optimized same-core vs cross-core messaging",
    )

    print_class_docs(
        "MessageRouter",
        "Routes messages between agents using optimal communication method based on core location",
        [
            "__init__() - Initialize with agent mappings and cross-core queues",
            "register_agent_location(agent_id: str, core_id: int) - Map agent to core",
            "route_message(from_agent: str, to_agent: str, message: dict) - Smart routing",
            "send_cross_core_message(target_core: int, message: dict) - Multiprocessing IPC",
            "_send_same_core_message(message: dict) - Threading communication",
            "receive_cross_core_message(core_id: int, timeout: float = 1.0) - Receive IPC",
            "set_thread_messenger(thread_messenger) - Configure threading layer",
        ],
    )

    print_class_docs(
        "ThreadMessenger",
        "Handles same-core agent communication using ThreadPoolExecutor and queue.Queue",
        [
            "__init__(max_workers: int = 4) - Initialize thread pool and agent queues",
            "send_async_message(from_agent: str, to_agent: str, message: dict) -> Future - Async delivery",
            "register_agent_queue(agent_id: str) -> queue.Queue - Create agent mailbox",
            "get_message(agent_id: str, timeout: float = 1.0) -> Any - Retrieve message",
            "has_messages(agent_id: str) -> bool - Check for pending messages",
            "shutdown() - Clean shutdown of thread pool",
        ],
    )

    print_method_call(
        "Creating MessageRouter - handles intelligent message routing",
        "MessageRouter()",
        "Initialized with agent_to_core_mapping, cross_core_queues, and MessageSerializer",
    )

    router = MessageRouter()

    print_method_call(
        "Creating ThreadMessenger - manages same-core communication",
        "ThreadMessenger()",
        "Initialized with ThreadPoolExecutor(max_workers=4) and agent_queues dictionary",
    )

    thread_messenger = ThreadMessenger()

    print_method_call(
        "Connecting MessageRouter to ThreadMessenger for same-core routing",
        "router.set_thread_messenger(thread_messenger)",
        "Enables MessageRouter to delegate same-core messages to ThreadMessenger",
    )

    router.set_thread_messenger(thread_messenger)

    print_method_call(
        "Registering agent1 on Core 0 - establishes agent location mapping",
        'router.register_agent_location("agent1", 0)',
        "agent1 -> Core 0 mapping stored, cross_core_queue[0] created if needed",
    )

    router.register_agent_location("agent1", 0)  # Core 0
    router.register_agent_location("agent2", 1)  # Core 1
    router.register_agent_location("agent3", 0)  # Same core as agent1

    print_method_call(
        "Testing CROSS-CORE communication (agent1->agent2) - uses multiprocessing.Queue",
        'router.route_message("agent1", "agent2", {"msg": "cross-core test", "type": "multiprocessing"})',
        "Message serialized via MessageSerializer and sent through multiprocessing.Queue",
    )

    router.route_message("agent1", "agent2", {"msg": "cross-core test", "type": "multiprocessing"})

    print_method_call(
        "Testing SAME-CORE communication (agent1->agent3) - uses ThreadPoolExecutor",
        'router.route_message("agent1", "agent3", {"msg": "same-core test", "type": "threading"})',
        "Message routed to ThreadMessenger, delivered via Future to agent3's queue",
    )

    future = router.route_message("agent1", "agent3", {"msg": "same-core test", "type": "threading"})

    # Demonstrate async behavior by checking the future result
    if future is not None:
        print(f"âœ… Same-core message sent asynchronously: Future object {type(future).__name__}")
        # Optionally wait for completion (though not necessary for this demo)
        # future.result()  # This would block until completion

    print_method_call(
        "Receiving cross-core message from Core 1 - demonstrates IPC retrieval",
        "router.receive_cross_core_message(core_id=1)",
        "Message deserialized from multiprocessing.Queue and returned",
    )

    cross_core_msg = router.receive_cross_core_message(core_id=1)
    print(f"âœ… Cross-core message received: {cross_core_msg}")

    print_method_call(
        "Receiving same-core message via ThreadMessenger - demonstrates threading retrieval",
        'thread_messenger.get_message("agent3")',
        "Message retrieved from agent3's queue.Queue mailbox",
    )

    same_core_msg = thread_messenger.get_message("agent3")
    print(f"âœ… Same-core message received: {same_core_msg}")

    # =====================================================================================
    # GOAL 3: REAL-TIME CONTEXT SWITCHING DOCUMENTATION & TESTING
    # =====================================================================================

    print_section_header(
        "GOAL 3: REAL-TIME CONTEXT SWITCHING BETWEEN LLMs",
        "ContextManager + LLMPool for shared context and LLM connection management",
    )

    print_class_docs(
        "ContextManager",
        "Manages context variables across parallel processes with real-time synchronization",
        [
            "__init__() - Initialize with multiprocessing.Manager for shared state",
            "update_context(key: str, value: Any, process_id: int = 0) - Update shared context",
            "get_context(process_id: int = 0) -> dict[str, Any] - Get context with caching",
            "get_context_value(key: str, default: Any = None) -> Any - Get specific value",
            "get_context_version() -> int - Get version for synchronization",
            "sync_check(process_id: int = 0) -> bool - Check cache synchronization",
            "force_sync(process_id: int = 0) - Force cache update",
            "clear_context() - Clear all context data",
            "get_stats() -> dict[str, Any] - Get synchronization statistics",
        ],
    )

    print_class_docs(
        "LLMPool",
        "Manages pool of LLM connections for a specific CPU core with context switching",
        [
            "__init__(core_id: int, pool_size: int = 2) - Initialize connection pool",
            "_initialize_pool() - Create LLMConnection instances",
            "switch_context(connection: LLMConnection, new_context: dict) -> LLMConnection - Context switch",
            "execute_with_context(agent_id: str, prompt: str, context: dict) -> str - Execute with context",
            "_get_available_connection() -> LLMConnection - Get free connection",
            "_return_connection(connection: LLMConnection) - Return to pool",
            "get_pool_stats() -> dict[str, Any] - Get pool utilization stats",
            "cleanup() - Clean shutdown of all connections",
        ],
    )

    print_class_docs(
        "LLMConnection",
        "Represents an LLM connection with context and execution capabilities",
        [
            "__init__(connection_id: str, config: dict = None) - Initialize connection",
            "set_context(context: dict[str, Any]) - Set current context",
            "get_context() -> dict[str, Any] - Get current context",
            "execute_prompt(prompt: str) -> str - Execute with current context (mock)",
        ],
    )

    print_method_call(
        "Creating ContextManager - enables shared context across processes",
        "ContextManager()",
        "Initialized with multiprocessing.Manager.dict() and version tracking",
    )

    context_mgr = ContextManager()

    print_method_call(
        "Creating LLMPool for Core 0 - manages LLM connections with context switching",
        "LLMPool(core_id=0)",
        "Initialized with 2 LLMConnection instances: core_0_conn_0, core_0_conn_1",
    )

    llm_pool = LLMPool(core_id=0)

    print_method_call(
        "Updating shared context - demonstrates cross-process synchronization",
        'context_mgr.update_context("current_task", "document_analysis", process_id=0)',
        "Context updated in shared memory, version incremented, local cache updated",
    )

    context_mgr.update_context("current_task", "document_analysis", process_id=0)
    context_mgr.update_context("user_id", "user_123", process_id=0)
    context_mgr.update_context("session_id", "session_456", process_id=0)

    print_method_call(
        "Getting context with caching - demonstrates performance optimization",
        "context_mgr.get_context(process_id=0)",
        "Returns cached context if version unchanged, otherwise updates from shared memory",
    )

    analysis_context = context_mgr.get_context(process_id=0)

    print_method_call(
        "Executing LLM with context - demonstrates context switching and execution",
        'llm_pool.execute_with_context("agent1", "Analyze the document structure", analysis_context)',
        "Gets available connection, switches context, executes prompt, returns connection to pool",
    )

    result1 = llm_pool.execute_with_context("agent1", "Analyze the document structure", analysis_context)
    print(f"âœ… LLM Result 1: {result1}")

    print_method_call(
        "Updating context for new task - demonstrates real-time context switching",
        'context_mgr.update_context("current_task", "summarization", process_id=0)',
        "Context changed, version incremented, all processes will see new context on next access",
    )

    context_mgr.update_context("current_task", "summarization", process_id=0)
    context_mgr.update_context("output_format", "bullet_points", process_id=0)

    summary_context = context_mgr.get_context(process_id=0)
    result2 = llm_pool.execute_with_context("agent1", "Summarize the key findings", summary_context)
    print(f"âœ… LLM Result 2: {result2}")

    print_method_call(
        "Getting context version - demonstrates synchronization tracking",
        "context_mgr.get_context_version()",
        "Returns current version number for synchronization checking",
    )

    print(f"âœ… Context version: {context_mgr.get_context_version()}")
    print(f"âœ… Context stats: {context_mgr.get_stats()}")
    print(f"âœ… LLM pool stats: {llm_pool.get_pool_stats()}")

    # =====================================================================================
    # INTEGRATION TEST: ALL SYSTEMS WORKING TOGETHER
    # =====================================================================================

    print_section_header(
        "INTEGRATION TEST: ALL 3 SYSTEMS WORKING TOGETHER",
        "Demonstrates complete parallel agent workflow with core distribution, hybrid communication, and context switching",
    )

    print("ðŸ”„ WORKFLOW SIMULATION:")
    print("   1. Agent1 (Core 0) performs initial analysis with shared context")
    print("   2. Results sent to Agent2 (Core 1) via cross-core communication")
    print("   3. Context updated for next stage across all processes")
    print("   4. Agent2 processes on different core with updated context")

    print_method_call(
        "Starting workflow - Agent1 on Core 0 begins analysis",
        'context_mgr.update_context("workflow_stage", "initial_analysis", process_id=0)',
        "Shared context updated, version incremented, available to all processes",
    )

    context_mgr.update_context("workflow_stage", "initial_analysis", process_id=0)

    analysis_result = llm_pool.execute_with_context(
        "agent1", "Start document analysis workflow", context_mgr.get_context(process_id=0)
    )

    print_method_call(
        "Cross-core collaboration - Agent1 sends results to Agent2 on Core 1",
        'router.route_message("agent1", "agent2", {"analysis_result": analysis_result, "next_stage": "detailed_processing"})',
        "Message routed via multiprocessing.Queue to Agent2's core, serialized for IPC",
    )

    router.route_message("agent1", "agent2", {"analysis_result": analysis_result, "next_stage": "detailed_processing"})

    print_method_call(
        "Context synchronization - updating context for next workflow stage",
        'context_mgr.update_context("workflow_stage", "detailed_processing", process_id=1)',
        "Context updated in shared memory, Agent2 on Core 1 will see new context",
    )

    context_mgr.update_context("workflow_stage", "detailed_processing", process_id=1)

    print_method_call(
        "Creating LLMPool for Core 1 - demonstrates multi-core LLM management",
        "LLMPool(core_id=1)",
        "Separate LLM pool with 2 connections: core_1_conn_0, core_1_conn_1",
    )

    llm_pool_core1 = LLMPool(core_id=1)

    processing_result = llm_pool_core1.execute_with_context(
        "agent2", "Perform detailed processing", context_mgr.get_context(process_id=1)
    )
    print(f"âœ… Processing result: {processing_result}")

    print("âœ… Integration test completed successfully!")
    print("   ðŸ“Š Core distribution: Agents on cores 0 and 1")
    print("   ðŸ”„ Cross-core communication: agent1 -> agent2 via multiprocessing")
    print("    Context switching: Real-time synchronization across cores")
    print("   ðŸ§  LLM execution: Context-aware processing on multiple cores")

    # =====================================================================================
    # CLEANUP AND FINAL VERIFICATION
    # =====================================================================================

    print_section_header(
        "CLEANUP AND SYSTEM VERIFICATION", "Graceful shutdown of all system components with final status reporting"
    )

    print_method_call(
        "Shutting down ThreadMessenger - stops thread pool and cleans up queues",
        "thread_messenger.shutdown()",
        "ThreadPoolExecutor shutdown with wait=True, all agent queues cleared",
    )

    thread_messenger.shutdown()

    print_method_call(
        "Cleaning up LLMPool Core 0 - waits for busy connections and clears pool",
        "llm_pool.cleanup()",
        "Waits for all connections to finish, clears connection dictionaries",
    )

    llm_pool.cleanup()

    print_method_call(
        "Cleaning up LLMPool Core 1 - demonstrates multi-core cleanup",
        "llm_pool_core1.cleanup()",
        "Separate cleanup for Core 1's LLM connections",
    )

    llm_pool_core1.cleanup()

    print_method_call(
        "Shutting down ProcessManager - terminates all worker processes",
        "process_manager.shutdown()",
        "Sends shutdown signals to all cores, waits for processes to finish, terminates if needed",
    )

    process_manager.shutdown()

    print_section_header(
        "FINAL SYSTEM VERIFICATION", "All parallel agent system goals successfully demonstrated and tested"
    )

    print("âœ… ALL TESTS PASSED! Parallel agent system is working correctly.")
    print("")
    print("ðŸŽ¯ GOAL 1: Core-level distribution âœ“")
    print("   â€¢ ProcessManager successfully distributes tasks across CPU cores")
    print("   â€¢ CoreAffinityManager binds processes to specific cores")
    print("   â€¢ Worker processes handle tasks independently")
    print("")
    print("ðŸŽ¯ GOAL 2: Hybrid communication âœ“")
    print("   â€¢ MessageRouter intelligently routes based on agent core locations")
    print("   â€¢ ThreadMessenger handles same-core communication via ThreadPoolExecutor")
    print("   â€¢ Multiprocessing.Queue handles cross-core communication")
    print("   â€¢ MessageSerializer ensures reliable IPC message transfer")
    print("")
    print("ðŸŽ¯ GOAL 3: Real-time context switching âœ“")
    print("   â€¢ ContextManager provides shared memory across processes")
    print("   â€¢ Version-based synchronization with local caching")
    print("   â€¢ LLMPool manages connections with context switching")
    print("   â€¢ Real-time context updates visible across all cores")
    print("")
    print("ðŸš€ INTEGRATION: All systems working together âœ“")
    print("   â€¢ Multi-core task distribution with shared context")
    print("   â€¢ Cross-core agent collaboration via hybrid communication")
    print("   â€¢ Context-aware LLM execution across multiple cores")
    print("   â€¢ Graceful cleanup and resource management")


if __name__ == "__main__":
    test_minimal_parallel_system()
