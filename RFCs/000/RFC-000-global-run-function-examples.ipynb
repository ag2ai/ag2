{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC 001: Global run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Annotated, Any, Iterable, Optional, Protocol, Union, runtime_checkable, Literal\n",
    "from unittest.mock import MagicMock\n",
    "from uuid import UUID, uuid4\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autogen import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Eventually, we will move away from dictionaries and represent all messages with objects (dataclasses or Pydantic base models). For now, we will use existing implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Message = dict[str, Any]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "\n",
    "These are six different abstract types of events used by the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EventType = Literal[\"input_request\", \"async_input_request\", \"input_response\", \"agent_message\", \"output\", \"system\"]\n",
    "\n",
    "class Event(BaseModel, ABC):\n",
    "    uuid: Annotated[UUID, Field(default_factory=uuid4)]\n",
    "\n",
    "    type: EventType\n",
    "\n",
    "    @abstractmethod\n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"): ...\n",
    "\n",
    "    @abstractmethod\n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"): ...\n",
    "\n",
    "\n",
    "class InputRequestEvent(Event):\n",
    "    prompt: str\n",
    "\n",
    "    def respond(self, response: \"InputResponseEvent\"):\n",
    "        pass\n",
    "\n",
    "    type: EventType = \"input_request\"\n",
    "\n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"):\n",
    "        print(f\"InputRequestEvent.process: {self=}, {event_processor=}\")\n",
    "        event_processor.process_input_request_event(self)\n",
    "    \n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"):\n",
    "        await event_processor.a_process_input_request_event(self)\n",
    "    \n",
    "\n",
    "class AsyncInputRequestEvent(Event):\n",
    "    prompt: str\n",
    "\n",
    "    async def a_respond(self, response: \"InputResponseEvent\"):\n",
    "        pass\n",
    "\n",
    "    type: EventType = \"async_input_request\"\n",
    "\n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"):\n",
    "        raise RuntimeError(\"Cannot process async input request synchronously\")\n",
    "    \n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"):\n",
    "        await event_processor.a_process_async_input_request_event(self)\n",
    "\n",
    "\n",
    "class InputResponseEvent(Event):\n",
    "    type: EventType = \"input_response\"\n",
    "\n",
    "    value: str\n",
    "    \n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"):\n",
    "        event_processor.process_input_response_event(self)\n",
    "\n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"):\n",
    "        await event_processor.a_process_input_response_event(self)\n",
    "\n",
    "class AgentMessageEvent(Event):\n",
    "    message: Message\n",
    "\n",
    "    type: EventType = \"agent_message\"\n",
    "\n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"):\n",
    "        event_processor.process_agent_message_event(self)\n",
    "\n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"):\n",
    "        await event_processor.a_process_agent_message_event(self)\n",
    "\n",
    "    \n",
    "class OutputEvent(Event):\n",
    "    value: str\n",
    "\n",
    "    type: EventType = \"output\"\n",
    "\n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"):\n",
    "        event_processor.process_output_event(self)\n",
    "\n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"):\n",
    "        await event_processor.a_process_output_event(self)\n",
    "\n",
    "\n",
    "class SystemEvent(Event):\n",
    "    value: str\n",
    "\n",
    "    type: EventType = \"system\"\n",
    "\n",
    "    def process(self, event_processor: \"EventProcessorProtocol\"):\n",
    "        event_processor.process_system_event(self)\n",
    "\n",
    "    async def a_process(self, event_processor: \"AsyncEventProcessorProtocol\"):\n",
    "        await event_processor.a_process_system_event(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_input_request(event: Event) -> bool:\n",
    "    return event.type == \"input_request\"\n",
    "\n",
    "def is_async_input_request(event: Event) -> bool:\n",
    "    return event.type == \"async_input_request\"\n",
    "\n",
    "def is_input_response(event: Event) -> bool:\n",
    "    return event.type == \"input_response\"\n",
    "\n",
    "def is_output(event: Event) -> bool:\n",
    "    return event.type == \"output\"\n",
    "\n",
    "def is_agent_message(event: Event) -> bool:\n",
    "    return event.type == \"agent_message\"\n",
    "\n",
    "def is_system_event(event: Event) -> bool:\n",
    "    return event.type == \"system\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncIterable\n",
    "\n",
    "\n",
    "class RunResponseProtocol(Protocol):\n",
    "    @property\n",
    "    def events(self) -> Iterable[Event]: ...\n",
    "\n",
    "    @property\n",
    "    def messages(self) -> Iterable[Message]: ...\n",
    "\n",
    "    @property\n",
    "    def summary(self) -> str: ...\n",
    "\n",
    "def process_run_response(run_response: RunResponseProtocol, processor: \"EventProcessorProtocol\") -> None:\n",
    "    for event in run_response.events:\n",
    "        event.process(processor)\n",
    "\n",
    "\n",
    "class AsyncRunResponseProtocol(Protocol):\n",
    "    @property\n",
    "    def events(self) -> AsyncIterable[Event]: ...\n",
    "\n",
    "    @property\n",
    "    def messages(self) -> AsyncIterable[Message]: ...\n",
    "\n",
    "    @property\n",
    "    async def summary(self) -> str: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat manager protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatManagerProtocol(Protocol):\n",
    "    def register_agent(self, agent: Union[Agent, list[Agent]]) -> None: ...\n",
    "    def get_next_agent(self, response: RunResponseProtocol) -> Agent: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round robin chat manager example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundRobinChatManager():\n",
    "    def __init__(self):\n",
    "        self.agents: list[Agent] = []\n",
    "        self.agent_names: list[str] = []\n",
    "    \n",
    "    def register_agent(self, agent: Union[Agent, list[Agent]]) -> None:\n",
    "        if isinstance(agent, list):\n",
    "            self.agents.extend(agent)\n",
    "            self.agent_names.extend([agent.name for agent in agent])\n",
    "        else:\n",
    "            self.agents.append(agent)\n",
    "            self.agent_names.append(agent.name)\n",
    "\n",
    "    def get_next_agent(self, response: RunResponseProtocol) -> Agent:\n",
    "        # Get last agent\n",
    "        if not response.messages:\n",
    "            return self.agents[0]\n",
    "        \n",
    "        last_agent = response.messages[-1].message[\"sender\"]\n",
    "        last_agent_index = self.agent_names.index(last_agent)\n",
    "        next_agent_index = (last_agent_index + 1) % len(self.agent_names)\n",
    "        return self.agents[next_agent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    *agents: Agent, \n",
    "    message: Optional[str] = None, \n",
    "    previous_run: Optional[RunResponseProtocol] = None, \n",
    "    chat_manager: Optional[ChatManagerProtocol] = None, \n",
    "    **kwargs: Any\n",
    ") -> RunResponseProtocol:\n",
    "    \"\"\"Run the agents with the given initial message.\n",
    "\n",
    "    Args:\n",
    "        agents: The agents to run.\n",
    "        message: The initial message to send to the first agent.\n",
    "        previous_run: The previous run to continue.\n",
    "        kwargs: Additional arguments to pass to the agents.\n",
    "\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "async def a_run(\n",
    "    *agents: Agent, message: Optional[str] = None, \n",
    "    previous_run: Optional[RunResponseProtocol] = None, \n",
    "    chat_manager: Optional[ChatManagerProtocol] = None,\n",
    "    **kwargs: Any\n",
    ") -> AsyncRunResponseProtocol:\n",
    "    \"\"\"Run the agents with the given initial message.\n",
    "\n",
    "    Args:\n",
    "        agents: The agents to run.\n",
    "        message: The initial message to send to the first agent.\n",
    "        previous_run: The previous run to continue.\n",
    "        kwargs: Additional arguments to pass to the agents.\n",
    "\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event processing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "\n",
    "agents: list[Agent] = [ConversableAgent(name=\"Alice\"), ConversableAgent(name=\"Bob\")]\n",
    "\n",
    "response = run(*agents, message=\"What is the meaning of life?\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    InputRequestEvent(prompt=\"What is the meaning of life?\"),\n",
    "    InputResponseEvent(value=\"42\"),\n",
    "    AgentMessageEvent(message={\"text\": \"What is the meaning of life?\", \"sender\": \"Alice\"}),\n",
    "    OutputEvent(value=\"thinking about it...\"),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "response.messages = [\n",
    "    {\"text\": \"What is the meaning of life?\", \"sender\": \"Alice\"},\n",
    "]\n",
    "response.summary = \"Alice and Bob had a conversation about the meaning of life.\"\n",
    "\n",
    "with unittest.mock.patch(\"builtins.input\", return_value=\"42\"):\n",
    "    for event in response.events:\n",
    "        print(f\"Event: {event}\")\n",
    "        if is_input_request(event):\n",
    "            print(f\"Input request: {event.prompt}\")\n",
    "            s = input(event.prompt)\n",
    "\n",
    "            print(f\"Response from UI: {s}\")\n",
    "            event.respond(s)\n",
    "\n",
    "        elif is_output(event):\n",
    "            print(f\"Output message: {event.value}\")\n",
    "\n",
    "        elif is_system_event(event):\n",
    "            print(f\"System event: {event}\")\n",
    "\n",
    "print()\n",
    "print(f\"Messages: {response.messages}\")\n",
    "\n",
    "print()\n",
    "print(f\"Summary: {response.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event processor classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventProcessorProtocol(Protocol):\n",
    "    def process_input_request_event(self, event: Event):\n",
    "        ...\n",
    "\n",
    "    def process_input_response_event(self, event: Event):\n",
    "        ...\n",
    "\n",
    "    def process_agent_message_event(self, event: Event):\n",
    "        ...\n",
    "\n",
    "    def process_output_event(self, event: Event):\n",
    "        ...\n",
    "\n",
    "    def process_system_event(self, event: Event):\n",
    "        ...\n",
    "\n",
    "class SimpleEventProcessor:\n",
    "    def process_input_request_event(self, event: Event):\n",
    "        print(f\"Input request: {event.prompt}\")\n",
    "        s = input(event.prompt)\n",
    "\n",
    "        print(f\"Response from UI: {s}\")\n",
    "        event.respond(s)\n",
    "\n",
    "    def process_input_response_event(self, event: Event):\n",
    "        print(f\"Input response: {event.value}\")\n",
    "\n",
    "    def process_agent_message_event(self, event: Event):\n",
    "        print(f\"Agent message: {event.message}\")\n",
    "\n",
    "    def process_output_event(self, event: Event):\n",
    "        print(f\"Output message: {event.value}\")\n",
    "\n",
    "    def process_system_event(self, event: Event):\n",
    "        print(f\"System event: {event}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with unittest.mock.patch(\"builtins.input\", return_value=\"42\"):\n",
    "    process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single agent run simplest form (no functions, no conversation with the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "agent = ConversableAgent(name=\"Alice\", llm_config=llm_config)\n",
    "\n",
    "response = run(agent, message=\"What is the meaning of life?\", is_termination_message=lambda x: x == \"42\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"thinking about it...\", \"sender\": \"Alice\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"42\", \"sender\": \"Alice\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "response.messages = [\n",
    "    {\"text\": \"thinking about it...\", \"sender\": \"Alice\"},\n",
    "    {\"text\": \"42\", \"sender\": \"Alice\"},\n",
    "]\n",
    "response.summary = \"Alice said the meaning of life is 42\"\n",
    "\n",
    "process_run_response(response, SimpleEventProcessor())\n",
    "\n",
    "print()\n",
    "print(f\"Messages: {response.messages}\")\n",
    "\n",
    "print()\n",
    "print(f\"Summary: {response.summary}\")\n",
    "process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single agent run using functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.tools import tool\n",
    "\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "agent = ConversableAgent(name=\"Alice\", llm_config=llm_config)\n",
    "\n",
    "@tool(description=\"Returns the meaning of life.\")\n",
    "def meaning_of_life():\n",
    "    return \"42\"\n",
    "\n",
    "meaning_of_life.register_tool(agent)\n",
    "#agent.register_tool(meaning_of_life) # Alternative implementation\n",
    "\n",
    "response = run(agent, message=\"What is the meaning of life?\", is_termination_message=lambda x: x == \"42\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"thinking about it...\", \"sender\": \"Alice\"}),\n",
    "    SystemEvent(value=\"Alice called meaning_of_life\"), # Replace WithFunctionCallEvent subclass of AgentMessageEvent\n",
    "    SystemEvent(value=\"meaning_of_life returned 42\"),\n",
    "    AgentMessageEvent(message={\"text\": \"42\", \"sender\": \"Alice\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "response.messages = [\n",
    "    {\"text\": \"thinking about it...\", \"sender\": \"Alice\"},\n",
    "    {\"text\": \"42\", \"sender\": \"Alice\"},\n",
    "]\n",
    "response.summary = \"Alice said the meaning of life is 42\"\n",
    "\n",
    "process_run_response(response, SimpleEventProcessor())\n",
    "\n",
    "print()\n",
    "print(f\"Messages: {response.messages}\")\n",
    "\n",
    "print()\n",
    "print(f\"Summary: {response.summary}\")\n",
    "process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat between two comedian agents\n",
    "\n",
    "# 1. Import our agent class\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# 2. Define our LLM configuration for OpenAI's GPT-4o mini,\n",
    "#    uses the OPENAI_API_KEY environment variable\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "# 3. Create our agents who will tell each other jokes,\n",
    "#    with Jack ending the chat when Emma says FINISH\n",
    "jack = ConversableAgent(\n",
    "    \"Jack\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=(\n",
    "      \"Your name is Jack and you are a comedian \"\n",
    "      \"in a two-person comedy show.\"\n",
    "    ),\n",
    "    is_termination_msg=lambda x: True if \"FINISH\" in x[\"text\"] else False\n",
    ")\n",
    "emma = ConversableAgent(\n",
    "    \"Emma\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=(\n",
    "      \"Your name is Emma and you are a comedian \"\n",
    "      \"in a two-person comedy show. Say the word FINISH \"\n",
    "      \"ONLY AFTER you've heard 2 of Jack's jokes.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = run(jack, emma, message=\"Tell me a joke.\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"What do you call a fake noodle? An impasta.\", \"sender\": \"Jack\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Haha, nice one! What do you call a belt made of watches? A waist of time.\", \"sender\": \"Emma\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Why couldn't the bicycle stand up by itself? It was two tired.\", \"sender\": \"Jack\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"FINISH\", \"sender\": \"Emma\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"What do you call a fake noodle? An impasta.\", \"sender\": \"Jack\"},\n",
    "    {\"text\": \"Haha, nice one! What do you call a belt made of watches? A waist of time.\", \"sender\": \"Emma\"},\n",
    "    {\"text\": \"Why couldn't the bicycle stand up by itself? It was two tired.\", \"sender\": \"Jack\"},\n",
    "    {\"text\": \"FINISH\", \"sender\": \"Emma\"},\n",
    "]\n",
    "\n",
    "response.summary = \"Jack and Emma had a comedy chat.\"\n",
    "\n",
    "process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "# Planner agent setup\n",
    "planner_message = \"Create lesson plans for 4th grade.\"\n",
    "planner = ConversableAgent(\n",
    "    name=\"planner_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=planner_message,\n",
    "    description=\"Creates lesson plans\"\n",
    ")\n",
    "\n",
    "# Reviewer agent setup\n",
    "reviewer_message = \"Review lesson plans against 4th grade curriculum. Provide max 3 changes.\"\n",
    "reviewer = ConversableAgent(\n",
    "    name=\"reviewer_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=reviewer_message,\n",
    "    description=\"Reviews lesson plans\"\n",
    ")\n",
    "\n",
    "# Teacher agent setup\n",
    "teacher_message = \"Choose topics and work with planner and reviewer. Say DONE! when finished.\"\n",
    "teacher = ConversableAgent(\n",
    "    name=\"teacher_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=teacher_message,\n",
    ")\n",
    "\n",
    "groupchat = GroupChat(\n",
    "    agents=[teacher, planner, reviewer],\n",
    "    speaker_selection_method=\"auto\",\n",
    "    messages=[]\n",
    ")\n",
    "\n",
    "# Create manager\n",
    "# At each turn, the manager will check if the message contains DONE! and end the chat if so\n",
    "# Otherwise, it will select the next appropriate agent using its LLM\n",
    "manager = GroupChatManager(\n",
    "    name=\"group_manager\",\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: \"DONE!\" in (x.get(\"content\", \"\") or \"\").upper()\n",
    ")\n",
    "\n",
    "class NewGroupChatManager(GroupChatManager):\n",
    "    def __init__(self, is_termination_msg, llm_config):\n",
    "        self._is_termination_msg = is_termination_msg\n",
    "        self._llm_config = llm_config\n",
    "\n",
    "\n",
    "response = run(planner, reviewer, teacher, message=\"Create lesson plans for 4th grade.\", chat_manager=manager)\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"I would change the addition and subtraction with multiplication and division.\", \"sender\": \"reviewer_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"teacher_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"DONE!\", \"sender\": \"teacher_agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"I would change the addition and subtraction with multiplication and division.\", \"sender\": \"reviewer_agent\"},\n",
    "    {\"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"teacher_agent\"},\n",
    "    {\"text\": \"DONE!\", \"sender\": \"teacher_agent\"},\n",
    "]\n",
    "\n",
    "response.summary = \"planner_agent, reviewer_agent, and teacher_agent had a chat.\"\n",
    "\n",
    "process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "\n",
    "class NewGroupChatManager(GroupChatManager):\n",
    "    def __init__(self, is_termination_msg, llm_config):\n",
    "        self._is_termination_msg = is_termination_msg\n",
    "        self._llm_config = llm_config\n",
    "\n",
    "llm_config = LMMConfig({\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"})\n",
    "\n",
    "@tool\n",
    "def submit_plan(plan: str) -> str:\n",
    "    return f\"Plan submitted: {plan}\"\n",
    "\n",
    "with llm_config:\n",
    "    planner = ConversableAgent(\"You are a planner. Collaborate with teacher and reviewer to create lesson plans.\")\n",
    "\n",
    "    reviewer = ConversableAgent(\"You are a reviewer. Review lesson plans against 4th grade curriculum. Provide max 3 changes.\")\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        \"You are a teacher. Choose topics and work with planner and reviewer. Say DONE! when finished.\",\n",
    "        tools = submit_plan\n",
    "    )\n",
    "\n",
    "    chat_manager=NewGroupChatManager(terminate_on=Keyword(\"DONE!\"))\n",
    "\n",
    "response = run(\n",
    "    planner, reviewer, teacher, \n",
    "    message=\"Create lesson plans for 4th grade.\",\n",
    "    chat_manager=chat_manager,\n",
    ")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"I would change the addition and subtraction with multiplication and division.\", \"sender\": \"reviewer_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"teacher_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"DONE!\", \"sender\": \"teacher_agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"I would change the addition and subtraction with multiplication and division.\", \"sender\": \"reviewer_agent\"},\n",
    "    {\"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"teacher_agent\"},\n",
    "    {\"text\": \"DONE!\", \"sender\": \"teacher_agent\"},\n",
    "]\n",
    "\n",
    "response.summary = \"planner_agent, reviewer_agent, and teacher_agent had a chat.\"\n",
    "\n",
    "process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "# Planner agent setup\n",
    "planner_message = \"Create lesson plans for 4th grade.\"\n",
    "planner = ConversableAgent(\n",
    "    name=\"planner_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=planner_message,\n",
    "    description=\"Creates lesson plans\"\n",
    ")\n",
    "\n",
    "# Reviewer agent setup\n",
    "reviewer_message = \"Review lesson plans against 4th grade curriculum. Provide max 3 changes.\"\n",
    "reviewer = ConversableAgent(\n",
    "    name=\"reviewer_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=reviewer_message,\n",
    "    description=\"Reviews lesson plans\"\n",
    ")\n",
    "\n",
    "# Teacher agent setup\n",
    "teacher_message = \"Choose topics and work with planner and reviewer. Say DONE! when finished.\"\n",
    "teacher = ConversableAgent(\n",
    "    name=\"teacher_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=teacher_message,\n",
    ")\n",
    "\n",
    "response = run(\n",
    "    planner, reviewer, teacher, \n",
    "    message=\"Create lesson plans for 4th grade.\", \n",
    "    chat_manager=RoundRobinChatManager([planner, reviewer, teacher])\n",
    ")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"I would change the addition and subtraction with multiplication and division.\", \"sender\": \"reviewer_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"teacher_agent\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"DONE!\", \"sender\": \"teacher_agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"I would change the addition and subtraction with multiplication and division.\", \"sender\": \"reviewer_agent\"},\n",
    "    {\"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"planner_agent\"},\n",
    "    {\"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\", \"sender\": \"teacher_agent\"},\n",
    "    {\"text\": \"DONE!\", \"sender\": \"teacher_agent\"},\n",
    "]\n",
    "\n",
    "response.summary = \"planner_agent, reviewer_agent, and teacher_agent had a chat.\"\n",
    "\n",
    "process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent = ConversableAgent(name=\"Sales Agent\", llm_config=llm_config)\n",
    "complaints_agent = ConversableAgent(name=\"Complaints Agent\", llm_config=llm_config)\n",
    "\n",
    "triage_agent = ConversableAgent(name=\"Triage Agent\", llm_config=llm_config)\n",
    "\n",
    "@triage_agent.register_for_llm()\n",
    "def transfer_to_sales():\n",
    "   return sales_agent\n",
    "\n",
    "@triage_agent.register_for_llm()\n",
    "def transfer_to_complaints():\n",
    "   return complaints_agent\n",
    "\n",
    "\n",
    "response = run(triage_agent, message=\"I have a complaint about my order.\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    SystemEvent(value=\"Triage Agent called transfer_to_complaints\"),\n",
    "    SystemEvent(value=\"transfer_to_complaints returned Complaints Agent\"),\n",
    "    InputRequestEvent(prompt=\"Hi what is your complaint?\"),\n",
    "    InputResponseEvent(value=\"My order was late.\"),\n",
    "    AgentMessageEvent(message={\"text\": \"I'm sorry to hear that. We will make the order faster.\", \"sender\": \"Complaints Agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"I'm sorry to hear that. We will make the order faster.\", \"sender\": \"Complaints Agent\"},\n",
    "]\n",
    "response.summary = \"Complaints Agent apologized for the late order.\"\n",
    "\n",
    "with unittest.mock.patch(\"builtins.input\", return_value=\"My order was late.\"):\n",
    "    process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
