{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC 001: Global run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from random import randint\n",
    "from typing import Annotated, Any, Iterable, Literal, Optional, Protocol, Union, runtime_checkable\n",
    "from unittest.mock import MagicMock\n",
    "from uuid import UUID, uuid4\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autogen import Agent as OriginalAgent\n",
    "from autogen import ConversableAgent as OriginalConversableAgent\n",
    "from autogen.tools import Depends, Tool, tool\n",
    "\n",
    "\n",
    "def on(o: Any):\n",
    "    return lambda o=o: o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runtime_checkable\n",
    "class LLMConfigProtocol(Protocol):\n",
    "    def __enter__(self): ...\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback): ...\n",
    "\n",
    "\n",
    "class LLMConfig:\n",
    "    llm_config: list[dict[str, Any]] = []\n",
    "\n",
    "    def __init__(self, llm_config: dict[str, Any]):\n",
    "        self._llm_config = llm_config\n",
    "\n",
    "    def __enter__(self):\n",
    "        LLMConfig.llm_config.append(self._llm_config)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        LLMConfig.llm_config.pop()\n",
    "\n",
    "    @classmethod\n",
    "    def get_llm_config(cls):\n",
    "        return cls.llm_config[-1] if LLMConfig.llm_config else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversable agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversableAgent(OriginalConversableAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs[\"name\"] = kwargs.get(\"name\", f\"name-{randint(0, 1000)}\")\n",
    "        llm_config = kwargs.get(\"llm_config\", {}) if \"llm_config\" in kwargs else LLMConfig.get_llm_config()\n",
    "        kwargs[\"llm_config\"] = llm_config\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def add_tool(self, tool: Tool):\n",
    "        tool.register_for_llm(self)\n",
    "\n",
    "\n",
    "ConversableAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentProtocol(OriginalAgent, Protocol):\n",
    "    @property\n",
    "    def run_info(self) -> Optional[\"RunInfo\"]: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_run_tool(agent: AgentProtocol) -> Tool:\n",
    "    @tool()\n",
    "    def sub_chat(agent: Annotated[AgentProtocol, Depends(on(agent))]) -> str:\n",
    "        agent1 = MagicMock(spec=ConversableAgent)\n",
    "        agent2 = MagicMock(spec=ConversableAgent)\n",
    "\n",
    "        response = run(agent1, agent2, above_run=agent.run_info, message=\"Hello, world!\")\n",
    "\n",
    "        return response.summary\n",
    "\n",
    "    return sub_chat\n",
    "\n",
    "\n",
    "# agent = MagicMock(spec=AgentProtocol)\n",
    "# create_sub_chat(agent).func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages\n",
    "\n",
    "Eventually, we will move away from dictionaries and represent all messages with objects (dataclasses or Pydantic base models). For now, we will use existing implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Message = dict[str, Any]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events\n",
    "\n",
    "These are six different abstract types of events used by the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EventType = Literal[\"input_request\", \"async_input_request\", \"input_response\", \"agent_message\", \"output\", \"system\"]\n",
    "\n",
    "\n",
    "class Event(BaseModel, ABC):\n",
    "    uuid: Annotated[UUID, Field(default_factory=uuid4)]\n",
    "\n",
    "    type: EventType\n",
    "\n",
    "\n",
    "class InputRequestEvent(Event):\n",
    "    prompt: str\n",
    "\n",
    "    def respond(self, response: \"InputResponseEvent\"):\n",
    "        pass\n",
    "\n",
    "    type: EventType = \"input_request\"\n",
    "\n",
    "\n",
    "class AsyncInputRequestEvent(Event):\n",
    "    prompt: str\n",
    "\n",
    "    async def a_respond(self, response: \"InputResponseEvent\"):\n",
    "        pass\n",
    "\n",
    "    type: EventType = \"async_input_request\"\n",
    "\n",
    "\n",
    "class InputResponseEvent(Event):\n",
    "    type: EventType = \"input_response\"\n",
    "\n",
    "    value: str\n",
    "\n",
    "\n",
    "class AgentMessageEvent(Event):\n",
    "    message: Message\n",
    "\n",
    "    type: EventType = \"agent_message\"\n",
    "\n",
    "\n",
    "class OutputEvent(Event):\n",
    "    value: str\n",
    "\n",
    "    type: EventType = \"output\"\n",
    "\n",
    "\n",
    "class SystemEvent(Event):\n",
    "    value: str\n",
    "\n",
    "    type: EventType = \"system\"\n",
    "\n",
    "\n",
    "class ErrorEvent(Event):\n",
    "    type: EventType = \"error\"\n",
    "\n",
    "    error: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global run function\n",
    "\n",
    "### Run response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncIterable\n",
    "\n",
    "\n",
    "class RunInfoProtocol(Protocol):\n",
    "    @property\n",
    "    def uuid(self) -> UUID: ...\n",
    "\n",
    "    @property\n",
    "    def above_run(self) -> Optional[\"RunResponseProtocol\"]: ...\n",
    "\n",
    "\n",
    "class RunResponseProtocol(RunInfoProtocol, Protocol):\n",
    "    @property\n",
    "    def events(self) -> Iterable[Event]: ...\n",
    "\n",
    "    @property\n",
    "    def messages(self) -> Iterable[Message]: ...\n",
    "\n",
    "    @property\n",
    "    def summary(self) -> str: ...\n",
    "\n",
    "\n",
    "class AsyncRunResponseProtocol(RunInfoProtocol, Protocol):\n",
    "    @property\n",
    "    def uuid(self) -> UUID: ...\n",
    "\n",
    "    @property\n",
    "    def above_run(self) -> Optional[\"RunResponseProtocol\"]: ...\n",
    "\n",
    "    @property\n",
    "    def events(self) -> AsyncIterable[Event]: ...\n",
    "\n",
    "    @property\n",
    "    def messages(self) -> AsyncIterable[Message]: ...\n",
    "\n",
    "    @property\n",
    "    async def summary(self) -> str: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat manager protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatManagerProtocol(Protocol):\n",
    "    def register_agent(self, agent: Union[AgentProtocol, list[AgentProtocol]]) -> None: ...\n",
    "    def get_next_agent(self, response: RunResponseProtocol) -> AgentProtocol: ...\n",
    "\n",
    "\n",
    "class AsyncChatManagerProtocol(Protocol):\n",
    "    def register_agent(self, agent: Union[AgentProtocol, list[AgentProtocol]]) -> None: ...\n",
    "    async def a_get_next_agent(self, response: AsyncRunResponseProtocol) -> AgentProtocol: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round robin chat manager example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundRobinChatManager:\n",
    "    def __init__(self):\n",
    "        self.agents: list[AgentProtocol] = []\n",
    "        self.agent_names: list[str] = []\n",
    "\n",
    "    def register_agent(self, agent: Union[AgentProtocol, list[AgentProtocol]]) -> None:\n",
    "        if isinstance(agent, list):\n",
    "            self.agents.extend(agent)\n",
    "            self.agent_names.extend([agent.name for agent in agent])\n",
    "        else:\n",
    "            self.agents.append(agent)\n",
    "            self.agent_names.append(agent.name)\n",
    "\n",
    "    def get_next_agent(self, response: RunResponseProtocol) -> AgentProtocol:\n",
    "        # Get last agent\n",
    "        if not response.messages:\n",
    "            return self.agents[0]\n",
    "\n",
    "        last_agent = response.messages[-1].message[\"sender\"]\n",
    "        last_agent_index = self.agent_names.index(last_agent)\n",
    "        next_agent_index = (last_agent_index + 1) % len(self.agent_names)\n",
    "        return self.agents[next_agent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SummaryMethod:\n",
    "    def __init__(\n",
    "        self,\n",
    "        method: Optional[\n",
    "            Union[\n",
    "                Literal[\"last_msg\", \"reflection_with_llm\"],\n",
    "                Callable[[AgentProtocol, AgentProtocol, dict[str, Any]], str],\n",
    "            ]\n",
    "        ] = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        self.method = method if method else ConversableAgent.DEFAULT_SUMMARY_METHOD\n",
    "        self.kwargs = kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    *agents: AgentProtocol,\n",
    "    message: Optional[str] = None,\n",
    "    continuation_of: Optional[RunResponseProtocol] = None,\n",
    "    sub_run_of: Optional[RunInfoProtocol] = None,\n",
    "    chat_manager: Optional[ChatManagerProtocol] = None,\n",
    "    max_turns: Optional[int] = None,\n",
    "    summary_method: Optional[SummaryMethod] = None,\n",
    "    **kwargs: Any,\n",
    ") -> RunResponseProtocol:\n",
    "    \"\"\"Run the agents with the given initial message.\n",
    "\n",
    "    Args:\n",
    "        agents: The agents to run.\n",
    "        message: The initial message to send to the first agent.\n",
    "        previous_run: The previous run to continue.\n",
    "        kwargs: Additional arguments to pass to the agents.\n",
    "\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "async def a_run(\n",
    "    *agents: AgentProtocol,\n",
    "    message: Optional[str] = None,\n",
    "    continuation_of: Optional[AsyncRunResponseProtocol] = None,\n",
    "    sub_run_of: Optional[RunInfoProtocol] = None,\n",
    "    chat_manager: Optional[AsyncChatManagerProtocol] = None,\n",
    "    max_turns: Optional[int] = None,\n",
    "    summary_method: Optional[SummaryMethod] = None,\n",
    "    **kwargs: Any,\n",
    ") -> AsyncRunResponseProtocol:\n",
    "    \"\"\"Run the agents with the given initial message.\n",
    "\n",
    "    Args:\n",
    "        agents: The agents to run.\n",
    "        message: The initial message to send to the first agent.\n",
    "        previous_run: The previous run to continue.\n",
    "        kwargs: Additional arguments to pass to the agents.\n",
    "\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event processing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config.get_llm_config()\n",
    "with llm_config:\n",
    "    print(LLMConfig.llm_config)\n",
    "    print(llm_config.get_llm_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import environ\n",
    "\n",
    "# llm_config will be an object that can be used as a context manager\n",
    "# this will allow us to set the configuration for the agents without passing it as an argument\n",
    "llm_config = LLMConfig({\"config_list\": [{\"api_key\": environ[\"OPENAI_API_KEY\"], \"model\": \"gpt-4o-mini\"}]})\n",
    "\n",
    "with llm_config:\n",
    "    alice = ConversableAgent(system_message=\"You are a useful assistant doing your best to solve a task problem.\")\n",
    "    bob = ConversableAgent(\n",
    "        system_message=\"You are a fact checker and your job is to check all fact using realible sources.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# tools will be attached to agents directly without using register_for_llm and register_for_execution functions\n",
    "@tool(description=\"Search Wikipedia for the given query.\")\n",
    "def search_wikipedia(query: str) -> str: ...\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: Annotated[str, \"A short answer to the user's question.\"]\n",
    "    explanation: Annotated[str, \"A detailed explanation of the answer.\"]\n",
    "    links_visited: list[str]\n",
    "\n",
    "\n",
    "@tool(description=\"Send the answer to the user.\")\n",
    "def send_answer(answer: Answer) -> str: ...\n",
    "\n",
    "\n",
    "alice.add_tool(send_answer)\n",
    "bob.add_tool(search_wikipedia)\n",
    "\n",
    "# finally, we will execute a global run function to run the agents\n",
    "# run function will internally create a UserProxyAgent and use it for tool execution\n",
    "# the function will return immediately and return an RunResponseProtocol object that can be used for iterating over events and messages produced by the agents running\n",
    "# there are both sync and async versions of the run function\n",
    "response = run(alice, bob, message=\"Who is Leonardo da Vinci?\")\n",
    "\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    InputRequestEvent(prompt=\"What is the meaning of life?\"),\n",
    "    InputResponseEvent(value=\"42\"),\n",
    "    AgentMessageEvent(message={\"text\": \"What is the meaning of life?\", \"sender\": \"Alice\"}),\n",
    "    OutputEvent(value=\"thinking about it...\"),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "response.messages = [\n",
    "    {\"text\": \"What is the meaning of life?\", \"sender\": \"Alice\"},\n",
    "]\n",
    "response.summary = \"Alice and Bob had a conversation about the meaning of life.\"\n",
    "\n",
    "with unittest.mock.patch(\"builtins.input\", return_value=\"42\"):\n",
    "    for event in response.events:\n",
    "        print(f\"Event: {event}\")\n",
    "        if event.type == \"input_request\":\n",
    "            print(f\"Input request: {event.prompt}\")\n",
    "            s = input(event.prompt)\n",
    "\n",
    "            print(f\"Response from UI: {s}\")\n",
    "            event.respond(s)\n",
    "\n",
    "        elif event.type == \"input_response\":\n",
    "            # Do nothing, just pass\n",
    "            if event.value != s:\n",
    "                raise RuntimeError(f\"Expected {s}, got {event.value}\")\n",
    "\n",
    "        elif event.type == \"output\":\n",
    "            print(f\"Output message: {event.value}\")\n",
    "\n",
    "        elif event.type == \"agent_message\":\n",
    "            print(f\"Agent message: {event.message}\")\n",
    "\n",
    "        elif event.type == \"system\":\n",
    "            print(f\"System event: {event}\")\n",
    "\n",
    "        elif event.type == \"error\":\n",
    "            print(f\"Error event: {event}\")\n",
    "\n",
    "print()\n",
    "print(f\"Messages: {response.messages}\")\n",
    "\n",
    "print()\n",
    "print(f\"Summary: {response.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(response: RunResponseProtocol):\n",
    "    for event in response.events:\n",
    "        print(f\"Event: {event}\")\n",
    "        if event.type == \"input_request\":\n",
    "            print(f\"Input request: {event.prompt}\")\n",
    "            s = input(event.prompt)\n",
    "\n",
    "            print(f\"Response from UI: {s}\")\n",
    "            event.respond(s)\n",
    "\n",
    "        elif event.type == \"input_response\":\n",
    "            # Do nothing, just pass\n",
    "            if event.value != s:\n",
    "                raise RuntimeError(f\"Expected {s}, got {event.value}\")\n",
    "\n",
    "        elif event.type == \"output\":\n",
    "            print(f\"Output message: {event.value}\")\n",
    "\n",
    "        elif event.type == \"agent_message\":\n",
    "            print(f\"Agent message: {event.message}\")\n",
    "\n",
    "        elif event.type == \"system\":\n",
    "            print(f\"System event: {event}\")\n",
    "\n",
    "        elif event.type == \"error\":\n",
    "            print(f\"Error event: {event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single agent run simplest form (no functions, no conversation with the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "agent = ConversableAgent(name=\"Alice\", llm_config=llm_config)\n",
    "\n",
    "response = run(agent, message=\"What is the meaning of life?\", is_termination_message=lambda x: x == \"42\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"thinking about it...\", \"sender\": \"Alice\"}),\n",
    "    AgentMessageEvent(message={\"text\": \"42\", \"sender\": \"Alice\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "response.messages = [\n",
    "    {\"text\": \"thinking about it...\", \"sender\": \"Alice\"},\n",
    "    {\"text\": \"42\", \"sender\": \"Alice\"},\n",
    "]\n",
    "response.summary = \"Alice said the meaning of life is 42\"\n",
    "\n",
    "process_response(response)\n",
    "\n",
    "print()\n",
    "print(f\"Messages: {response.messages}\")\n",
    "\n",
    "print()\n",
    "print(f\"Summary: {response.summary}\")\n",
    "process_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single agent run using functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.tools import tool\n",
    "\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "agent = ConversableAgent(name=\"Alice\", llm_config=llm_config)\n",
    "\n",
    "\n",
    "@tool(description=\"Returns the meaning of life.\")\n",
    "def meaning_of_life():\n",
    "    return \"42\"\n",
    "\n",
    "\n",
    "meaning_of_life.register_tool(agent)\n",
    "# agent.register_tool(meaning_of_life) # Alternative implementation\n",
    "\n",
    "response = run(agent, message=\"What is the meaning of life?\", is_termination_message=lambda x: x == \"42\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"thinking about it...\", \"sender\": \"Alice\"}),\n",
    "    SystemEvent(value=\"Alice called meaning_of_life\"),  # Replace WithFunctionCallEvent subclass of AgentMessageEvent\n",
    "    SystemEvent(value=\"meaning_of_life returned 42\"),\n",
    "    AgentMessageEvent(message={\"text\": \"42\", \"sender\": \"Alice\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "response.messages = [\n",
    "    {\"text\": \"thinking about it...\", \"sender\": \"Alice\"},\n",
    "    {\"text\": \"42\", \"sender\": \"Alice\"},\n",
    "]\n",
    "response.summary = \"Alice said the meaning of life is 42\"\n",
    "\n",
    "process_response(response)\n",
    "\n",
    "print()\n",
    "print(f\"Messages: {response.messages}\")\n",
    "\n",
    "print()\n",
    "print(f\"Summary: {response.summary}\")\n",
    "process_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat between two comedian agents\n",
    "\n",
    "# 1. Import our agent class\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# 2. Define our LLM configuration for OpenAI's GPT-4o mini,\n",
    "#    uses the OPENAI_API_KEY environment variable\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "# 3. Create our agents who will tell each other jokes,\n",
    "#    with Jack ending the chat when Emma says FINISH\n",
    "jack = ConversableAgent(\n",
    "    \"Jack\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=(\"Your name is Jack and you are a comedian in a two-person comedy show.\"),\n",
    "    is_termination_msg=lambda x: True if \"FINISH\" in x[\"text\"] else False,\n",
    ")\n",
    "emma = ConversableAgent(\n",
    "    \"Emma\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=(\n",
    "        \"Your name is Emma and you are a comedian \"\n",
    "        \"in a two-person comedy show. Say the word FINISH \"\n",
    "        \"ONLY AFTER you've heard 2 of Jack's jokes.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = run(jack, emma, message=\"Tell me a joke.\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"What do you call a fake noodle? An impasta.\", \"sender\": \"Jack\"}),\n",
    "    AgentMessageEvent(\n",
    "        message={\"text\": \"Haha, nice one! What do you call a belt made of watches? A waist of time.\", \"sender\": \"Emma\"}\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\"text\": \"Why couldn't the bicycle stand up by itself? It was two tired.\", \"sender\": \"Jack\"}\n",
    "    ),\n",
    "    AgentMessageEvent(message={\"text\": \"FINISH\", \"sender\": \"Emma\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"What do you call a fake noodle? An impasta.\", \"sender\": \"Jack\"},\n",
    "    {\"text\": \"Haha, nice one! What do you call a belt made of watches? A waist of time.\", \"sender\": \"Emma\"},\n",
    "    {\"text\": \"Why couldn't the bicycle stand up by itself? It was two tired.\", \"sender\": \"Jack\"},\n",
    "    {\"text\": \"FINISH\", \"sender\": \"Emma\"},\n",
    "]\n",
    "\n",
    "response.summary = \"Jack and Emma had a comedy chat.\"\n",
    "\n",
    "process_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "# Planner agent setup\n",
    "planner_message = \"Create lesson plans for 4th grade.\"\n",
    "planner = ConversableAgent(\n",
    "    name=\"planner_agent\", llm_config=llm_config, system_message=planner_message, description=\"Creates lesson plans\"\n",
    ")\n",
    "\n",
    "# Reviewer agent setup\n",
    "reviewer_message = \"Review lesson plans against 4th grade curriculum. Provide max 3 changes.\"\n",
    "reviewer = ConversableAgent(\n",
    "    name=\"reviewer_agent\", llm_config=llm_config, system_message=reviewer_message, description=\"Reviews lesson plans\"\n",
    ")\n",
    "\n",
    "# Teacher agent setup\n",
    "teacher_message = \"Choose topics and work with planner and reviewer. Say DONE! when finished.\"\n",
    "teacher = ConversableAgent(\n",
    "    name=\"teacher_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=teacher_message,\n",
    ")\n",
    "\n",
    "groupchat = GroupChat(agents=[teacher, planner, reviewer], speaker_selection_method=\"auto\", messages=[])\n",
    "\n",
    "# Create manager\n",
    "# At each turn, the manager will check if the message contains DONE! and end the chat if so\n",
    "# Otherwise, it will select the next appropriate agent using its LLM\n",
    "manager = GroupChatManager(\n",
    "    name=\"group_manager\",\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: \"DONE!\" in (x.get(\"content\", \"\") or \"\").upper(),\n",
    ")\n",
    "\n",
    "\n",
    "class NewGroupChatManager(GroupChatManager):\n",
    "    def __init__(self, is_termination_msg, llm_config):\n",
    "        self._is_termination_msg = is_termination_msg\n",
    "        self._llm_config = llm_config\n",
    "\n",
    "\n",
    "response = run(planner, reviewer, teacher, message=\"Create lesson plans for 4th grade.\", chat_manager=manager)\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\",\n",
    "            \"sender\": \"planner_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"I would change the addition and subtraction with multiplication and division.\",\n",
    "            \"sender\": \"reviewer_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "            \"sender\": \"planner_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "            \"sender\": \"teacher_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(message={\"text\": \"DONE!\", \"sender\": \"teacher_agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"},\n",
    "    {\n",
    "        \"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\",\n",
    "        \"sender\": \"planner_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I would change the addition and subtraction with multiplication and division.\",\n",
    "        \"sender\": \"reviewer_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "        \"sender\": \"planner_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "        \"sender\": \"teacher_agent\",\n",
    "    },\n",
    "    {\"text\": \"DONE!\", \"sender\": \"teacher_agent\"},\n",
    "]\n",
    "\n",
    "response.summary = \"planner_agent, reviewer_agent, and teacher_agent had a chat.\"\n",
    "\n",
    "process_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "\n",
    "class NewGroupChatManager(GroupChatManager):\n",
    "    def __init__(self, is_termination_msg, llm_config):\n",
    "        self._is_termination_msg = is_termination_msg\n",
    "        self._llm_config = llm_config\n",
    "\n",
    "\n",
    "llm_config = LLMConfig({\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"})\n",
    "\n",
    "\n",
    "@tool\n",
    "def submit_plan(plan: str) -> str:\n",
    "    return f\"Plan submitted: {plan}\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    planner = ConversableAgent(\"You are a planner. Collaborate with teacher and reviewer to create lesson plans.\")\n",
    "\n",
    "    reviewer = ConversableAgent(\n",
    "        \"You are a reviewer. Review lesson plans against 4th grade curriculum. Provide max 3 changes.\"\n",
    "    )\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        \"You are a teacher. Choose topics and work with planner and reviewer. Say DONE! when finished.\",\n",
    "    )\n",
    "    teacher.add_tool(submit_plan)\n",
    "\n",
    "    chat_manager = NewGroupChatManager(terminate_on=Keyword(\"DONE!\"))\n",
    "\n",
    "response = run(\n",
    "    planner,\n",
    "    reviewer,\n",
    "    teacher,\n",
    "    message=\"Create lesson plans for 4th grade.\",\n",
    "    chat_manager=chat_manager,\n",
    ")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\",\n",
    "            \"sender\": \"planner_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"I would change the addition and subtraction with multiplication and division.\",\n",
    "            \"sender\": \"reviewer_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "            \"sender\": \"planner_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "            \"sender\": \"teacher_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(message={\"text\": \"DONE!\", \"sender\": \"teacher_agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"},\n",
    "    {\n",
    "        \"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\",\n",
    "        \"sender\": \"planner_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I would change the addition and subtraction with multiplication and division.\",\n",
    "        \"sender\": \"reviewer_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "        \"sender\": \"planner_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "        \"sender\": \"teacher_agent\",\n",
    "    },\n",
    "    {\"text\": \"DONE!\", \"sender\": \"teacher_agent\"},\n",
    "]\n",
    "\n",
    "response.summary = \"planner_agent, reviewer_agent, and teacher_agent had a chat.\"\n",
    "\n",
    "process_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "llm_config = {\"api_type\": \"openai\", \"model\": \"gpt-4o-mini\"}\n",
    "\n",
    "# Planner agent setup\n",
    "planner_message = \"Create lesson plans for 4th grade.\"\n",
    "planner = ConversableAgent(\n",
    "    name=\"planner_agent\", llm_config=llm_config, system_message=planner_message, description=\"Creates lesson plans\"\n",
    ")\n",
    "\n",
    "# Reviewer agent setup\n",
    "reviewer_message = \"Review lesson plans against 4th grade curriculum. Provide max 3 changes.\"\n",
    "reviewer = ConversableAgent(\n",
    "    name=\"reviewer_agent\", llm_config=llm_config, system_message=reviewer_message, description=\"Reviews lesson plans\"\n",
    ")\n",
    "\n",
    "# Teacher agent setup\n",
    "teacher_message = \"Choose topics and work with planner and reviewer. Say DONE! when finished.\"\n",
    "teacher = ConversableAgent(\n",
    "    name=\"teacher_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=teacher_message,\n",
    ")\n",
    "\n",
    "response = run(\n",
    "    planner,\n",
    "    reviewer,\n",
    "    teacher,\n",
    "    message=\"Create lesson plans for 4th grade.\",\n",
    "    chat_manager=RoundRobinChatManager([planner, reviewer, teacher]),\n",
    ")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "\n",
    "response.events = [\n",
    "    AgentMessageEvent(message={\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"}),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\",\n",
    "            \"sender\": \"planner_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"I would change the addition and subtraction with multiplication and division.\",\n",
    "            \"sender\": \"reviewer_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "            \"sender\": \"planner_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(\n",
    "        message={\n",
    "            \"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "            \"sender\": \"teacher_agent\",\n",
    "        }\n",
    "    ),\n",
    "    AgentMessageEvent(message={\"text\": \"DONE!\", \"sender\": \"teacher_agent\"}),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"Create lesson plans for 4th grade.\", \"sender\": \"planner_agent\"},\n",
    "    {\n",
    "        \"text\": \"Plan is: Math, Learn addition and subtraction, Script: Teach addition and subtraction using examples.\",\n",
    "        \"sender\": \"planner_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I would change the addition and subtraction with multiplication and division.\",\n",
    "        \"sender\": \"reviewer_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Plan is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "        \"sender\": \"planner_agent\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Okay first lesson is: Math, Learn multiplication and division, Script: Teach multiplication and division using examples.\",\n",
    "        \"sender\": \"teacher_agent\",\n",
    "    },\n",
    "    {\"text\": \"DONE!\", \"sender\": \"teacher_agent\"},\n",
    "]\n",
    "\n",
    "response.summary = \"planner_agent, reviewer_agent, and teacher_agent had a chat.\"\n",
    "\n",
    "process_run_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent = ConversableAgent(name=\"Sales Agent\", llm_config=llm_config)\n",
    "complaints_agent = ConversableAgent(name=\"Complaints Agent\", llm_config=llm_config)\n",
    "\n",
    "triage_agent = ConversableAgent(name=\"Triage Agent\", llm_config=llm_config)\n",
    "\n",
    "\n",
    "@triage_agent.register_for_llm()\n",
    "def transfer_to_sales():\n",
    "    return sales_agent\n",
    "\n",
    "\n",
    "@triage_agent.register_for_llm()\n",
    "def transfer_to_complaints():\n",
    "    return complaints_agent\n",
    "\n",
    "\n",
    "response = run(triage_agent, message=\"I have a complaint about my order.\")\n",
    "\n",
    "# mocking response\n",
    "response = MagicMock(spec=RunResponseProtocol)\n",
    "response.events = [\n",
    "    SystemEvent(value=\"Triage Agent called transfer_to_complaints\"),\n",
    "    SystemEvent(value=\"transfer_to_complaints returned Complaints Agent\"),\n",
    "    InputRequestEvent(prompt=\"Hi what is your complaint?\"),\n",
    "    InputResponseEvent(value=\"My order was late.\"),\n",
    "    AgentMessageEvent(\n",
    "        message={\"text\": \"I'm sorry to hear that. We will make the order faster.\", \"sender\": \"Complaints Agent\"}\n",
    "    ),\n",
    "    SystemEvent(value=\"done\"),\n",
    "]\n",
    "\n",
    "response.messages = [\n",
    "    {\"text\": \"I'm sorry to hear that. We will make the order faster.\", \"sender\": \"Complaints Agent\"},\n",
    "]\n",
    "response.summary = \"Complaints Agent apologized for the late order.\"\n",
    "\n",
    "with unittest.mock.patch(\"builtins.input\", return_value=\"My order was late.\"):\n",
    "    process_run_response(response, SimpleEventProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.11-document-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
