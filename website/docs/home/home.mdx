---
title: "Key Features"
mode: "wide"
---

<div class="homepage-hero-section">
  <div class="hero-content">
    <div class="hero-logo-section">
      <img class="hero-logo" noZoom src="../../assets/img/ag2.svg" alt="AG2 Logo" />
    </div>
    <div class="hero-text-section">
      <h2 class="hero-title">Open-Source AgentOS for AI Agents</h2>
      <p class="hero-subtitle">Build production-ready multi-agent systems in minutes, not months.</p>
    </div>
  </div>
</div>

<p align="center">
  <img src="https://img.shields.io/pypi/dm/pyautogen?label=PyPI%20downloads">
  <a href="https://badge.fury.io/py/autogen"><img src="https://badge.fury.io/py/autogen.svg"></a>
  <a href="https://github.com/ag2ai/ag2/actions/workflows/python-package.yml">
    <img src="https://github.com/ag2ai/ag2/actions/workflows/python-package.yml/badge.svg">
  </a>
  <img src="https://img.shields.io/badge/3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12-blue">
  <a href="https://discord.gg/pAbnFJrkgZ">
    <img src="https://img.shields.io/discord/1153072414184452236?logo=discord&style=flat">
  </a>
</p>

AG2 (formerly AutoGen) is an open-source framework for building AI agents and enabling multi-agent collaboration to solve tasks. It supports various LLMs, tool use, autonomous and human-in-the-loop workflows, and multi-agent conversation patterns, streamlining agentic AI development and research.

## Key Features

<div class="key-features">
    <CardGroup cols={3}>
        <Card>
            <div class="key-feature">
                <img noZoom src="/static/img/conv_2.svg" alt="Multi-Agent Conversation Framework" />
                <b>Multi-Agent Conversation Framework</b>
                <p>AG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.</p>
            </div>
        </Card>
        <Card>
            <div class="key-feature">
                <img noZoom src="/static/img/autogen_app.svg" alt='Easily Build Diverse Applications' />
                <b>Easily Build Diverse Applications</b>
                <p>AG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.</p>
            </div>
        </Card>
        <Card>
            <div class="key-feature">
                <img noZoom src="/static/img/extend.svg" alt='Enhanced LLM Inference & Optimization' />
                <b>Enhanced LLM Inference & Optimization</b>
                <p>AG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.</p>
            </div>
        </Card>
    </CardGroup>
</div>


## Getting Started with AG2

This guide will help you set up AG2 and implement your first multi-agent workflow.

### Setting Up Your Environment

<Tip>
We recommended using a virtual environment for your project to keep your packages contained. See <a href="https://docs.python.org/3/library/venv.html" target="_blank">venv</a>.
</Tip>

#### Installation

AG2 requires **Python version >= 3.9, < 3.14**. Install AG2 with OpenAI integration using pip:

```bash
pip install ag2[openai]
```

The package is available under `ag2`, `pyautogen`, or `autogen` names. The default installation includes minimal dependencies, you can add extra options based on your specific requirements.

<Warning>
**From version 0.8**: The OpenAI package, `openai`, is not installed by default.

Install AG2 with your preferred model provider(s), for example:
- `pip install ag2[openai]`
- `pip install ag2[gemini]`
- `pip install ag2[anthropic,cohere,mistral]`

On Mac OS, if you get "no matches found:", add a quote to the package name, for example:
- `pip install "ag2[openai]"`
</Warning>

### API Key Configuration

To keep your LLM dependencies neat we recommend using the `OAI_CONFIG_LIST` file to store your API keys.

Create a file named `OAI_CONFIG_LIST` in your project working directory with the below structure. Replace the `<your OpenAI API key here>` with your actual OpenAI API key and the model with the one you want to use.

```bash

```json
[
  {
    "model": "gpt-4o",
    "api_key": "<your OpenAI API key here>"
  }
]
```

### Implementing Your First Agent Workflow

The following example demonstrates a fundamental use case of the AG2 framework - creating a collaborative multi-agent system to solve a task.

Create a Python script or Jupyter Notebook with the following code:

```python
from autogen import AssistantAgent, UserProxyAgent, LLMConfig

llm_config = LLMConfig.from_json(path="OAI_CONFIG_LIST")


with llm_config:
    assistant = AssistantAgent("assistant")

user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding", "use_docker": False})

user_proxy.initiate_chat(assistant, message="Plot a chart of NVDA and TESLA stock price change YTD.")
```

This code creates two agents:

1. An `AssistantAgent` that leverages the configured LLM to generate responses
2. A `UserProxyAgent` that can execute code in a specified directory

When executed, these agents will interact to solve the given task, with the assistant generating code and the user proxy executing it.

### Running the Example

To run the example, execute the script or notebook. The agents will communicate and work together to complete the task.

#### Python Script:

```shell
# 1. Save the code to a file (e.g., first_agent.py)
# 2. Run the script
python first_agent.py
```

#### Jupyter Notebook:

- Create a new notebook cell and paste the code
- Execute the cell

When the code runs, you'll see the agents exchange messages and collaborate to create the requested stock comparison chart.

## Core Agent Concepts

AG2 provides several foundational agent types and interaction patterns to build sophisticated AI systems. Here are the key concepts:

- **Conversable Agent:** The fundamental building block that can send messages, receive messages, and generate responses using GenAI models, external tools, or human input.
- **Human in the Loop:** Seamlessly integrate human judgment and expertise into agent workflows, allowing for oversight, guidance, and collaboration at critical decision points.
- **Orchestrating Multiple Agents:** Coordinate complex agent interactions through built-in patterns like swarms, group chats, nested conversations, and sequential workflows—or create custom orchestration by registering specialized reply methods.
- **Tools:** Extend agent capabilities by registering external programs and APIs that agents can invoke and execute to access specialized functionality or data.

### Conversable agent

The ConversableAgent is the fundamental building block of AG2, designed to enable seamless communication between AI entities. This core agent type handles message exchange and response generation, serving as the base class for all agents in the framework.

In the example below, we'll create a simple information validation workflow with two specialized agents that communicate with each other:

```python
from autogen import ConversableAgent

with llm_config:
  # Create an AI agent
  assistant = ConversableAgent(
      name="assistant",
      system_message="You are an assistant that responds concisely.",
  )

  # Create another AI agent
  fact_checker = ConversableAgent(
      name="fact_checker",
      system_message="You are a fact-checking assistant.",
  )

# Start the conversation
assistant.initiate_chat(
    recipient=fact_checker,
    message="What is AG2?",
    max_turns=2
)
```

When you run this code, you'll see a simple fact-checking interaction in action. The assistant agent initiates the conversation by asking "What is AG2?", and the fact-checker agent responds with verified information about the AG2 framework.

### Human in the loop

Human oversight is crucial for many AI workflows, especially when dealing with critical decisions, creative tasks, or situations requiring expert judgment. AG2 makes integrating human feedback seamless through its human-in-the-loop functionality.
You can configure how and when human input is solicited using the `human_input_mode` parameter:

- `ALWAYS`: Requires human input for every response
- `NEVER`: Operates autonomously without human involvement
- `TERMINATE`: Only requests human input to end conversations

For convenience, AG2 provides the specialized `UserProxyAgent` class that automatically sets `human_input_mode` to `ALWAYS` and supports code execution:

```python
from autogen import ConversableAgent

# Create an AI agent
with llm_config:
  assistant = ConversableAgent(
      name="assistant",
      system_message="You are a helpful assistant.",
  )

# Create a human agent with manual input mode
human = ConversableAgent(
    name="human",
    human_input_mode="ALWAYS"
)
# or
human = UserProxyAgent(name="human", code_execution_config={"work_dir": "coding", "use_docker": False})

# Start the chat
human.initiate_chat(
    recipient=assistant,
    message="Hello! What's 2 + 2?"
)

```

In this example, the human serves as both the conversation initiator and an active participant. You'll be prompted for input at each step, allowing you to guide the assistant, validate its responses, and provide additional context as needed—essential for workflows where human judgment and domain expertise are required.

### Orchestrating multiple agents

AG2 enables sophisticated multi-agent collaboration through flexible orchestration patterns, allowing you to create dynamic systems where specialized agents work together to solve complex problems.

The framework offers both custom orchestration and several built-in collaboration patterns including `GroupChat` and `Swarm`.

Here's how to implement a collaborative team for curriculum development using GroupChat:

```python
from autogen import ConversableAgent, GroupChat, GroupChatManager

# Create AI agents
teacher = ConversableAgent(name="teacher", system_message="You suggest lesson topics.")
planner = ConversableAgent(name="planner", system_message="You create lesson plans.")
reviewer = ConversableAgent(name="reviewer", system_message="You review lesson plans.")

# Create GroupChat
groupchat = GroupChat(agents=[teacher, planner, reviewer], speaker_selection_method="auto")

# Create the GroupChatManager, it will manage the conversation and uses an LLM to select the next agent
manager = GroupChatManager(name="manager", groupchat=groupchat)

# Start the conversation
teacher.initiate_chat(manager, "Create a lesson on photosynthesis.")
```

When executed, this code creates a collaborative system where the teacher initiates by suggesting photosynthesis as a topic, the planner develops a structured lesson plan, and the reviewer evaluates and improves it—all orchestrated by the GroupChatManager that determines which agent should speak next based on the conversation context.

For workflows requiring more structured processes, explore the Swarm pattern in the detailed [documentation](../user-guide/advanced-concepts/conversation-patterns-deep-dive).

### Tools

While large language models excel at generating content and reasoning, they have inherent limitations: they lack real-time data access, can't perform precise calculations reliably, and cannot interact with external systems. Tools overcome these limitations by connecting agents to specialized functions, APIs, and data sources.

With AG2's tool integration, you can:

- Access up-to-date information beyond the model's training data
- Interact with external services and databases
- Execute domain-specific operations with precision

Here's how to implement a date calculation tool:

```python
from datetime import datetime
from typing import Annotated

from autogen import ConversableAgent, register_function

# 1. Our tool, returns the day of the week for a given date
def get_weekday(date_string: Annotated[str, "Format: YYYY-MM-DD"]) -> str:
    date = datetime.strptime(date_string, "%Y-%m-%d")
    return date.strftime("%A")

# 2. Agent for determining whether to run the tool
with llm_config:
  date_agent = ConversableAgent(
      name="date_agent",
      system_message="You get the day of the week for a given date.",
  )

# 3. And an agent for executing the tool
executor_agent = ConversableAgent(
    name="executor_agent",
    human_input_mode="NEVER",
)

# 4. Registers the tool with the agents, the description will be used by the LLM
register_function(
    get_weekday,
    caller=date_agent,
    executor=executor_agent,
    description="Get the day of the week for a given date",
)

# 5. Two-way chat ensures the executor agent follows the suggesting agent
chat_result = executor_agent.initiate_chat(
    recipient=date_agent,
    message="I was born on the 25th of March 1995, what day was it?",
    max_turns=1,
)
```

When executed, this code determines that March 25, 1995, was a Saturday—delivering an accurate response through tool execution rather than relying on the model's potentially outdated or imprecise knowledge. This pattern can be extended to integrate any Python function, API, or external system into your agent workflows.

## Advanced agentic design patterns

AG2 offers sophisticated patterns and capabilities to build production-ready agent systems for complex use cases. These advanced features enable you to create robust, secure, and highly functional agent workflows.

- [Structured Output](../user-guide/basic-concepts/llm-configuration/llm-configuration/structured-outputs)
- [Ending a conversation](../user-guide/basic-concepts/ending-a-chat)
- [Retrieval Augmented Generation (RAG)](../user-guide/advanced-concepts/rag)
- [Code Execution](../user-guide/advanced-concepts/code-execution)
- [Tools with Secrets](../user-guide/basic-concepts/tools/tools-with-secrets)

## Popular resources

We maintain a dedicated repository with a wide range of applications to help you get started with various use cases or check out our collection of jupyter notebooks as a starting point.

- [Build with AG2](https://github.com/ag2ai/build-with-ag2)
- [Jupyter Notebooks](notebook)

<div class="popular-resources">
  <CardGroup cols={2}>
    <Card>
      <div class="youtube-video">
        <iframe
          class="w-full aspect-video rounded-md"
          src="https://www.youtube.com/embed/RLwyXRVvlNk"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen
        ></iframe>
        <a target="_blank" href="https://www.youtube.com/watch?v=RLwyXRVvlNk">
          Foundation Capital Interview with Dr. Chi Wang
        </a>
      </div>
    </Card>
    <Card>
      <div class="youtube-video">
        <iframe
          class="w-full aspect-video rounded-md"
          src="https://www.youtube.com/embed/TBNTH-fwGPE"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen
        ></iframe>
        <a target="_blank" href="https://www.youtube.com/watch?v=TBNTH-fwGPE">
          Learn AG2 on DeepLearningAI
        </a>
      </div>
    </Card>
  </CardGroup>
</div>


## Next Steps
<div class="explore-content">
  <div class="explore-content-grid-container">
    <CardGroup cols={2}>
      <Card title="Concepts" href="../user-guide/basic-concepts/installing-ag2">
        Work through the key concepts of AG2 including ConversableAgent, GroupChat, Swarm, and tools.
      </Card>
      <Card title="Advanced Concepts" href="../user-guide/advanced-concepts/rag">
        Advance to RAG, Code Execution, and more complex GroupChats and Swarms.
      </Card>
      <Card title="Use Cases" href="../use-cases/use-cases/">
        Try out use case workflows including Customer Service, Travel Planning, and Game Design.
      </Card>
      <Card title="Notebook Examples" href="../use-cases/notebooks/Notebooks">
        A collection of interactive notebooks across all AG2 topics.
      </Card>
      <Card title="API Reference" href="../api-reference/autogen">
        Delve into the AG2 API reference.
      </Card>
      <Card title="How to Contribute" href="../contributor-guide/contributing">
        Get involved with AG2 by adding what you need and making the framework even better!
      </Card>
    </CardGroup>
  </div>
</div>
