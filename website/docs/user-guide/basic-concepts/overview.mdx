---
title: Overview
sidebarTitle: Overview
---

Before diving into details, let's explore the core building blocks of AG2. Understanding these concepts will help you build dynamic, multi-agent AI systems that communicate, collaborate, and solve problems.

## Basic Concepts

Here are the basic concepts you'll need to get started.

### LLM Configuration

The LLM Configuration defines the language model intelligence that powers your agents. It's the first element you should configure when building with AG2, as it determines how your agents will think and reason.

LLM Configuration controls how an agent:

- Connects to and authenticates with language model providers
- Selects models and sets parameters
- Thinks, reasons, and generates responses

[Learn more about LLM Configuration →](../llm-configuration/llm-configuration)

### ConversableAgent

The [`ConversableAgent`](../../../api-reference/autogen/ConversableAgent) is the core building block of AG2 — a smart, interactive agent that uses your configured LLM to process information and interact with other agents or humans. With a properly configured LLM, your agents can:

- Communicating with other agents and humans
- Processing information using Large Language Models (LLMs)
- Making decisions based on its defined purpose
- Executing tools and functions when needed

[Learn more about ConversableAgent →](../conversable-agent)

### Human in the Loop (HITL)

Human in the Loop (HITL) brings human oversight into your agent workflows, allowing agents to request input at crucial decision points. This capability:

- Enables agents to seek approval before taking critical actions
- Presents options for human selection
- Integrates feedback into the decision-making process
- Balances automation with human judgment

[Learn more about Human in the Loop →](../human-in-the-loop)

### Agent Orchestration

Agent Orchestration defines patterns for connecting multiple agents, allowing them to work together in various configurations:

- Two-agent conversations
- Sequential conversations that chain multiple dialogues
- Group collaborations with multiple specialized agents
- Reusable nested workflows
- Specialized swarms of agents

This orchestration enables you to build rich, collaborative, multi-agent applications. [Learn more about Agent Orchestration →](../orchestration/orchestrations)

### Tools

The tools extend an agent’s capabilities beyond text conversations, enabling them to:

- Connect with external APIs and services
- Perform calculations and data processing
- Access and work with files, databases, or other systems
- Execute code in various programming languages

[Learn more about Tools →](../tools/basics)

### Structured Outputs

Structured Outputs ensure agents return well-defined, consistent, and validated responses using Pydantic models. This allows you to:

- Define structured response formats
- Guarantee consistent data structures
- Simplify downstream processing and application integration
- Ensure responses are complete and reliable

[Learn more about Structured Outputs →](../llm-configuration/structured-outputs)


### Ending Conversations
Understanding how to properly end conversations between agents is crucial for building efficient workflows. AG2 provides multiple ways to terminate conversations:

- Setting maximum turns or rounds
- Defining termination conditions in messages
- Limiting automatic replies
- Human intervention with 'exit' command
- Using custom reply functions

[Learn more about Ending Conversations →](../llm-configuration/structured-outputs)

## How These Concepts Work Together

In a typical AG2 application, these components work together in the following sequence:

1. Start by creating the right **LLM Configuration** for your needs
2. Create one or more **ConversableAgents** powered by this configuration
3. Connect them using **Agent Orchestration** patterns
4. Optionally, add **Human in the Loop** oversight to enhance decision-making
5. Optionally, extend their functionality with **Tools**
6. Optionally, define **Structured Outputs** for clean, reusable data
7. Implement appropriate methods for **Ending Conversations**

The workflow is illustrated below:

``` mermaid
flowchart TD
    classDef agent fill:#f9f9ff,stroke:#333,stroke-width:2px
    classDef config fill:#e6f7ff,stroke:#333,stroke-width:1px
    classDef patterns fill:#f0f7ff,stroke:#333,stroke-width:1px
    classDef extensions fill:#fff7e6,stroke:#333,stroke-width:1px
    classDef optional fill:#f0e6ff,stroke:#333,stroke-width:1px,stroke-dasharray: 5 5

    B[LLM Configuration] --> A[ConversableAgent]
    A -.-> C[Human in the Loop]
    A --> D[Agent Orchestration]
    A -.-> E[Tools]
    B -.-> F[Structured Outputs]
    A -.-> G[Ending Conversations]

    subgraph Agent
        A
    end

    subgraph Configuration
        B
        F
    end

    subgraph Patterns
        D
        C
        G
    end

    subgraph Extensions
        E
    end

    class A agent
    class B config
    class C,E,F,G optional
    class D patterns
    class E extensions
```

Together, these core concepts allow you to build powerful, flexible AI systems — from simple agents to collaborative, multi-agent workflows — with or without human supervision.

## Financial Compliance Example

Throughout the following sections, we'll use a financial compliance assistant example to illustrate these concepts in action. This example demonstrates how different components work together to create a functional agent system that:

- Uses LLMs to analyze financial transactions
- Reviews transactions for compliance issues
- Flags suspicious transactions for human review
- Provides summary reports of transaction status

Each section will build upon this example, showing how that specific concept applies to building our financial compliance system.

**Next up**: Dive deeper into each of these components, starting with [LLM Configuration](/docs/user-guide/basic-concepts/llm-configuration/llm-configuration) — the foundation for all AG2 agents.
