---
title: Overview
sidebarTitle: Overview
---

### Understanding Tool Usage in AG2

Agents significantly enhance their capabilities by leveraging tools, which provide access to external data, APIs, and additional functionality.

In **AG2**, tool usage happens in two stages:

- An agent suggests which tool to use (via its LLM).
- Another agent executes the selected tool.

Typically, you'll create two agents. One to determine the appropriate tool and another to carry out the execution.

<Note>In a conversation, the executor agent must always follow the agent that suggests a tool.</Note>

### Example: Implementing a Date Tool

import Example from "/snippets/python-examples/toolregister.mdx";

<Example/>

1. We define a tool, a function that will be attached to our agents. The `Annotated` parameter is included in the LLM call to ensure it understands the purpose of `date_string`.

2. The `date_agent` decides whether to use the tool based on its LLM reasoning.

3. The `executor_agent` executes the tool and returns the output as its response.

4. We register the tool with the agents and provide a description to help the LLM determine when to use it.

5. Since this is a two-way conversation, the `executor_agent` follows the `date_agent`. If the `date_agent` suggests using the tool, the `executor_agent` executes it accordingly.

    ```console
    executor_agent (to date_agent):

    I was born on the 25th of March 1995, what day was it?

    --------------------------------------------------------------------------------

    >>>>>>>> USING AUTO REPLY...
    date_agent (to executor_agent):

    ***** Suggested tool call (call_iOOZMTCoIVVwMkkSVu04Krj8): get_weekday *****
    Arguments:
    {"date_string":"1995-03-25"}
    ****************************************************************************

    --------------------------------------------------------------------------------

    >>>>>>>> EXECUTING FUNCTION get_weekday...
    Call ID: call_iOOZMTCoIVVwMkkSVu04Krj8
    Input arguments: {'date_string': '1995-03-25'}
    executor_agent (to date_agent):

    ***** Response from calling tool (call_iOOZMTCoIVVwMkkSVu04Krj8) *****
    Saturday
    **********************************************************************

    --------------------------------------------------------------------------------

    >>>>>>>> USING AUTO REPLY...
    date_agent (to executor_agent):

    It was a Saturday.

    --------------------------------------------------------------------------------
    ```

### Alternative Registration Methods

Alternatively, you can use decorators [`register_for_execution`](/docs/api-reference/autogen/ConversableAgent#register-for-execution) and [`register_for_llm`](/docs/api-reference/autogen/ConversableAgent#register-for-llm) to register a tool. So, instead of using [`register_function`](/docs/api-reference/autogen/register_function), you can register them with the function definition.
```python
@date_agent.register_for_llm(description="Get the day of the week for a given date")
@executor_agent.register_for_execution()
def get_weekday(date_string: Annotated[str, "Format: YYYY-MM-DD"]) -> str:
    date = datetime.strptime(date_string, '%Y-%m-%d')
    return date.strftime('%A')
```

### Tool call guardrails

When agents suggest tool calls, you may want to check the **arguments** of those calls (e.g. for safety, policy, or sensitive data) before they are executed. AG2's **Tool call LLM guardrail** inspects the tool name and arguments extracted from agent messages and runs an LLM-based check against a condition you define.

- **As an output guardrail**: It runs when the agent's reply contains `tool_calls`. The guardrail sees the suggested tool name(s) and argument payload(s) and can block or redirect (e.g. via a [transition target](/docs/user-guide/advanced-concepts/orchestration/group-chat/guardrails)) if the condition is met.
- **As an input guardrail**: It runs when the last message in the context contains `tool_calls`, so you can screen tool calls before the next agent acts on them.

You provide a **condition** (e.g. "arguments contain PII or dangerous commands") and an **LLM config**; the guardrail prepends "Here are arguments to a Tool call function." to your condition and uses that to call the LLM. If there are no tool calls in the context, the guardrail does not activate.

Example: register a tool-call guardrail on an assistant in a group chat so that every time the assistant suggests a tool call, its arguments are checked before execution.

```python
from autogen import AssistantAgent, GroupChat, GroupChatManager, UserProxyAgent
from autogen.agentchat.group.guardrails import ToolCallLLMGuardrail
from autogen.agentchat.group.targets.transition_target import StayTarget
from autogen.llm_config import LLMConfig

llm_config = LLMConfig(model="gpt-4o-mini", api_key="...", api_type="openai")

tool_call_guardrail = ToolCallLLMGuardrail(
    name="tool_safety",
    condition="arguments contain harmful or illegal content.",
    target=TransitionTarget(),
    llm_config=llm_config,
)

assistant = AssistantAgent("assistant", llm_config=llm_config)
assistant.register_output_guardrail(tool_call_guardrail)

# Use the assistant in a GroupChat; when it replies with tool_calls, the guardrail runs.
```

For more on guardrail placement (input vs output), targets, and other guardrail types, see [Guardrails](/docs/user-guide/advanced-concepts/orchestration/group-chat/guardrails).

### Client-specific built-in tools

AG2's OpenAI Responses client offers support for the following tools through the `built_in_tools` parameter in `LLMConfig`:

- web_search
- image_generation
- apply_patch


An example of how to use built_in_tools:

```python
import os
from pathlib import Path

from dotenv import load_dotenv

from autogen import ConversableAgent, LLMConfig

load_dotenv()

# configure LLMConfig to use built_in_tools
llm_config = LLMConfig(
    config_list={
        "api_type": "responses",
        "model": "gpt-5.1",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "built_in_tools": ["apply_patch"],
        "workspace_dir": "./my_project_folder",
    },
)

coding_agent = ConversableAgent(
    name="coding_assistant",
    llm_config=llm_config,
    system_message="""You are a helpful coding assistant...""",
)

# Tool is automatically registered! Just use it:
result = coding_agent.initiate_chat(
    recipient=coding_agent,
    message="""
    Create app.py in the workspace directory,
    create a app.yaml file,
    create a app.sh file,
    create a folder /tests,
    create tests/test_app.py
    """,
    max_turns=2,
)
```
