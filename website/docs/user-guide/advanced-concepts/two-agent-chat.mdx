---
title: Two-Agent Chat
---

## Two-Agent Chat and Chat Result

Two-agent chat is the simplest form of conversation pattern.
We start a two-agent chat using the `initiate_chat` method of every `ConversableAgent` agent.

The following figure illustrates how two-agent chat works.

![Two-agent chat](./assets/two-agent-chat.png)

A two-agent chat takes two inputs: a message (which can be a string, a message dictionary, or a list of message dicts provided by the caller), and a context, which specifies various parameters of the chat.

The example below is a two-agent chat between a student agent and a teacher agent. Its summarizer uses an LLM-based summary.

![Two-agent Chat Process](./assets/two_agent_chat.png)


```python
import os

from autogen import ConversableAgent, LLMConfig

llm_config = LLMConfig(config_list={
    "api_type": "openai",
    "model": "gpt-5-nano",
    "api_key": os.environ["OPENAI_API_KEY"],
})

student_agent = ConversableAgent(
    name="Student_Agent",
    system_message="You are a student willing to learn.",
    llm_config=llm_config,
)

teacher_agent = ConversableAgent(
    name="Teacher_Agent",
    system_message="You are a math teacher.",
    llm_config=llm_config,
)

chat_result = student_agent.initiate_chat(
    teacher_agent,
    message="What is triangle inequality?",
    summary_method="reflection_with_llm",
    max_turns=2,
)

print(chat_result.summary)
```

In the above example, the summary method is set to `reflection_with_llm` which takes a list of messages from the conversation and summarizes them using a call to an LLM.

The summary method first tries to use the recipient's LLM, if it is not available then it uses the sender's LLM. In this case the recipient is "Teacher_Agent" and the sender is "Student_Agent".

The input prompt for the LLM is the following default prompt:

```python
print(ConversableAgent.DEFAULT_SUMMARY_PROMPT)
```

You can also use a custom prompt by setting the `summary_prompt` argument of `initiate_chat`.

There are some other useful information in the `ChatResult` object, including the conversation history, human input, and token cost.

```python
# Get the chat history.
import pprint

pprint.pprint(chat_result.chat_history)
```
