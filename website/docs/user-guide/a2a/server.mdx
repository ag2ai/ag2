---
title: "A2A Server Setup"
description: "Learn how to set up and configure A2A agent servers for distributed communication."
---

# A2A Server Setup

The A2A server allows you to expose your AG2 agents as web services that can be accessed by remote clients. This guide covers everything you need to know about setting up and configuring A2A servers.

## Basic Server Setup

```python title="server.py" linenums="1" hl_lines="16-19"
from autogen import ConversableAgent, LLMConfig
from autogen.a2a import A2aAgentServer

# Create your regular agent
llm_config = LLMConfig({ "model": "gpt-4o-mini" })

agent = ConversableAgent(
    name="python_coder",
    system_message="You are an expert Python developer...",
    llm_config=llm_config,
    # set human_input_mode "NEVER" to avoid asking for human input on server side
    human_input_mode="NEVER",
)

# Create A2A server
server = A2aAgentServer(
    agent,
    url="http://0.0.0.0:8000"
).build()
```

Now you can start it using any ASGI server, for example:

```bash
uvicorn server:server --host 0.0.0.0 --port 8000
```

!!! tip
    Do not forget to set `url` parameter to your server URL. It will be used to build public agent card.

## Capabilities

### Remote Tools execution details

AG2 has a great feature - [Tools](/docs/user-guide/advanced-concepts/tools){.internal-link}. Fortunately, our A2A agent executer allows your remote agent execute any tool by itself. So, if your client calls an agent with a tool, this tool will be executed by the remote agent, process results and return them to the client.

```python title="remote.py" linenums="1" hl_lines="21-27"
import os
from datetime import datetime
from typing import Annotated

from autogen import ConversableAgent, LLMConfig
from autogen.a2a import A2aAgentServer
from autogen.agentchat import ReplyResult

llm_config = LLMConfig(
    model="gpt-4o-mini",
    api_key=os.getenv("OPENAI_API_KEY"),
)

agent = ConversableAgent(
    name="calendar_agent",
    llm_config=llm_config,
    human_input_mode="NEVER",
    silent=True,
)

@agent.register_for_llm(name="get_weekday", description="Get the day of the week for a given date")
@agent.register_for_execution(name="get_weekday")
def get_weekday(
    date_string: Annotated[str, "Format: YYYY-MM-DD"],
) -> str:
    date = datetime.strptime(date_string, "%Y-%m-%d")
    return ReplyResult(message=date.strftime("%A"))

app = A2aAgentServer(agent, url="http://0.0.0.0:8000").build()
```

In this way, processing steps are:
1. Remote client calls `A2aAgentServer` agent
2. `A2aAgentServer` agent asks LLM to decide if the tool should be called
3. `A2aAgentServer` agent calls `get_weekday` tool
4. `A2aAgentServer` processes the tool result by LLM
5. `A2aAgentServer` returns the whole local history to the client

Also, remote agents supports another group chat features without any additional configuration.

- [Context Variables](docs/user-guide/advanced-concepts/orchestration/group-chat/context-variables/){.internal-link}
- [Guardrails](docs/user-guide/advanced-concepts/orchestration/group-chat/guardrails/){.internal-link}

Just use these features with your remote `ConversableAgent` agent, wrap it in `A2aAgentServer` and let the magic happen.


### Multiple agents at one server

A2A protocol assumes single agent per server. But because of `A2aAgentServer` is an full-featured ASGI application, you can combine it with another ASGI apps in a way you need. So, you can insert your server to regular FastAPI application or any other ASGI application. Or you can combine multiple agents into one server, separated by paths.

As an example

```python title="remote.py" linenums="1" hl_lines="9 13 17"
from autogen.a2a import A2aAgentServer
from starlette.applications import Starlette
from starlette.routing import Mount

app = Starlette(
    routes=[
        Mount(
            "/triage",
            A2aAgentServer(triage_agent, url="http://0.0.0.0:8000/triage/").build(),
        ),
        Mount(
            "/tech",
            A2aAgentServer(tech_agent, url="http://0.0.0.0:8000/tech/").build(),
        ),
        Mount(
            "/general",
            A2aAgentServer(general_agent, url="http://0.0.0.0:8000/general/").build(),
        ),
    ]
)
```

!!! tip

    Be careful with `A2aAgentServer(..., url="...")` parameter. It will be used to build agent card, so you need to add your path with `/` to the end of the server URL.


So, your clients for such agents will be:

```python title="client.py" linenums="1" hl_lines="4 9 14"
from autogen.a2a import A2aRemoteAgent

triage_agent = A2aRemoteAgent(
    "http://localhost:8000/triage/",
    name="triage_agent",
)

tech_agent = A2aRemoteAgent(
    "http://localhost:8000/tech/",
    name="tech_agent",
)

general_agent = A2aRemoteAgent(
    "http://localhost:8000/general/",
    name="general_agent",
)
```

## Advanced A2A Configuration

Also, AG2 do not limit you with our default implementation. You can specify any parts of the server you need.
This reason we provide a way to use native [A2A python sdk](https://github.com/a2aproject/a2a-python){.external-link target="_blank"} to fully customize your server.

### Agent Card

The Agent Card describes your agent's capabilities and is [automatically discovered by clients](https://a2a-protocol.org/latest/topics/agent-discovery/){.external-link target="_blank"}.

To configure it, you can use `agent_card` and `extended_agent_card` parameters.

* `agent_card` - basic agent card, describes basic capabilities of your agent and is available to all clients
* `extended_agent_card` - extended agent card, for authenticated access with additional capabilities

```python title="server.py" linenums="1" hl_lines="7 11"
from autogen.a2a import A2aAgentServer, CardSettings
from a2a.types import AgentSkill

server = A2aAgentServer(
    agent,
    url="http://0.0.0.0:8000",
    agent_card=CardSettings(
        name="Public Python Coder",
        description="Basic Python coding assistance",
    ),
    extended_agent_card=CardSettings(
        name="Premium Python Coder",
        description="Advanced Python coding with premium features",
        skills=[
            AgentSkill(
                name="advanced_optimization",
                id="opt",
                description="Advanced code optimization techniques",
                tags=["python", "coding", "optimization"],
            )
        ]
    )
).build()
```

!!! note
    By default `A2aAgentServer` uses agent's name and description to build agent card.
    You can override it by passing `agent_card` and `extended_agent_card` parameters.

### Custom Request Handler

For advanced use cases, you can customize the request handling.
It allows you to use your own task store, queue manager, configure push notifications, etc. By default, `A2aAgentServer` uses the simplest `InMemoryTaskStore` to store tasks.

```python title="server.py" linenums="1" hl_lines="7-10"
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore
from autogen.a2a import A2aAgentServer

server = A2aAgentServer(agent)

request_handler = DefaultRequestHandler(
    agent_executor=server.executor,  # use autogen executor
    task_store=InMemoryTaskStore(),
)

app = server.build(request_handler=request_handler)
```

### Custom Server Application

Also, you can use your own server application. For example, `A2AFastAPIApplication` is a FastAPI application that can be used to serve your agent.

```python title="server.py" linenums="1" hl_lines="7-13"
from a2a.server.apps import A2AFastAPIApplication
from autogen import ConversableAgent
from autogen.a2a import A2aAgentServer

server = A2aAgentServer(agent)

app = A2AFastAPIApplication(
    agent_card=server.card,
    extended_agent_card=server.extended_agent_card,
    # use default request handler or
    # your own request handler from the previous example
    http_handler=server.build_request_handler(),
).build()
```

Please refer to [A2A python sdk](https://github.com/a2aproject/a2a-python){.external-link target="_blank"} documentation for more details on how to use it.
