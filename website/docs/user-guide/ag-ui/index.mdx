---
sidebarTitle: AG-UI
title: "AG-UI (Agent-User Interaction) Integration"
description: "Expose AG2 ConversableAgent agents to AG-UI-compatible frontends using AGUIStream."
---

## Overview

The Agent-User Interaction (AG-UI) protocol standardizes how frontend applications communicate with agents.
In AG2, `autogen.ag_ui.AGUIStream` bridges a `ConversableAgent` to AG-UI event streams.

This solves common integration problems:

- Streaming agent output to UI clients
- Emitting tool-call lifecycle events
- Synchronizing shared state snapshots
- Supporting human-in-the-loop checkpoints through frontend actions and input-required flows

For protocol background, see [AG-UI Protocol introduction](https://docs.ag-ui.com/introduction).

## When to use AG-UI vs direct integration

| Approach | Use it when | Trade-offs |
| --- | --- | --- |
| AG-UI integration (`AGUIStream`) | You need streaming UI, tool rendering, shared state sync, and a protocol-compatible client ecosystem | Adds protocol event semantics you need to expose from your endpoint |
| Direct integration (custom REST/WebSocket contract) | You only need a narrow, app-specific API and will own protocol design end-to-end | You must define and maintain your own streaming/tool/state contract |

Use AG-UI when you want a reusable UI contract across clients and frameworks.

## Supported capabilities

Verified in AG2 code/tests:

* [x] Streaming text events (`TEXT_MESSAGE_START`, `TEXT_MESSAGE_CONTENT`, `TEXT_MESSAGE_END`, `TEXT_MESSAGE_CHUNK`)
  Source: `autogen/ag_ui/adapter.py`, `test/ag_ui/test_adapter.py`
* [x] Backend tool lifecycle events (`TOOL_CALL_START`, `TOOL_CALL_ARGS`, `TOOL_CALL_RESULT`, `TOOL_CALL_END`)
  Source: `autogen/ag_ui/adapter.py`, `test/ag_ui/test_adapter.py`
* [x] Frontend-tool dispatch (`TOOL_CALL_CHUNK` for client tools in `RunAgentInput.tools`)
  Source: `autogen/ag_ui/adapter.py`, `test/ag_ui/test_adapter.py`
* [x] Shared-state snapshots (`STATE_SNAPSHOT`) from context and agent state
  Source: `autogen/ag_ui/adapter.py`, `test/ag_ui/test_adapter.py`
* [x] Human input checkpoints (`input_required` surfaced as user-visible message events)
  Source: `autogen/ag_ui/adapter.py`
* [x] ASGI endpoint generation via `build_asgi()` for Starlette/FastAPI apps
  Source: `autogen/ag_ui/asgi.py`, `test/ag_ui/test_asgi.py`

## Architecture

Transport: request/response HTTP with streamed AG-UI events (default `text/event-stream`).

```text
AG-UI client
  -> POST /chat (RunAgentInput)
  -> AGUIStream.dispatch(...)
  -> AgentService(ConversableAgent + tools)
  -> AG-UI events (SSE-encoded stream)
  -> UI renders text, tools, and state
```

`AGUIStream` merges three state inputs before execution: agent context variables, frontend `incoming.state`, and server-provided `context`.

## Framework to AG-UI mapping

| AG2 runtime concept | AG-UI semantics |
| --- | --- |
| Agent run starts/finishes | `RUN_STARTED`, `RUN_FINISHED` |
| Streaming assistant output | `TEXT_MESSAGE_START` + `TEXT_MESSAGE_CONTENT` + `TEXT_MESSAGE_END` |
| Non-streamed assistant output | `TEXT_MESSAGE_CHUNK` |
| Backend Python tool call | `TOOL_CALL_START` + `TOOL_CALL_ARGS` + `TOOL_CALL_RESULT` + `TOOL_CALL_END` |
| Frontend tool request | `TOOL_CALL_CHUNK` |
| Context/state synchronization | `STATE_SNAPSHOT` |
| Human input required from agent flow | user-visible message event from `input_required` |

## Installation

Install AG2 with AG-UI support:

```bash
pip install "ag2[ag-ui]"
```

Compatibility note: the `ag-ui` extra pins `ag-ui-protocol>=0.1.10,<0.2` in this repository (`pyproject.toml`).

## Minimal server example

Use the manual-dispatch pattern when you want full control over auth, logging, and middleware:

```python title="run_ag_ui.py" linenums="1" hl_lines="13 16-24"
from fastapi import FastAPI, Header
from fastapi.responses import StreamingResponse

from autogen import ConversableAgent, LLMConfig
from autogen.ag_ui import AGUIStream, RunAgentInput

agent = ConversableAgent(
    name="support_bot",
    system_message="You help users with billing questions.",
    llm_config=LLMConfig({"model": "gpt-4o-mini"}),
)

stream = AGUIStream(agent)
app = FastAPI()


@app.post("/chat")
async def run_agent(
    message: RunAgentInput,
    accept: str | None = Header(None),
) -> StreamingResponse:
    return StreamingResponse(
        stream.dispatch(message, accept=accept),
        media_type=accept or "text/event-stream",
    )
```

Run it:

```bash
uvicorn run_ag_ui:app --reload --port 8000
```

### Test the endpoint

```bash
curl -N -X POST http://127.0.0.1:8000/chat \
  -H "Content-Type: application/json" \
  -H "Accept: text/event-stream" \
  -d '{
    "thread_id": "thread-1",
    "run_id": "run-1",
    "messages": [{"id": "m1", "role": "user", "content": "Hello"}],
    "state": {},
    "context": [],
    "tools": []
  }'
```

Example stream (truncated):

```text
data: {"type":"RUN_STARTED","threadId":"thread-1","runId":"run-1",...}
data: {"type":"TEXT_MESSAGE_CHUNK","delta":"Hello! How can I help?",...}
data: {"type":"RUN_FINISHED","threadId":"thread-1","runId":"run-1",...}
```

## UI clients

Any AG-UI client works with this endpoint.

For React/Next.js UIs, CopilotKit is the recommended client path in AG2 docs because it provides:

- Streaming chat components
- Tool UI rendering hooks/components
- Shared state patterns for interactive workflows

Start from the [CopilotKit UI quickstart](./copilotkit-quickstart).

## Next steps

1. Build the AG-UI endpoint from the minimal example above.
2. Follow the [CopilotKit UI quickstart](./copilotkit-quickstart) to connect a React/Next.js client.
