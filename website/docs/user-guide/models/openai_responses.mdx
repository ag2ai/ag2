---
title: OpenAI Responses API
sidebarTitle: OpenAI Responses
---

[OpenAI](https://openai.com/)'s Responses API represents a significant evolution from the Chat Completions and Assistants APIs, offering support for both stateless interactions and structured, stateful conversations. 

Additionally, it includes built-in tools for web search, file search, and computer use. The robust multimodal capabilities of the API also set it apart and will be utilized in our initial support for this API. [See their website for further details](https://platform.openai.com/docs/api-reference/responses).

<Warning>
There are two main OpenAI client interfaces:

- **Legacy** (`api_type: "responses"`): supports OpenAI's legacy /responses endpoint with some feature limitations.
- **Recommended** (`api_type: "openai_v2"`): supports the next-generation OpenAIResponsesClient with full UnifiedResponse, group chat, rich multimodal, and compatibility with `run()` and pattern-based workflows.

We now recommend using the `openai_v2` client for all new applications. See examples below for configuration.
</Warning>

## Installation

``` bash
pip install ag2[openai]
```

<Tip>
If you have been using `autogen` or `ag2`, all you need to do is upgrade it using:
```bash
pip install -U autogen[openai]
```
or
```bash
pip install -U ag2[openai]
```
as `autogen` and `ag2` are aliases for the same PyPI package.
</Tip>

## LLM Configurations

See the [LLM Configuration](/docs/user-guide/basic-concepts/llm-configuration) for further details on setting and creating an LLM configuration.

### Using the New `openai_v2` Client (Recommended)

Set `api_type` to `openai_v2` to activate the next-generation OpenAI V2 client, which supports group chat, the `run()` API, full multimodal images, and rich UnifiedResponse content:

```python
[
    {
        "api_type": "openai_v2",  # use OpenAI V2 client
        "model": "gpt-4o-mini",   # or "o1-preview", "o3-mini", etc. (vision and reasoning models)
        "api_key": "your OpenAI Key goes here",
        # optional: other model or API parameters
    }
]
```

- This client works with all autogen/AG2 agent workflows, including:
    - two-agent chat (`initiate_chat`) and multi-agent group chat
    - the modern `run()` interface
    - pattern-based group orchestrations
- It returns rich UnifiedResponse objects (see the [notebook example](https://github.com/microsoft/autogen/tree/main/notebook/agentchat_openai_v2_client_image.ipynb)), supporting typed content blocks (reasoning, citations, thinking, tool calls, and forward-compatible content types).

### Using the Legacy `responses` API (For Reference)

As before, you may use the legacy `/responses` endpoint by setting `api_type` to `responses`:

```python
[
    {
        "api_type": "responses", # legacy OpenAI Responses API
        "model": "gpt-5",
        "api_key": "your OpenAI Key goes here",

        # Optional: use image_generation and web_search built-in tools
        # See https://platform.openai.com/docs/guides/images-vision?api-mode=responses
        "built_in_tools": ["image_generation", "web_search"],
    }
]
```

### Environment Variable for API Key

As an alternative to including your API key in the config, you can set the environment variable `OPENAI_API_KEY` as usual:

Linux/Mac:
``` bash
export OPENAI_API_KEY="your_openai_api_key_here"
```

Windows:
``` bash
set OPENAI_API_KEY=your_openai_api_key_here
```

## Feature Support Matrix

| Feature                                       | `openai_v2` (Recommended) | Legacy `responses` |
|----------------------------------------------- |:-------------------------:|:------------------:|
| Group chat                                    |        ✅ Yes              |   ❌               |
| Modern run() API / pattern-based orchestration |        ✅ Yes              |   ❌               |
| Rich multimodal content (images, vision)       |        ✅ Yes              |   ⚠ partial        |
| Reasoning, thinking blocks                     |        ✅ Yes              |   ⚠ partial        |
| Typed UnifiedResponse                         |        ✅ Yes              |   ❌               |
| Forward compatibility (future types)           |        ✅ Yes              |   ❌               |
| Backward compatibility                        |        ✅ Yes              |   ⚠ some           |

See the examples in the [Notebook section](/docs/use-cases/notebooks/Notebooks/?tags=responses) of the documentation for how to use both clients, with an emphasis on the V2 client for new and advanced workflows.

<Migrate>
**Migrating from 'responses' to 'openai_v2':**
- Simply change `"api_type": "responses"` to `"api_type": "openai_v2"` in your config.
- All functionality will remain, but you'll gain support for modern features and richer agent behaviors.
</Migrate>

  