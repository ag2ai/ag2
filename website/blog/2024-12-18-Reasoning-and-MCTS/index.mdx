---
title: MCTS vs Beam Search in Reasoning Agent to Help LLM Post-Training
authors:
  - BabyCNM
  - Hk669
  - sonichi
  - qingyunwu
tags: [LLM, GPT, research]
---

![Tree of Thoughts](img/reasoningagent_1.png)

**TL;DR:**
* We introduce Monte Carlo Tree Search (MCTS) as an alternative to Beam Search in ReasoningAgent
* MCTS is particularly effective when ground truth evaluation is available or when LLM-based evaluation is expensive
* We provide detailed complexity analysis and comparison between MCTS and Beam Search approaches
* The resulting search trees can be used to generate high-quality training datasets for LLM fine-tuning.

## Introduction

In our [previous post](/blog/2024-12-02-ReasoningAgent2), we introduced the ReasoningAgent with Beam Search for systematic reasoning.
Our reasoning agent is inspired by OpenAI's 2023 paper [Let's Verify Step by Step](https://arxiv.org/pdf/2305.20050) and the 2024 [O1](https://openai.com/o1/) feature.

Today, we explore an alternative approach using Monte Carlo Tree Search (MCTS) that offers unique advantages in certain scenarios, particularly when:
1. Ground truth evaluation is available (either from human feedback or labeled data).
2. LLM-based evaluation is expensive or unreliable.
3. You want to generate high-quality training data for future LLM fine-tuning.

We also take inspiration from Language Agent Tree Search, [LATS](https://ag2ai.github.io/ag2/docs/notebooks/lats_search/). The main difference is that our reasoning agent is based on a "process reward model" and has no access to the environment, while the LATS approach requires ground truth feedback from the environment.
In our implementation, we use our existing grader agent to provide pseudo rewards and feedback.

## MCTS vs Beam Search: Key Differences

### Search Strategy
- **Beam Search**: Maintains a fixed number (beam size) of most promising paths at each step
- **MCTS**: Dynamically explores the search space, balancing exploitation of known good paths with exploration of new possibilities

### Evaluation Timing
- **Beam Search**: Evaluates every node at every step
- **MCTS**: Only evaluates leaf nodes during simulation, making it more efficient when evaluation is expensive

### Memory Usage
- **Beam Search**: Memory usage is bounded by beam size Ã— depth
- **MCTS**: Memory grows with number of simulations but focuses on promising paths

## MCTS Implementation Details

The MCTS implementation in ReasoningAgent follows four key steps:

1. **Selection**: Choose nodes to explore using UCT (Upper Confidence Bound for Trees)
```python
choices_weights = [
    # exploitation term
    (child.value / (child.visits + EPSILON)) +
    # exploration term
    self.exploration_constant * math.sqrt((2 * math.log(node.visits + EPSILON) / (child.visits + EPSILON)))
    for child in node.children
]
```

2. **Expansion**: Generate possible next steps using the thinker agent
```python
# Expansion happens through the expand() method
new_nodes = self.expand(node)
```

3. **Simulation**: Run random simulations to leaf nodes
```python
while not self.is_terminal(node):
    if len(node.children) == 0:
        self.expand(node)
    node = random.choice(node.children)
```

4. **Backpropagation**: Update node statistics based on simulation results
```python
while node is not None:
    node.visits += 1
    if node.value is None:
        node.value = reward
    else:
        node.value += reward
    node = node.parent
```

### Ground Truth Evaluation

ReasoningAgent now supports ground truth evaluation by allowing users to include a "GROUND_TRUTH" marker in their prompts. This enables more accurate evaluation of reasoning paths:

```python
# Example usage with ground truth
prompt = """What is the expected maximum dice value if you can roll a 6-sided dice three times?

GROUND_TRUTH:
We define X as the highest outcome among the three rolls.
The probability that X is at least m is 1 - \left(\frac{m-1}{6}\right)^3 for each m from 1 to 6.
Summing these probabilities gives the expectation E(X) = \sum_{m=1}^{6} [1 - (\frac{m-1}{6})^3].
Calculating this sum results in E(X) = 6 - \frac{225}{216} = \frac{119}{24}, which approximates to 4.9583.
Therefore, the expected maximum value when rolling a six-sided die three times is \frac{119}{24} or approximately 4.9583."""

# The agent will use the ground truth to provide more accurate evaluation scores
ans = user_proxy.initiate_chat(mcts_agent, message=prompt)```

When ground truth is provided:
1. The agent automatically splits the prompt into the question and ground truth
2. The grader's system message is updated to include the ground truth
3. Evaluation scores become more reliable since they're based on actual correct answers

This feature is particularly useful for:
- Training data generation with verified correct answers
- Educational applications where correct solutions are known
- Fine-tuning reward models with ground truth supervision


## Generating Training Data

Both MCTS and Beam Search can generate valuable training data, but in different ways:

### From MCTS:
```python
from autogen.agentchat.contrib.reasoning_agent import extract_sft_dataset, extract_rlhf_preference_dataset

# Get SFT data from successful paths
sft_data = extract_sft_dataset(reason_agent._root)

# Get preference pairs for RLHF
rlhf_data = extract_rlhf_preference_dataset(reason_agent._root)
```

The MCTS approach tends to generate:
- More diverse reasoning paths
- Better exploration of alternative solutions
- Stronger contrast between good and bad paths (useful for RLHF)

## Complexity Analysis

Let's analyze the computational complexity of both approaches:

$d$: maximum depth of search tree
$w$: average branching factor (options per node)
$n$: number of Monte Carlo simulations
$b$: beam size

### MCTS
- **Time Complexity**: $O(n \times d)$
  - Each simulation traverses max depth $d$
  - Performs $n$ simulations
- **Memory Complexity**: $O(w^d)$ worst case, but typically much lower in practice
  - Tree grows based on visited paths
  - Focuses on promising branches

### Beam Search
- **Time Complexity**: $O(d \times b \times (w + 1))$
  - At each depth $d$, evaluates $b$ beams
  - Each beam generates $w$ new options
  - Plus one evaluation per beam
- **Memory Complexity**: $O(b \times d)$
  - Maintains $b$ paths
  - Each path has depth $d$



## LATS Implementation Details

LATS (Language Agent Tree Search) is implemented as a variant of MCTS with a key difference in how simulation and evaluation are handled:

1. **Selection**: Uses the same UCT formula as standard MCTS:
   ```python
   choices_weights = [
       (child.value / (child.visits + EPSILON)) +  # exploitation
       exploration_constant * math.sqrt(  # exploration
           (2 * math.log(node.visits + EPSILON) / (child.visits + EPSILON))
       )
   ]
   ```

2. **Expansion**: Similar to MCTS, but evaluates nodes immediately:
   - Generates options using the thinker agent
   - Each new node is immediately evaluated using ground truth
   - Rewards are backpropagated right after expansion

3. **Simulation**: More focused on immediate evaluation:
   - Instead of random rollouts, LATS evaluates each node as it's created
   - Uses ground truth comparison for more reliable evaluation
   - Shorter simulation depth compared to standard MCTS

4. **Key Differences from Standard MCTS**:
   - Earlier evaluation in the search process
   - Stronger reliance on ground truth feedback
   - More immediate reward propagation
   - Better suited for scenarios with reliable evaluation criteria

## Forest of Trees to Add Bootstrapping

The forest approach implements ensemble reasoning by maintaining multiple independent trees:

1. **Implementation**:
   ```python
   forest_size = reason_config.get("forest_size", 5)
   forest_answers = []
   for _ in range(forest_size):
       # Generate independent trees
       if self.method == "beam_search":
           success, response = self.generate_beam_response(prompt, ground_truth)
       elif self.method in ["mcts", "lats"]:
           success, response = self.generate_mcts_response(prompt, ground_truth)
       forest_answers.append(response)
   ```

2. **Consensus Building**:
   - If forest_size = 1, returns single tree result
   - For multiple trees:
     ```python
     self.send(
         message=f"Answer the question {prompt}. Here are some students' different answers:\n{"\n-".join(forest_answers)}",
         recipient=self,
         request_reply=True,
     )
     ```

3. **Benefits**:
   - Increased robustness through multiple independent searches
   - Better exploration of the solution space
   - Reduced sensitivity to random initialization
   - Ability to identify consensus among different reasoning paths

4. **Configuration**:
   - Controlled via `forest_size` parameter in reason_config
   - Default size is 5 trees
   - Each tree can use either MCTS, LATS, or beam search

## When to Use Each Approach

### Use MCTS when:
1. You have reliable ground truth evaluation
2. LLM-based evaluation is expensive
3. You want to generate training data with diverse, high-quality reasoning paths
4. Exploration of the solution space is important

### Use Beam Search when:
1. Exploration is not very important, as the quality of previous steps is indicative for future steps
2. LLM-based evaluation is cheap and reliable
3. The problem space is well-structured
4. Memory constraints are strict


## Conclusion

While both MCTS and Beam Search are valuable approaches for ReasoningAgent, they serve different purposes:

- MCTS excels at thorough exploration and generating training data
- Beam Search is more efficient for quick, direct problem-solving

The choice between them should be based on your specific needs regarding:
- Evaluation cost and availability
- Time and resource constraints
- Intended use of the results

## For Further Reading

* [Original ReasoningAgent with Beam Search](/blog/2024-12-02-ReasoningAgent2)
* [Documentation about ReasoningAgent](/docs/reference/agentchat/contrib/reasoning_agent)
* [MCTS in Wikipedia](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search)

*Join our [Discord](https://discord.com/invite/pAbnFJrkgZ) server to discuss your experiences with these approaches and suggest improvements.*
