```python
import json

from pydantic import BaseModel

from autogen import ConversableAgent

# 1. Define our lesson plan JSON schema (matches expected LLM-structured output)
lesson_plan_json_schema = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "learning_objectives": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "description": {"type": "string"}
                },
                "required": ["title", "description"],
            }
        },
        "script": {"type": "string"}
    },
    "required": ["title", "learning_objectives", "script"],
    "additionalProperties": False,
}

# 2. Use OpenAI V2 client and set response format as JSON schema
llm_config = {
    "config_list": [{
        "api_type": "openai_v2",
        "model": "gpt-5-nano",
        "response_format": {
            "type": "json_schema",
            "json_schema": lesson_plan_json_schema,
        },
    }],
    "temperature": 0,
}

# 3. The agent's system message doesn't need any formatting instructions
system_message = """You are a classroom lesson agent.
Given a topic, write a lesson plan for a fourth grade class.
"""

my_agent = ConversableAgent(
    name="lesson_agent",
    system_message=system_message,
    llm_config=llm_config,
)

# 4. Chat directly with our agent
response = my_agent.run(
    message="Let's learn about the solar system!",
    user_input=True,
    max_turns=1,
)

# 5. Iterate through the chat automatically with console output
response.process()

# 6. Get and print our lesson plan (from structured JSON output)
lesson_plan_json = json.loads(response.text)
print(json.dumps(lesson_plan_json, indent=2))
```