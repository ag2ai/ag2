{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f10761",
   "metadata": {},
   "source": [
    "### Init and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca301a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import autogen\n",
    "from autogen.agentchat.contrib.learning.knowledge_code_gen_swarm_agent import KnowledgeCodeGenSwarmAgent\n",
    "from autogen.agentchat.contrib.learning.knowledge_function_swarm_agent import KnowledgeFunctionSwarmAgent\n",
    "from autogen.coding.jupyter.local_jupyter_server import LocalJupyterServer\n",
    "\n",
    "key_map = {\"gpt-4o-mini\": \"OPENAI_API_KEY\"}\n",
    "\n",
    "config_list = autogen.config_list_from_json(env_or_file=\"/workspaces/ag2/OAI_CONFIG_LIST\")\n",
    "\n",
    "llm_config = {\n",
    "    \"cache_seed\": 42,  # Change the cache_seed for different trials\n",
    "    \"temperature\": 1,\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0acab6",
   "metadata": {},
   "source": [
    "### Call a function for me\n",
    "\n",
    "The first feature to show is creating an in code agent which calls a function for you.\n",
    "\n",
    "`run_query` This function is very simple. One interesting thing (that needs to be documented) is that\n",
    "the function you provide can return a Tuple[Any, str]. Where the Any is passed through as the final result\n",
    "but the string is what is used and interpreted by the LLM. This is so we can truncate the data for the LLM to see\n",
    "but we can return the whole thing to the user.\n",
    "\n",
    "`queryer` This sets up an agent which is responsible for using the function.\n",
    "\n",
    "That's all the setup! Then it's ready to go with some simple queries. It doesn't really know anything yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de253a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(context_variables: dict, query: str):\n",
    "    \"\"\"\n",
    "    Executes a DuckDB query and returns the results as a markdown table.\n",
    "\n",
    "    Args:\n",
    "        context_variables (dict): Contextual variables (unused in this function).\n",
    "        query (str): The DuckDB-compatible SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        str: Query results\n",
    "    \"\"\"\n",
    "    with duckdb.connect(\"/workspaces/ag2/autogen/agentchat/contrib/learning/animal_crossing.duckdb\") as conn:\n",
    "        df = conn.execute(query).fetchdf()\n",
    "        response_lines = []\n",
    "        if len(df) > 50:\n",
    "            response_lines.append(\n",
    "                f\"Truncated Results: Query returned {len(df)} rows. Only 50 rows will be visible. This is not an error\"\n",
    "            )\n",
    "        response_lines.append(df.head(50).to_markdown())\n",
    "        return (df, \"\\n\".join(response_lines))\n",
    "\n",
    "\n",
    "queryer = KnowledgeFunctionSwarmAgent(\n",
    "    name=\"AnimalCrossingQueryer\",\n",
    "    researcher_llm_config=llm_config,\n",
    "    result_validator_llm_config=llm_config,\n",
    "    agent_system_message=\"You are responsible for querying a database containing information about the game animal crossing. It's fine if the result you see is truncated.\",\n",
    "    max_rounds=50,\n",
    "    functions=[run_query],\n",
    ")\n",
    "\n",
    "list_tables_result = queryer.auto_gen_func(\"List the available tables. Only use valid DuckDB syntax.\")\n",
    "\n",
    "print(list_tables_result.result)\n",
    "\n",
    "# Explicitly tell the agent to remember this response\n",
    "queryer.remember(list_tables_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57669eef",
   "metadata": {},
   "source": [
    "### It needs a friend!\n",
    "To show off the agents sharing memories with one another, here is another agent table_summarizer.\n",
    "This function defined here should be able to be replaced with a way to configure structured output, but that's not super relevant.\n",
    "\n",
    "This agent is responsible for summarizing tables. Since it's implemented as a function, these can be saved to memories!\n",
    "\n",
    "This helps make the super rough example possible:\n",
    "- The results of one agent aren't great to be stored in memories. They're either long or ugly\n",
    "- So you instead pass the results to another agent to summarize, then you use the memories of that agent instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSummary(BaseModel):\n",
    "    column_name: str\n",
    "    column_type: str\n",
    "    values_summary: str\n",
    "\n",
    "\n",
    "class TableSummaryModel(BaseModel):\n",
    "    table_name: str\n",
    "    table_summary: str\n",
    "    columns: list[ColumnSummary]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"table_name: {self.table_name}\n",
    "table_summary:\n",
    "{self.table_summary}\"\"\"\n",
    "\n",
    "\n",
    "def summarize_table(context_variables: dict, table_summary: TableSummaryModel):\n",
    "    \"\"\"\n",
    "    Allows you to specify a summary of the provided text.\n",
    "\n",
    "    Args:\n",
    "        table_summary (TableSummaryModel): The informational summary of the table.\n",
    "    Returns:\n",
    "        str: the summary\n",
    "    \"\"\"\n",
    "    return table_summary, str(table_summary)\n",
    "\n",
    "\n",
    "table_summarizer = KnowledgeFunctionSwarmAgent(\n",
    "    name=\"TableSummarizer\",\n",
    "    researcher_llm_config=llm_config,\n",
    "    result_validator_llm_config=llm_config,\n",
    "    agent_system_message=\"\"\"Provide a summary of the provided table using the summarize function.\n",
    "Ensure you fill out the entire TableSummaryModel schema:\n",
    "table_name:str\n",
    "table_summary: str The summary of the purpose and content of the table. 3 sentences max.\n",
    "columns:list[str]\n",
    "column_name: str\n",
    "column_type: str\n",
    "values_summary: str\"\"\",\n",
    "    max_rounds=5,\n",
    "    functions=[summarize_table],\n",
    ")\n",
    "\n",
    "ten_fish_res = queryer.auto_gen_func(\"Show me 10 fish\")\n",
    "# Note, not saving the memory because this is just for an example\n",
    "summary_res = table_summarizer.auto_gen_func(f\"\"\"Summarize the following table: fish\n",
    "{ten_fish_res.result.to_markdown()}\"\"\")\n",
    "# TODO there's some bug here where the function is being passed a dict and not the data type\n",
    "print(\"\\n\\n\")\n",
    "print(str(summary_res.result[\"table_summary\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf037",
   "metadata": {},
   "source": [
    "### Putting the two of them together\n",
    "Putting them together, this code will query 10 example rows, then pass in those example rows to be used to summarize the table.\n",
    "\n",
    "Information about the previously queried or summarized tables are not super useful here, so we `remember` them after\n",
    "to save on context to make this fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_funcs = []\n",
    "tables_df = list_tables_result.result\n",
    "for row in tables_df.itertuples(index=True):\n",
    "    # TODO remove, just a hack to make it go faster for now.\n",
    "    if len(res_funcs) > 10:\n",
    "        break\n",
    "    table_name = row.name\n",
    "\n",
    "    # TODO some way to cache the function here so it doesn't have to figure it out every time with LLM calls.\n",
    "    example_row_res = queryer.auto_gen_func(f\"List 10 example rows in the table {table_name}\")\n",
    "\n",
    "    summary_res = table_summarizer.auto_gen_func(f\"\"\"Summarize the following table: {table_name}\n",
    "{example_row_res.result.to_markdown()}\"\"\")\n",
    "\n",
    "    # Save the memories so they can be remembered after the loop\n",
    "    res_funcs.append(summary_res)\n",
    "\n",
    "# Go through and remember all the summaries\n",
    "for res_func in res_funcs:\n",
    "    table_summarizer.remember(res_func)\n",
    "\n",
    "# Now that the table_summarizer is populated with summaries of all the tables, the queryer can use it!\n",
    "queryer.add_knowledge_source(table_summarizer)\n",
    "\n",
    "print(f\"Queryer has {len(queryer.get_function_memories_as_messages())} memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81791162",
   "metadata": {},
   "source": [
    "### So now lets show off the impact of memory\n",
    "\n",
    "First, we just try to ask a question that is probably too hard for a model like 4o-mini to one shot with its current knowledge\n",
    "It struggles a lot more figuring out what big means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e31b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_fish_res = queryer.auto_gen_func(\"How many big fish are there?\")\n",
    "\n",
    "print(big_fish_res.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256dd85",
   "metadata": {},
   "source": [
    "#### Lets have the agent examine the sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b026ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_sizes_res = queryer.auto_gen_func(\"What are the different possible sizes of fish?\")\n",
    "print(fish_sizes_res.result)\n",
    "\n",
    "queryer.remember(fish_sizes_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6ab62",
   "metadata": {},
   "source": [
    "#### And now it should be able to do a better job. It got it in one go!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_fish_res = queryer.auto_gen_func(\"How many big fish are there?\")\n",
    "\n",
    "print(big_fish_res.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f611f",
   "metadata": {},
   "source": [
    "### Code Generation\n",
    "\n",
    "Now onto code generation. The first example here is showing code generation without \n",
    "leveraging the memory of previous agents. The answer isn't quite right. It just tries\n",
    "to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import pandas\n",
    "\n",
    "all_fish_res = queryer.auto_gen_func(\"Get me all fish\")\n",
    "all_fish_df = all_fish_res.result\n",
    "\n",
    "with LocalJupyterServer() as server:\n",
    "    func_generator = KnowledgeCodeGenSwarmAgent(\n",
    "        name=\"FunctionGenerator\",\n",
    "        docker_server=server,\n",
    "        researcher_llm_config=llm_config,\n",
    "        result_validator_llm_config=llm_config,\n",
    "        max_rounds=50,\n",
    "    )\n",
    "    rand_fish_func_res = func_generator.generate_function(\n",
    "        \"\"\"Generate me a function which picks a random fish from the input fish dataframe input_df, but the choice is decided based on their size.\n",
    "The bigger the fish the more common it is based on the multiplier parameter. Return (Name, Size). The result is random, its fine if it returns something small. \"\"\",\n",
    "        function_name=\"column_analysis_func\",\n",
    "        params={\"input_df\": (all_fish_df, pandas.DataFrame), \"multiplier\": (5, int)},\n",
    "        return_type=Tuple[str, str],\n",
    "    )\n",
    "    rand_fish_func = rand_fish_func_res.result\n",
    "\n",
    "    print(rand_fish_func(all_fish_df, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d98884",
   "metadata": {},
   "source": [
    "#### Now here we add `func_generator.add_knowledge_source(queryer)` to give the memories of the queryer to the function generator. It should help it know more about what the columns are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import pandas\n",
    "\n",
    "all_fish_res = queryer.auto_gen_func(\"Get me all fish\")\n",
    "all_fish_df = all_fish_res.result\n",
    "with LocalJupyterServer() as server:\n",
    "    func_generator = KnowledgeCodeGenSwarmAgent(\n",
    "        name=\"FunctionGenerator\",\n",
    "        docker_server=server,\n",
    "        researcher_llm_config=llm_config,\n",
    "        result_validator_llm_config=llm_config,\n",
    "        max_rounds=50,\n",
    "    )\n",
    "    func_generator.add_knowledge_source(queryer)\n",
    "    rand_fish_func_res = func_generator.generate_function(\n",
    "        \"\"\"Generate me a function which picks a random fish from the input fish dataframe input_df, but the choice is decided based on their size.\n",
    "The bigger the fish the more common it is based on the multiplier parameter. Return (Name, Size). The result is random, its fine if it returns something small. \"\"\",\n",
    "        function_name=\"column_analysis_func\",\n",
    "        params={\"input_df\": (all_fish_df, pandas.DataFrame), \"multiplier\": (5, int)},\n",
    "        return_type=Tuple[str, str],\n",
    "    )\n",
    "    rand_fish_func = rand_fish_func_res.result\n",
    "\n",
    "for i in range(10):\n",
    "    print(rand_fish_func(all_fish_df, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print(rand_fish_func(all_fish_df, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cd7b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Learn how to implement both synchronous and asynchronous function calls using AssistantAgent and UserProxyAgent in AutoGen, with examples of their application in individual and group chat settings for task execution with language models.",
   "tags": [
    "tool/function",
    "async"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
