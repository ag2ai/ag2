{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocumentAgent\n",
    "\n",
    "In this notebook, see how DocumentAgent, through natural language, can\n",
    "\n",
    "1. Ingest documents from a local file or URL\n",
    "2. and answer questions with RAG capability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "To get started with the document agent integration in AG2, follow these steps:\n",
    "\n",
    "Install AG2 with the `rag` extra:\n",
    "```bash\n",
    "pip install ag2[rag]\n",
    "```\n",
    "\n",
    "Note:\n",
    "\n",
    "   1. Currently, the DocumentAgent only supports questions related to the ingested documents.\n",
    "   2. Answers may not be accurate for documents that cannot be parsed correctly to Markdown format.\n",
    "\n",
    "You're all set! Now you can start using DocumentAgent feature in AG2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inside the DocumentAgent\n",
    "\n",
    "![./documentagent/documentagent_swarm.png](DocumentAgent's internal swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import autogen\n",
    "from autogen import AfterWorkOption, ConversableAgent, initiate_swarm_chat\n",
    "from autogen.agents.experimental import DocumentAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"../OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4o\"],\n",
    "    },\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = config_list[0][\"api_key\"]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting local documents and answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_agent = DocumentAgent(llm_config=llm_config, collection_name=\"toast_report\")\n",
    "document_agent.run(\n",
    "    \"could you ingest ../test/agentchat/contrib/graph_rag/Toast_financial_report.pdf? What is the fiscal year 2024 financial summary?\",\n",
    "    max_turns=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching a webpage and answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_agent = DocumentAgent(llm_config=llm_config, collection_name=\"news_reports\")\n",
    "document_agent.run(\n",
    "    \"could you read 'https://www.independent.co.uk/space/earth-core-inner-shape-change-b2695585.html' and summarize the article?\",\n",
    "    max_turns=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple DocumentAgents in a Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the OPENAI_API_KEY is set in the environment\n",
    "llm_config = {\"model\": \"gpt-4o-mini\", \"api_type\": \"openai\", \"cache_seed\": None}\n",
    "\n",
    "nvidia_agent = DocumentAgent(\n",
    "    name=\"nvidia_agent\",\n",
    "    llm_config=llm_config,\n",
    "    collection_name=\"nvidia-demo\",\n",
    ")\n",
    "\n",
    "amd_agent = DocumentAgent(\n",
    "    name=\"amd_agent\",\n",
    "    llm_config=llm_config,\n",
    "    collection_name=\"amd-demo\",\n",
    ")\n",
    "\n",
    "analyst = ConversableAgent(\n",
    "    name=\"financial_analyst\",\n",
    "    system_message=(\n",
    "        \"You are a financial analyst working with two specialist agents, amd_agent who handles all AMD documents and queries, and nvidia_agent who handles all NVIDIA documents and queries. \"\n",
    "        \"Each agent knows how to load documents and answer questions from the document regarding their respective companies. \"\n",
    "        \"Only mention one of the two agents at a time, prioritize amd_agent. You will be able to engage each agent separately in subsequent iterations. \"\n",
    "        \"Work with only one agent at a time and provide (a) an indication for them to take action by saying '[Next to speak is ...]' together with (b) documents they need to ingest and (c) queries they need to run, if any. \"\n",
    "        \"When all documents have been ingested and all queries have been answered, provide a summary and add 'TERMINATE' to the end of your summary.\"\n",
    "    ),\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and \"terminate\" in x.get(\"content\", \"\").lower(),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "result, _, _ = initiate_swarm_chat(\n",
    "    initial_agent=analyst,\n",
    "    agents=[analyst, nvidia_agent, amd_agent],\n",
    "    messages=(\n",
    "        \"Use the amd_agent to load AMD's 4th quarter 2024 report from \"\n",
    "        \"./documentagent/AMDQ4-2024.pdf \"\n",
    "        \"and use the nvidia_agent to load NVIDIA's 3rd quarter 2025 report from \"\n",
    "        \"./documentagent/NVIDIAQ3-2025.pdf. \"\n",
    "        \"Then ask both agents what AMD and NVIDIA did, in detail, in regards to AI in their latest quarters and what the net revenues were.\"\n",
    "    ),\n",
    "    swarm_manager_args={\n",
    "        \"llm_config\": llm_config,\n",
    "        \"system_message\": \"You are managing a financial analyst and two specialist company agents. After each specialist agent, amd_agent or nvidia_agent speak, always have the financial analyst speak next.\",\n",
    "        \"is_termination_msg\": lambda x: x.get(\"content\", \"\") and \"terminate\" in x.get(\"content\", \"\").lower(),\n",
    "    },\n",
    "    after_work=AfterWorkOption.SWARM_MANAGER,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "RAG with DocumentAgent",
   "tags": [
    "agents",
    "documents",
    "RAG",
    "documentagent"
   ]
  },
  "kernelspec": {
   "display_name": ".venv-3.11-document-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
