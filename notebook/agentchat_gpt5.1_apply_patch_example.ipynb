{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GPT-5.1 Apply Patch Tool Example\n",
    "\n",
    "This notebook demonstrates how to use the **apply_patch** tool with GPT-5.1 via OpenAI's Responses API. The apply_patch tool enables agents to create, update, and delete files using structured diffs, making it ideal for code editing tasks.\n",
    "\n",
    "AUTHOR: [Priyanshu Deshmukh](https://github.com/priyansh4320)\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `apply_patch` tool is a built-in capability in GPT-5.1 that allows agents to:\n",
    "- **Create files**: Generate new files with specified content\n",
    "- **Update files**: Modify existing files using unified diff format\n",
    "- **Delete files**: Remove files from the workspace\n",
    "\n",
    "Unlike traditional code execution methods, the apply_patch tool provides structured, controlled file operations that are safer and more precise than raw code generation.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AG2 requires `Python>=3.10`. To run this notebook, you need:\n",
    "- GPT-5.1 access (currently in beta)\n",
    "- OpenAI API key\n",
    "- AG2 installed with OpenAI support\n",
    "\n",
    "\n",
    "pip install ag2[openai]\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AG2 if needed\n",
    "# %pip install ag2[openai]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up your OpenAI API key and configure the LLM to use the Responses API with GPT-5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"responses\",\n",
    "        \"model\": \"gpt-5.1\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"built_in_tools\": [\"apply_patch\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "Create a coding assistant agent that can use the apply_patch tool. The tool is automatically available when you specify it in `built_in_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a coding assistant agent\n",
    "coding_agent = ConversableAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful coding assistant. You can create, edit, and delete files\n",
    "    using the apply_patch tool. When making changes, always use the apply_patch tool rather than\n",
    "    writing raw code blocks. Be precise with your file operations and explain what you're doing.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Example 1: Creating a New Project\n",
    "\n",
    "Let's start by creating a simple Python project with multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project structure\n",
    "result = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    Create a new Python project folder called 'calculator' with the following structure:\n",
    "    1. Create a main.py file with a Calculator class that has methods for add, subtract, multiply, and divide\n",
    "    \"\"\",\n",
    "    max_turns=2,\n",
    "    clear_history=True,\n",
    ")\n",
    "\n",
    "print(\"Chat Summary:\")\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Example 2: Modifying Existing Files\n",
    "\n",
    "Now let's update the calculator to add more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the calculator with new features\n",
    "result = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    In calculator folder, add power and square root methods to the Calculator class in main.py\n",
    "    \"\"\",\n",
    "    max_turns=2,\n",
    ")\n",
    "\n",
    "print(\"Chat Summary:\")\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Example 3: Refactoring Code\n",
    "\n",
    "Let's refactor the code to improve its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor the calculator code\n",
    "result = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    Refactor the calculator code in calculator folder:\n",
    "    1. Split the Calculator class into separate files: basic_operations.py and advanced_operations.py\n",
    "    2. Update main.py to import from both modules\n",
    "    3. Update tests to reflect the new structure\n",
    "    \"\"\",\n",
    "    max_turns=2,\n",
    ")\n",
    "\n",
    "print(\"Chat Summary:\")\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Example 4: Creating a Complete Application\n",
    "\n",
    "Let's create a more complex application: a simple web API using FastAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FastAPI application\n",
    "result = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    Create a FastAPI application with the following structure:\n",
    "    1. Create app/main.py with a FastAPI app and a simple /health endpoint\n",
    "    2. Create app/__init__.py\n",
    "    3. Create app/requirements.txt with fastapi and uvicorn\n",
    "    4. Create a app/README.md with setup and run instructions\n",
    "    5. Create app/.gitignore file for Python projects\n",
    "    \"\"\",\n",
    "    max_turns=2,\n",
    "    clear_history=True,\n",
    ")\n",
    "\n",
    "print(\"Chat Summary:\")\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Example 5: Bug Fixing\n",
    "\n",
    "The agent can also fix bugs in existing code. Let's first create some code with a bug, then ask the agent to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a file with a bug\n",
    "buggy_code = \"\"\"\n",
    "def calculate_average(numbers):\n",
    "    total = 0\n",
    "    for num in numbers:\n",
    "        total += num\n",
    "    return total / len(numbers)  # Bug: doesn't handle empty list\n",
    "\n",
    "def divide(a, b):\n",
    "    return a / b  # Bug: doesn't handle division by zero\n",
    "\"\"\"\n",
    "\n",
    "# Write the buggy file manually (or use the agent)\n",
    "Path(\"buggy_math.py\").write_text(buggy_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ask the agent to fix the bugs\n",
    "result = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    I have a file called buggy_math.py with some bugs:\n",
    "    1. The calculate_average function doesn't handle empty lists\n",
    "    2. The divide function doesn't handle division by zero\n",
    "    Please fix both bugs by adding proper error handling.\n",
    "    \"\"\",\n",
    "    max_turns=2,\n",
    "    clear_history=True,\n",
    ")\n",
    "\n",
    "print(\"Chat Summary:\")\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Example 6: Work with a dedicated Workspace Directory\n",
    "\n",
    "The Configurations allows a user to create a dedicated workspace_dir for themselves which serves as a root project directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"responses\",\n",
    "        \"model\": \"gpt-5.1\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"built_in_tools\": [\"apply_patch\"],\n",
    "        \"workspace_dir\": \"./my_project_folder\",  # NEW: Just specify workspace_dir here!\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create agent - no need to manually create editor or patch_tool\n",
    "coding_agent = ConversableAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful coding assistant...\"\"\",\n",
    ")\n",
    "\n",
    "# Tool is automatically registered! Just use it:\n",
    "result = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    Create app.py in the workspace directory,\n",
    "    create a app.yaml file,\n",
    "    create a app.sh file,\n",
    "    create a folder /tests,\n",
    "    create tests/test_app.py\n",
    "    \"\"\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Example 8: Working With Allowed Paths\n",
    "\n",
    "The  configuration introduces allowed_paths:\n",
    "List of allowed path patterns (for security).\n",
    "                Supports glob-style patterns with ** for recursive matching.\n",
    "                Works for both local filesystem and cloud storage paths.\n",
    "\n",
    "                Examples:\n",
    "                    - [\"**\"] - Allow all paths (default)\n",
    "                    - [\"src/**\"] - Allow all files in src/ and subdirectories\n",
    "                    - [\"my-bucket/**\"] - Allow all paths in cloud storage bucket\n",
    "                    - [\"s3://my-bucket/src/**\"] - Allow paths in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM with workspace_dir and allowed_paths\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"responses\",\n",
    "        \"model\": \"gpt-5.1\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"built_in_tools\": [\"apply_patch\"],\n",
    "        \"workspace_dir\": \"./my_project_folder\",\n",
    "        \"allowed_paths\": [\"src/**\", \"*.py\", \"tests/**\"],  # Only allow operations in these paths\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create agent - no need to manually create editor or patch_tool\n",
    "coding_agent = ConversableAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful coding assistant...\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Test 1: Try to create file in allowed path (should work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"Create src/main.py with a simple hello world function\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Test 2: Try to create file in NOT allowed path (should fail with clear error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"Create config/settings.json in the config directory (outside of src/ and tests/)\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Test 3: Try to update file in NOT allowed path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"Create a file called root_file.py in the root of the workspace (not in src/ or tests/)\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Async Patches\n",
    "an added feature to apply async patches and should allow a user to add patches asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "load_dotenv()\n",
    "# add async patches configuration\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"responses\",\n",
    "        \"model\": \"gpt-5.1\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"built_in_tools\": [\"apply_patch_async\"],\n",
    "        \"workspace_dir\": \"./my_project_folder\",\n",
    "    },\n",
    ")\n",
    "\n",
    "coding_agent = ConversableAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful coding assistant...\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = coding_agent.initiate_chat(\n",
    "    recipient=coding_agent,\n",
    "    message=\"\"\"\n",
    "    use apply_patch tool to create a project test_project with the following structure:\n",
    "    - create a project.py file\n",
    "    - create a tests folder\n",
    "    - create a tests/test_main.py file\n",
    "    \"\"\",\n",
    "    max_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb0085",
   "metadata": {},
   "source": [
    "# Two Agent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3774bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a coding assistant agent\n",
    "coding_agent = ConversableAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful coding assistant. You can create, edit, and delete files\n",
    "    using the apply_patch tool. When making changes, always use the apply_patch tool rather than\n",
    "    writing raw code blocks. Be precise with your file operations and explain what you're doing.\"\"\",\n",
    ")\n",
    "\n",
    "review_agent = ConversableAgent(\n",
    "    name=\"review_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    you are a review agent. you will review changes made by coding agent\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_agent.initiate_chat(\n",
    "    recipient=review_agent,\n",
    "    message=\"\"\"\n",
    "    use apply_patch tool to create a project test_project with the following structure:\n",
    "    - create a project.py file\n",
    "    - create a tests folder\n",
    "    - create a tests/test_main.py file\n",
    "    \"\"\",\n",
    "    max_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7f495",
   "metadata": {},
   "source": [
    "# Groupchat example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aba8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise LLM configuration\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"responses\",\n",
    "        \"model\": \"gpt-5.1\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"built_in_tools\": [\"apply_patch_async\"],\n",
    "        \"workspace_dir\": \"./my_project_folder\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ac209",
   "metadata": {},
   "source": [
    "we will built a groupchat of agents where each agent have diffrent role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25aa44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise agents\n",
    "from autogen.agentchat.group.patterns.auto import AutoPattern\n",
    "\n",
    "\n",
    "devops_agent = ConversableAgent(\n",
    "    name=\"devops_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful devops agent\n",
    "    you will be responsible for devOPS tasks.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "qa_agent = ConversableAgent(\n",
    "    name=\"qa_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful qa agent\n",
    "    you will be responsible for qa tasks.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "coding_agent = ConversableAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful coding assistant. You can create, edit, and delete files\n",
    "    using the apply_patch tool. When making changes, always use the apply_patch tool rather than\n",
    "    writing raw code blocks. Be precise with your file operations and explain what you're doing.\"\"\",\n",
    ")\n",
    "\n",
    "review_agent = ConversableAgent(\n",
    "    name=\"review_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    you are a review agent. you will review changes made by coding agent\n",
    "    \"\"\",\n",
    ")\n",
    "# create a groupchat\n",
    "\n",
    "\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=coding_agent,\n",
    "    agents=[devops_agent, qa_agent, review_agent, coding_agent],\n",
    "    group_manager_args={\"llm_config\": llm_config}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27aa0767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m_User\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "    create a project.py file\n",
      "    - in project.py add calculator code\n",
      "    - create a tests folder\n",
      "    - create a tests/test_main.py file\n",
      "    - add .yaml file to project.py\n",
      "    - add .sh file to project.py\n",
      "    - add .gitignore file to project.py\n",
      "    - add .md file to project.py\n",
      "    review the code and make sure it is correct\n",
      "    add test to the project.\n",
      "    \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: coding_assistant\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "params {'model': 'gpt-5.1', 'tool_choice': 'auto', 'stream': False, 'input': [{'role': 'system', 'content': [{'type': 'input_text', 'text': \"You are a helpful coding assistant. You can create, edit, and delete files\\n    using the apply_patch tool. When making changes, always use the apply_patch tool rather than\\n    writing raw code blocks. Be precise with your file operations and explain what you're doing.\"}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': '\\n    create a project.py file\\n    - in project.py add calculator code\\n    - create a tests folder\\n    - create a tests/test_main.py file\\n    - add .yaml file to project.py\\n    - add .sh file to project.py\\n    - add .gitignore file to project.py\\n    - add .md file to project.py\\n    review the code and make sure it is correct\\n    add test to the project.\\n    '}]}], 'tools': [{'type': 'apply_patch'}]}\n",
      "\u001b[33mcoding_assistant\u001b[0m (to chat_manager):\n",
      "\n",
      "<apply_patch_call: create_file on project.py (status: completed) diff: +\"\"\"\n",
      "+Simple calculator project.\n",
      "+\n",
      "+This module exposes:\n",
      "+- A Calculator class with basic arithmetic operations.\n",
      "+- Utility functions to:\n",
      "+  * Read configuration from a YAML file.\n",
      "+  * Read shell script content from a .sh file.\n",
      "+  * Read markdown documentation from a .md file.\n",
      "+  * Read ignore patterns from a .gitignore file.\n",
      "+\"\"\"\n",
      "+\n",
      "+from __future__ import annotations\n",
      "+\n",
      "+from dataclasses import dataclass\n",
      "+from pathlib import Path\n",
      "+from typing import Iterable, List, Optional\n",
      "+\n",
      "+import math\n",
      "+\n",
      "+try:\n",
      "+    import yaml  # type: ignore\n",
      "+except ImportError as exc:  # pragma: no cover - indicates a missing optional dependency\n",
      "+    raise RuntimeError(\n",
      "+        \"PyYAML is required for this project. Install with `pip install pyyaml`.\"\n",
      "+    ) from exc\n",
      "+\n",
      "+\n",
      "+PROJECT_ROOT = Path(__file__).parent\n",
      "+\n",
      "+\n",
      "+@dataclass\n",
      "+class Calculator:\n",
      "+    \"\"\"A simple calculator supporting basic operations.\"\"\"\n",
      "+\n",
      "+    def add(self, a: float, b: float) -> float:\n",
      "+        return a + b\n",
      "+\n",
      "+    def subtract(self, a: float, b: float) -> float:\n",
      "+        return a - b\n",
      "+\n",
      "+    def multiply(self, a: float, b: float) -> float:\n",
      "+        return a * b\n",
      "+\n",
      "+    def divide(self, a: float, b: float) -> float:\n",
      "+        if b == 0:\n",
      "+            raise ZeroDivisionError(\"Cannot divide by zero\")\n",
      "+        return a / b\n",
      "+\n",
      "+    def sqrt(self, x: float) -> float:\n",
      "+        if x < 0:\n",
      "+            raise ValueError(\"Cannot take square root of a negative number\")\n",
      "+        return math.sqrt(x)\n",
      "+\n",
      "+\n",
      "+def _ensure_file_exists(path: Path, default_content: str = \"\") -> Path:\n",
      "+    \"\"\"\n",
      "+    Ensure that a file exists at `path`. If it does not exist, create it\n",
      "+    with `default_content`.\n",
      "+\n",
      "+    Returns the path for convenience.\n",
      "+    \"\"\"\n",
      "+\n",
      "+    if not path.exists():\n",
      "+        path.parent.mkdir(parents=True, exist_ok=True)\n",
      "+        path.write_text(default_content, encoding=\"utf-8\")\n",
      "+    return path\n",
      "+\n",
      "+\n",
      "+def get_yaml_config(path: Optional[Path] = None) -> dict:\n",
      "+    \"\"\"\n",
      "+    Read a YAML configuration file and return it as a dictionary.\n",
      "+\n",
      "+    If `path` is None, uses `<project_root>/config.yaml`. If the file does\n",
      "+    not exist, it is created with a small default configuration.\n",
      "+    \"\"\"\n",
      "+\n",
      "+    if path is None:\n",
      "+        path = PROJECT_ROOT / \"config.yaml\"\n",
      "+\n",
      "+    default_yaml = \"calculator:\\n  precision: 4\\n  mode: basic\\n\"\n",
      "+    path = _ensure_file_exists(path, default_yaml)\n",
      "+\n",
      "+    content = path.read_text(encoding=\"utf-8\")\n",
      "+    data = yaml.safe_load(content) or {}\n",
      "+    if not isinstance(data, dict):\n",
      "+        raise ValueError(\"YAML configuration must contain a mapping at the top level\")\n",
      "+    return data\n",
      "+\n",
      "+\n",
      "+def get_shell_script(path: Optional[Path] = None) -> str:\n",
      "+    \"\"\"\n",
      "+    Read and return the contents of a .sh script.\n",
      "+\n",
      "+    If `path` is None, uses `<project_root>/run.sh`. If the file does not\n",
      "+    exist, it is created with a simple shell script.\n",
      "+    \"\"\"\n",
      "+\n",
      "+    if path is None:\n",
      "+        path = PROJECT_ROOT / \"run.sh\"\n",
      "+\n",
      "+    default_script = \"#!/usr/bin/env bash\\n\" \"echo \\\"Running calculator project\\\"\\n\"\n",
      "+    path = _ensure_file_exists(path, default_script)\n",
      "+\n",
      "+    return path.read_text(encoding=\"utf-8\")\n",
      "+\n",
      "+\n",
      "+def get_markdown_doc(path: Optional[Path] = None) -> str:\n",
      "+    \"\"\"\n",
      "+    Read and return the contents of a markdown (.md) file.\n",
      "+\n",
      "+    If `path` is None, uses `<project_root>/README.md`. If the file does\n",
      "+    not exist, it is created with a small default README.\n",
      "+    \"\"\"\n",
      "+\n",
      "+    if path is None:\n",
      "+        path = PROJECT_ROOT / \"README.md\"\n",
      "+\n",
      "+    default_md = (\n",
      "+        \"# Calculator Project\\n\\n\"\n",
      "+        \"This is a simple calculator project used for demonstration and testing.\\n\"\n",
      "+    )\n",
      "+    path = _ensure_file_exists(path, default_md)\n",
      "+\n",
      "+    return path.read_text(encoding=\"utf-8\")\n",
      "+\n",
      "+\n",
      "+def get_gitignore_patterns(path: Optional[Path] = None) -> List[str]:\n",
      "+    \"\"\"\n",
      "+    Read and return ignore patterns from a .gitignore-style file.\n",
      "+\n",
      "+    If `path` is None, uses `<project_root>/.gitignore`. If the file does\n",
      "+    not exist, it is created with a small default set of patterns.\n",
      "+    \"\"\"\n",
      "+\n",
      "+    if path is None:\n",
      "+        path = PROJECT_ROOT / \".gitignore\"\n",
      "+\n",
      "+    default_gitignore = \"__pycache__/\\n*.pyc\\n.env\\n\"\n",
      "+    path = _ensure_file_exists(path, default_gitignore)\n",
      "+\n",
      "+    lines = path.read_text(encoding=\"utf-8\").splitlines()\n",
      "+    return [line for line in lines if line.strip() and not line.lstrip().startswith(\"#\")]\n",
      "+\n",
      "+\n",
      "+def calculate_series_sum(numbers: Iterable[float]) -> float:\n",
      "+    \"\"\"Utility function used in tests â€“ returns the sum of an iterable of numbers.\"\"\"\n",
      "+\n",
      "+    total = 0.0\n",
      "+    for n in numbers:\n",
      "+        total += float(n)\n",
      "+    return total\n",
      "+\n",
      "+\n",
      "+__all__ = [\n",
      "+    \"Calculator\",\n",
      "+    \"calculate_series_sum\",\n",
      "+    \"get_yaml_config\",\n",
      "+    \"get_shell_script\",\n",
      "+    \"get_markdown_doc\",\n",
      "+    \"get_gitignore_patterns\",\n",
      "+]\n",
      "+\n",
      ">\n",
      "<apply_patch_call: create_file on tests/test_main.py (status: completed) diff: +import math\n",
      "+from pathlib import Path\n",
      "+\n",
      "+import pytest\n",
      "+\n",
      "+from project import (\n",
      "+    Calculator,\n",
      "+    calculate_series_sum,\n",
      "+    get_gitignore_patterns,\n",
      "+    get_markdown_doc,\n",
      "+    get_shell_script,\n",
      "+    get_yaml_config,\n",
      "+)\n",
      "+\n",
      "+\n",
      "+def test_addition():\n",
      "+    calc = Calculator()\n",
      "+    assert calc.add(1, 2) == 3\n",
      "+    assert calc.add(-1, 1.5) == 0.5\n",
      "+\n",
      "+\n",
      "+def test_subtraction():\n",
      "+    calc = Calculator()\n",
      "+    assert calc.subtract(5, 3) == 2\n",
      "+\n",
      "+\n",
      "+def test_multiplication():\n",
      "+    calc = Calculator()\n",
      "+    assert calc.multiply(4, 2.5) == 10\n",
      "+\n",
      "+\n",
      "+def test_division():\n",
      "+    calc = Calculator()\n",
      "+    assert calc.divide(10, 2) == 5\n",
      "+    with pytest.raises(ZeroDivisionError):\n",
      "+        calc.divide(1, 0)\n",
      "+\n",
      "+\n",
      "+def test_sqrt():\n",
      "+    calc = Calculator()\n",
      "+    assert calc.sqrt(9) == 3\n",
      "+    assert math.isclose(calc.sqrt(2), math.sqrt(2))\n",
      "+    with pytest.raises(ValueError):\n",
      "+        calc.sqrt(-1)\n",
      "+\n",
      "+\n",
      "+def test_calculate_series_sum():\n",
      "+    assert calculate_series_sum([1, 2, 3]) == 6\n",
      "+    assert calculate_series_sum([]) == 0\n",
      "+\n",
      "+\n",
      "+def test_yaml_config_roundtrip(tmp_path: Path):\n",
      "+    yaml_path = tmp_path / \"config.yaml\"\n",
      "+    yaml_path.write_text(\"calculator:\\n  precision: 2\\n\", encoding=\"utf-8\")\n",
      "+    cfg = get_yaml_config(yaml_path)\n",
      "+    assert cfg[\"calculator\"][\"precision\"] == 2\n",
      "+\n",
      "+\n",
      "+def test_shell_script_created_and_read(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):\n",
      "+    # Use a temporary directory as project root to avoid touching real files\n",
      "+    from project import PROJECT_ROOT as REAL_ROOT\n",
      "+\n",
      "+    monkeypatch.setattr(\"project.PROJECT_ROOT\", tmp_path)\n",
      "+    content = get_shell_script()\n",
      "+    assert \"Running calculator project\" in content\n",
      "+\n",
      "+\n",
      "+def test_markdown_doc_created_and_read(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):\n",
      "+    monkeypatch.setattr(\"project.PROJECT_ROOT\", tmp_path)\n",
      "+    content = get_markdown_doc()\n",
      "+    assert \"Calculator Project\" in content\n",
      "+\n",
      "+\n",
      "+def test_gitignore_patterns_created_and_read(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):\n",
      "+    monkeypatch.setattr(\"project.PROJECT_ROOT\", tmp_path)\n",
      "+    patterns = get_gitignore_patterns()\n",
      "+    assert \"__pycache__/\" in patterns\n",
      "+    assert \"*.pyc\" in patterns\n",
      "+\n",
      ">\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "params {'model': 'gpt-5.1', 'tool_choice': 'auto', 'stream': False, 'input': [{'role': 'system', 'content': [{'type': 'input_text', 'text': \"You are in a role play game. The following roles are available:\\n                _Group_Tool_Executor: Tool Execution, do not use this agent directly.\\ndevops_agent: You are a helpful devops agent\\n    you will be responsible for devOPS tasks.\\nqa_agent: You are a helpful qa agent\\n    you will be responsible for qa tasks.\\nreview_agent: \\n    you are a review agent. you will review changes made by coding agent\\ncoding_assistant: You are a helpful coding assistant. You can create, edit, and delete files\\n    using the apply_patch tool. When making changes, always use the apply_patch tool rather than\\n    writing raw code blocks. Be precise with your file operations and explain what you're doing.\\n_User: You are a helpful AI Assistant..\\n                Read the following conversation.\\n                Then select the next role from ['_Group_Tool_Executor', 'devops_agent', 'qa_agent', 'review_agent', 'coding_assistant', '_User'] to play. Only return the role.\"}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': '\\n    create a project.py file\\n    - in project.py add calculator code\\n    - create a tests folder\\n    - create a tests/test_main.py file\\n    - add .yaml file to project.py\\n    - add .sh file to project.py\\n    - add .gitignore file to project.py\\n    - add .md file to project.py\\n    review the code and make sure it is correct\\n    add test to the project.\\n    '}]}, {'role': 'system', 'content': [{'type': 'input_text', 'text': \"Read the above conversation. Then select the next role from ['_Group_Tool_Executor', 'devops_agent', 'qa_agent', 'review_agent', 'coding_assistant', '_User'] to play. Only return the role.\"}]}], 'tools': [{'type': 'apply_patch'}]}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magentchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initiate_group_chat\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result, context, last_agent = \u001b[43minitiate_group_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m    create a project.py file\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[33;43m    - in project.py add calculator code\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[33;43m    - create a tests folder\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[33;43m    - create a tests/test_main.py file\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[33;43m    - add .yaml file to project.py\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m    - add .sh file to project.py\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[33;43m    - add .gitignore file to project.py\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[33;43m    - add .md file to project.py\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[33;43m    review the code and make sure it is correct\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[33;43m    add test to the project.\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/group/multi_agent_chat.py:98\u001b[39m, in \u001b[36minitiate_group_chat\u001b[39m\u001b[34m(pattern, messages, max_rounds, safeguard_policy, safeguard_llm_config, mask_llm_config)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m last_agent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo agent selected to start the conversation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m chat_result = \u001b[43mlast_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m cleanup_temp_user_messages(chat_result)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m chat_result, context_variables, manager.last_speaker\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/conversable_agent.py:1475\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1473\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1474\u001b[39m         msg2send = \u001b[38;5;28mself\u001b[39m.generate_init_message(message, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1475\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1476\u001b[39m summary = \u001b[38;5;28mself\u001b[39m._summarize_chat(\n\u001b[32m   1477\u001b[39m     summary_method,\n\u001b[32m   1478\u001b[39m     summary_args,\n\u001b[32m   1479\u001b[39m     recipient,\n\u001b[32m   1480\u001b[39m     cache=cache,\n\u001b[32m   1481\u001b[39m )\n\u001b[32m   1482\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/conversable_agent.py:1128\u001b[39m, in \u001b[36mConversableAgent.send\u001b[39m\u001b[34m(self, message, recipient, request_reply, silent)\u001b[39m\n\u001b[32m   1126\u001b[39m valid = \u001b[38;5;28mself\u001b[39m._append_oai_message(message, recipient, role=\u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, name=\u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m   1127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m     \u001b[43mrecipient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1131\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMessage can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1132\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/conversable_agent.py:1236\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1236\u001b[39m reply = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1238\u001b[39m     \u001b[38;5;28mself\u001b[39m.send(reply, sender, silent=silent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/conversable_agent.py:2881\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, exclude)\u001b[39m\n\u001b[32m   2879\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2881\u001b[39m     final, reply = \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2882\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2883\u001b[39m         log_event(\n\u001b[32m   2884\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2885\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2889\u001b[39m             reply=reply,\n\u001b[32m   2890\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/groupchat.py:1255\u001b[39m, in \u001b[36mGroupChatManager.run_chat\u001b[39m\u001b[34m(self, messages, sender, config)\u001b[39m\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m     speaker = \u001b[43mgroupchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1256\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[32m   1257\u001b[39m         iostream = IOStream.get_default()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/groupchat.py:581\u001b[39m, in \u001b[36mGroupChat.select_speaker\u001b[39m\u001b[34m(self, last_speaker, selector)\u001b[39m\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next_agent(last_speaker)\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/groupchat.py:762\u001b[39m, in \u001b[36mGroupChat._auto_select_speaker\u001b[39m\u001b[34m(self, last_speaker, selector, messages, agents)\u001b[39m\n\u001b[32m    759\u001b[39m     \u001b[38;5;28mself\u001b[39m._speaker_selection_transforms.add_to_agent(speaker_selection_agent)\n\u001b[32m    761\u001b[39m \u001b[38;5;66;03m# Run the speaker selection chat\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m result = \u001b[43mchecking_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeaker_selection_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't use caching for the speaker selection chat\u001b[39;49;00m\n\u001b[32m    765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m    767\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limiting the chat to the number of attempts, including the initial one\u001b[39;49;00m\n\u001b[32m    768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselect_speaker_auto_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Base silence on the verbose attribute\u001b[39;49;00m\n\u001b[32m    770\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_speaker_selection_result(result, last_speaker, agents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/conversable_agent.py:1459\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_terminate_chat(recipient, last_message):\n\u001b[32m   1458\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1459\u001b[39m     msg2send = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/conversable_agent.py:2881\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, exclude)\u001b[39m\n\u001b[32m   2879\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2881\u001b[39m     final, reply = \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2882\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2883\u001b[39m         log_event(\n\u001b[32m   2884\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2885\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2889\u001b[39m             reply=reply,\n\u001b[32m   2890\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/groupchat.py:738\u001b[39m, in \u001b[36mGroupChat._auto_select_speaker.<locals>.validate_speaker_name\u001b[39m\u001b[34m(recipient, messages, sender, config)\u001b[39m\n\u001b[32m    735\u001b[39m attempt = attempt + \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m attempts_left = attempts_left - \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_speaker_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempts_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ag2/autogen/agentchat/groupchat.py:865\u001b[39m, in \u001b[36mGroupChat._validate_speaker_name\u001b[39m\u001b[34m(self, recipient, messages, sender, config, attempts_left, attempt, agents)\u001b[39m\n\u001b[32m    863\u001b[39m \u001b[38;5;66;03m# Validate the speaker name selected\u001b[39;00m\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mand\u001b[39;00m (name := messages[-\u001b[32m1\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     mentions = \u001b[38;5;28mself\u001b[39m._mentioned_agents(\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m(), agents)\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    867\u001b[39m     mentions = []\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "from autogen.agentchat import initiate_group_chat\n",
    "\n",
    "\n",
    "result, context, last_agent = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"\"\"\n",
    "    create a project.py file\n",
    "    - in project.py add calculator code\n",
    "    - create a tests folder\n",
    "    - create a tests/test_main.py file\n",
    "    - add .yaml file to project.py\n",
    "    - add .sh file to project.py\n",
    "    - add .gitignore file to project.py\n",
    "    - add .md file to project.py\n",
    "    review the code and make sure it is correct\n",
    "    add test to the project.\n",
    "    \"\"\",\n",
    "    max_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Understanding the Apply Patch Operations\n",
    "\n",
    "The apply_patch tool uses three types of operations:\n",
    "\n",
    "1. **create_file**: Creates a new file with the specified content\n",
    "2. **update_file**: Updates an existing file using unified diff format\n",
    "3. **delete_file**: Deletes a file from the workspace\n",
    "\n",
    "### Diff Format\n",
    "\n",
    "The update_file operation uses unified diff format. Here's an example:\n",
    "\n",
    "```\n",
    "@@ -1,3 +1,3 @@\n",
    " def hello():\n",
    "-    print(\"World\")\n",
    "+    print(\"Hello, World!\")\n",
    "     return True\n",
    "```\n",
    "\n",
    "This format is generated automatically by GPT-5.1 when using the apply_patch tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Start with Clear Instructions**: Provide detailed requirements for what you want to create or modify\n",
    "\n",
    "2. **Review Changes**: Always review the files created or modified by the agent before using them in production\n",
    "\n",
    "4. **Iterative Development**: Break complex tasks into smaller steps and verify each step before proceeding\n",
    "\n",
    "5. **Test Your Code**: Always test the generated code to ensure it works as expected\n",
    "\n",
    "6. **Handle Errors Gracefully**: The agent can fix bugs, but it's good practice to review error messages carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "1. **File Not Found Errors**: Make sure the file path is correct relative to the workspace directory\n",
    "\n",
    "2. **Permission Errors**: Ensure the agent has write permissions to the workspace directory\n",
    "\n",
    "3. **Invalid Diff Format**: If you manually create diffs, ensure they follow the unified diff format correctly\n",
    "\n",
    "4. **API Errors**: Verify your OpenAI API key has access to GPT-5.1\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "For more information, check:\n",
    "- [AG2 Documentation](https://docs.ag2.ai)\n",
    "- [OpenAI Responses API Documentation](https://platform.openai.com/docs/api-reference/responses)\n",
    "- [GitHub Issues](https://github.com/AG2ai/ag2/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand how to use the apply_patch tool, you can:\n",
    "\n",
    "- Create more complex applications\n",
    "- Integrate with other tools and agents\n",
    "- Build automated code generation workflows\n",
    "- Experiment with different approval mechanisms\n",
    "\n",
    "Happy coding! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Apply Patch Tool Example for GPT-5.1",
   "tags": [
    "tools",
    "apply_patch",
    "gpt-5.1",
    "gpt-5",
    "in-built-tool"
   ]
  },
  "kernelspec": {
   "display_name": "ag2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
