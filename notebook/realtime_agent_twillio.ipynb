{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "from typing import Annotated, Union\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, Request, WebSocket\n",
    "from fastapi.responses import HTMLResponse, JSONResponse\n",
    "from pydantic import BaseModel\n",
    "from twilio.twiml.voice_response import Connect, VoiceResponse\n",
    "\n",
    "from autogen.agentchat.realtime_agent import FunctionObserver, RealtimeAgent, TwilioAudioAdapter\n",
    "from autogen.agentchat.realtime_agent.swarm_observer import SwarmObserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PORT = int(os.getenv(\"PORT\", 5050))\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing the OpenAI API key. Please set it in the .env file.\")\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 45,  # change the seed for different trials\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-realtime-preview-2024-10-01\",\n",
    "            \"api_key\": OPENAI_API_KEY,\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "async def index_page():\n",
    "    return {\"message\": \"Twilio Media Stream Server is running!\"}\n",
    "\n",
    "\n",
    "@app.api_route(\"/incoming-call\", methods=[\"GET\", \"POST\"])\n",
    "async def handle_incoming_call(request: Request):\n",
    "    \"\"\"Handle incoming call and return TwiML response to connect to Media Stream.\"\"\"\n",
    "    response = VoiceResponse()\n",
    "    # <Say> punctuation to improve text-to-speech flow\n",
    "    response.say(\n",
    "        \"Please wait while we connect your call to the A. I. voice assistant, powered by Twilio and the Open-A.I. Realtime API\"\n",
    "    )\n",
    "    response.pause(length=1)\n",
    "    response.say(\"O.K. you can start talking!\")\n",
    "    host = request.url.hostname\n",
    "    connect = Connect()\n",
    "    connect.stream(url=f\"wss://{host}/media-stream\")\n",
    "    response.append(connect)\n",
    "    return HTMLResponse(content=str(response), media_type=\"application/xml\")\n",
    "\n",
    "\n",
    "@app.websocket(\"/media-stream\")\n",
    "async def handle_media_stream(websocket: WebSocket):\n",
    "    \"\"\"Handle WebSocket connections between Twilio and OpenAI.\"\"\"\n",
    "    await websocket.accept()\n",
    "\n",
    "    audio_adapter = TwilioAudioAdapter(websocket)\n",
    "    openai_client = RealtimeAgent(\n",
    "        name=\"Weather Bot\",\n",
    "        system_message=\"Hello there! I am an AI voice assistant powered by Twilio and the OpenAI Realtime API. You can ask me for facts, jokes, or anything you can imagine. How can I help you?\",\n",
    "        llm_config=llm_config,\n",
    "        audio_adapter=audio_adapter,\n",
    "    )\n",
    "\n",
    "    @openai_client.register_handover(name=\"get_weather\", description=\"Get the current weather\")\n",
    "    def get_weather(location: Annotated[str, \"city\"]) -> str:\n",
    "        ...\n",
    "        return \"The weather is cloudy.\" if location == \"Seattle\" else \"The weather is sunny.\"\n",
    "\n",
    "    await openai_client.run()\n",
    "\n",
    "\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With swarm questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "async def index_page():\n",
    "    return {\"message\": \"Twilio Media Stream Server is running!\"}\n",
    "\n",
    "\n",
    "@app.api_route(\"/incoming-call\", methods=[\"GET\", \"POST\"])\n",
    "async def handle_incoming_call(request: Request):\n",
    "    \"\"\"Handle incoming call and return TwiML response to connect to Media Stream.\"\"\"\n",
    "    response = VoiceResponse()\n",
    "    response.say(\n",
    "        \"Please wait while we connect your call to the A. I. voice assistant, powered by Twilio and the Open-A.I. Realtime API\"\n",
    "    )\n",
    "    response.pause(length=1)\n",
    "    response.say(\"O.K. you can start talking!\")\n",
    "    host = request.url.hostname\n",
    "    connect = Connect()\n",
    "    connect.stream(url=f\"wss://{host}/media-stream\")\n",
    "    response.append(connect)\n",
    "    return HTMLResponse(content=str(response), media_type=\"application/xml\")\n",
    "\n",
    "\n",
    "@app.websocket(\"/media-stream\")\n",
    "async def handle_media_stream(websocket: WebSocket):\n",
    "    \"\"\"Handle WebSocket connections between Twilio and OpenAI.\"\"\"\n",
    "    await websocket.accept()\n",
    "\n",
    "    audio_adapter = TwilioAudioAdapter(websocket)\n",
    "    realtime_agent = RealtimeAgent(\n",
    "        name=\"Customer service Bot\",\n",
    "        system_message=(\n",
    "            \"You are a helpful voice assistant. You are tasked with delegating tasks to a swarm of agents\\n\"\n",
    "            \"When a user calls in, you will need to ask the swarm for help to complete the task\\n\"\n",
    "            \"The swarm will ask questions and provide feedback to help you complete the task\\n\"\n",
    "            \"You can start the swarm by calling the function `start_swarm`\\n\"\n",
    "            \"After the swarm asks a question, you can answer it by calling the function `answer_swarm_question`\"\n",
    "        ),\n",
    "        llm_config=llm_config,\n",
    "        audio_adapter=audio_adapter,\n",
    "    )\n",
    "\n",
    "    class SwarmTaskInput(BaseModel):\n",
    "        task: str\n",
    "\n",
    "    class TaskEnd(BaseModel):\n",
    "        result: str\n",
    "\n",
    "    class TaskQuestion(BaseModel):\n",
    "        question: str\n",
    "\n",
    "    class TaskAnswer(BaseModel):\n",
    "        answer: str\n",
    "\n",
    "    swarm_started = False\n",
    "\n",
    "    @realtime_agent.register_handover(name=\"start_swarm\", description=\"Start a refund task using swarm intelligence\")\n",
    "    async def start_swarm(task_input: SwarmTaskInput) -> Union[TaskEnd, TaskQuestion]:\n",
    "        nonlocal swarm_started\n",
    "        swarm_started = True\n",
    "        await asyncio.sleep(2)\n",
    "        return TaskQuestion(\n",
    "            question=(\n",
    "                \"Need more info from user, ask him: 'What is your id number?'\\n\\n\"\n",
    "                \"After you get the answer from the user, call the function `answer_swarm_question` with the appropriate information to answer the question.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @realtime_agent.register_handover(name=\"answer_swarm_question\", description=\"Answer a question from the swarm\")\n",
    "    async def answer_swarm_question(answer: TaskAnswer) -> TaskEnd:\n",
    "        nonlocal swarm_started\n",
    "        if not swarm_started:\n",
    "            return \"Error: Swarm not started, call start_swarm first\"\n",
    "        await asyncio.sleep(2)\n",
    "        time.sleep(2)\n",
    "        return TaskEnd(result=\"We gave the user a refund for the last purchase.\")\n",
    "\n",
    "    await realtime_agent.run()\n",
    "\n",
    "\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=PORT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
