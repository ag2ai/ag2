{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/davor/projects/airt/ag2/.venv-3.9/lib/python3.9/site-packages/flaml/__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Annotated\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, Request, WebSocket\n",
    "from fastapi.responses import HTMLResponse, JSONResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.templating import Jinja2Templates\n",
    "\n",
    "from autogen.agentchat.realtime_agent import RealtimeAgent, WebsocketAudioAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PORT = int(os.getenv(\"PORT\", 5050))\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing the OpenAI API key. Please set it in the .env file.\")\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 45,  # change the seed for different trials\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-realtime-preview-2024-10-01\",\n",
    "            \"api_key\": OPENAI_API_KEY,\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [3287959]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39902 - \"GET /start-chat/ HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:39892 - \"GET /static/main.js HTTP/1.1\" 304 Not Modified\n",
      "INFO:     127.0.0.1:39902 - \"GET /static/wavtools.js HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:39902 - \"GET /static/Audio.js HTTP/1.1\" 304 Not Modified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     ('127.0.0.1', 39908) - \"WebSocket /media-stream\" [accepted]\n",
      "INFO:     connection open\n"
     ]
    }
   ],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "notebook_path = os.getcwd()\n",
    "\n",
    "app.mount(\n",
    "    \"/static\", StaticFiles(directory=Path(notebook_path) / \"agentchat_realtime_websocket\" / \"static\"), name=\"static\"\n",
    ")\n",
    "\n",
    "# Templates for HTML responses\n",
    "\n",
    "templates = Jinja2Templates(directory=Path(notebook_path) / \"agentchat_realtime_websocket\" / \"templates\")\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "async def index_page():\n",
    "    return {\"message\": \"Websocket Audio Stream Server is running!\"}\n",
    "\n",
    "\n",
    "@app.get(\"/start-chat/\", response_class=HTMLResponse)\n",
    "async def start_chat(request: Request):\n",
    "    \"\"\"Endpoint to return the HTML page for audio chat.\"\"\"\n",
    "    port = PORT  # Extract the client's port\n",
    "    return templates.TemplateResponse(\"chat.html\", {\"request\": request, \"port\": port})\n",
    "\n",
    "\n",
    "@app.websocket(\"/media-stream\")\n",
    "async def handle_media_stream(websocket: WebSocket):\n",
    "    \"\"\"Handle WebSocket connections providing audio stream and OpenAI.\"\"\"\n",
    "    await websocket.accept()\n",
    "\n",
    "    audio_adapter = WebsocketAudioAdapter(websocket)\n",
    "    realtime_agent = RealtimeAgent(\n",
    "        name=\"Weather Bot\",\n",
    "        system_message=\"Hello there! I am an AI voice assistant powered by Autogen and the OpenAI Realtime API. You can ask me about weather, jokes, or anything you can imagine. Start by saying How can I help you?\",\n",
    "        llm_config=llm_config,\n",
    "        audio_adapter=audio_adapter,\n",
    "    )\n",
    "\n",
    "    @realtime_agent.register_realtime_function(name=\"get_weather\", description=\"Get the current weather\")\n",
    "    def get_weather(location: Annotated[str, \"city\"]) -> str:\n",
    "        return \"The weather is cloudy.\" if location == \"Seattle\" else \"The weather is sunny.\"\n",
    "\n",
    "    await realtime_agent.run()\n",
    "\n",
    "\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
