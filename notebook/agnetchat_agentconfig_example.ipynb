{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgentConfig for Structured Outputs\n",
    "\n",
    "AG2 now supports an official `AgentConfig` class (from `autogen.llm_config`) for advanced per-agent configuration, such as specifying structured output schemas or agent-level API settings. This notebook demonstrates how to use `AgentConfig` to enable schema-based structured outputs in your agents.\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install `ag2`:\n",
    "\n",
    "pip install -U ag2[openai]\n",
    "```\n",
    "\n",
    "> **Note:** If you have been using `autogen` or `ag2`, all you need to do is upgrade it using:  \n",
    ">\n",
    "> pip install -U autogen\n",
    "> ```\n",
    "> or  \n",
    ">\n",
    "> pip install -U ag2\n",
    "> ```\n",
    "> as `autogen`, and `ag2` are aliases for the same PyPI package.  \n",
    "\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is AgentConfig?\n",
    "\n",
    "`AgentConfig` is a dedicated configuration class designed for per-agent settings in AG2. It provides a clean and explicit way to configure agent-specific features, particularly structured outputs through the `response_format` parameter.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Per-Agent Configuration**: Configure settings specific to individual agents without affecting others\n",
    "- **Structured Output Support**: Specify Pydantic models as `response_format` to enforce structured responses\n",
    "- **API Type Control**: Set `api_type` directly at the agent level\n",
    "- **Extensible Design**: Accepts additional configuration parameters through keyword arguments\n",
    "\n",
    "### Advantages over LLMConfig for Agent-Level Configuration:\n",
    "\n",
    "1. **Simplicity**: `AgentConfig` is designed specifically for agent-level configuration, making it more intuitive for per-agent settings\n",
    "2. **Clarity**: Explicitly indicates that the configuration is agent-specific, improving code readability\n",
    "3. **Flexibility**: Allows different agents in the same workflow to have different API types and response formats\n",
    "4. **Preference for Structured Outputs**: `AgentConfig` is often preferred for setting up structured outputs, as it provides a clean interface for schema-based results\n",
    "\n",
    "You can pass either `llm_config` (using `LLMConfig`) or `agent_config` (using `AgentConfig`) to agents, depending on your needs. Use `AgentConfig` when you want per-agent structured output or need to control how a particular agent interacts with the LLM API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Two-Agent Chat with Structured Outputs\n",
    "\n",
    "This example demonstrates how to use `AgentConfig` with structured outputs in a simple two-agent conversation. We'll create an assistant agent that responds with structured joke data, and a user proxy agent to interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from autogen import AgentConfig, AssistantAgent, LLMConfig, UserProxyAgent\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list=[\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"api_type\": \"openai\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define a structured output schema for the assistant's responses\n",
    "class JokeOutputSchema(BaseModel):\n",
    "    joke: str\n",
    "    explanation: str\n",
    "\n",
    "\n",
    "# Create AgentConfig with structured output and API type\n",
    "assistant_config = AgentConfig(\n",
    "    response_format=JokeOutputSchema,\n",
    "    api_type=\"openai\",\n",
    ")\n",
    "\n",
    "# Create the assistant agent with AgentConfig\n",
    "assistant = AssistantAgent(\n",
    "    \"assistant\",\n",
    "    agent_config=assistant_config,\n",
    "    system_message=\"You are a helpful assistant that tells jokes and explains them. Always structure your responses according to the JokeOutputSchema.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create the user proxy agent (no structured output needed)\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Two-Agent Chat\n",
    "\n",
    "Now let's initiate a conversation between the user proxy and the assistant. The assistant will respond with structured data matching our `JokeOutputSchema`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the chat\n",
    "\n",
    "result = user_proxy.run(\n",
    "    assistant,\n",
    "    message=\"Tell me a joke about NVDA and TESLA stock prices.\",\n",
    "    max_turns=1,\n",
    ")\n",
    "result.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: GroupChat with Multiple Agents Using Structured Outputs\n",
    "\n",
    "In this example, we'll create a GroupChat with multiple agents, each potentially using `AgentConfig` for structured outputs. This demonstrates how different agents can have different configurations in a multi-agent conversation.\n",
    "\n",
    "We'll create a scenario where:\n",
    "- A **Reviewer** agent provides structured feedback\n",
    "- A **Summarizer** agent provides structured summaries\n",
    "- A **User Proxy** agent coordinates the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from autogen import AgentConfig, AssistantAgent, LLMConfig, UserProxyAgent\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns.auto import AutoPattern\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list=[\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"api_type\": \"openai\",\n",
    "            \"response_format\": Answer,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define structured output schema for the Reviewer agent\n",
    "class ReviewFeedback(BaseModel):\n",
    "    rating: int  # 1-5 scale\n",
    "    strengths: list[str]\n",
    "    weaknesses: list[str]\n",
    "    recommendation: str\n",
    "\n",
    "\n",
    "# Define structured output schema for the Summarizer agent\n",
    "class SummaryOutput(BaseModel):\n",
    "    title: str\n",
    "    key_points: list[str]\n",
    "    conclusion: str\n",
    "\n",
    "\n",
    "# Create AgentConfig for the Reviewer agent\n",
    "reviewer_config = AgentConfig(\n",
    "    response_format=ReviewFeedback,\n",
    ")\n",
    "\n",
    "# Create AgentConfig for the Summarizer agent\n",
    "summarizer_config = AgentConfig(\n",
    "    response_format=SummaryOutput,\n",
    ")\n",
    "\n",
    "# Create the Reviewer agent with structured output\n",
    "reviewer = AssistantAgent(\n",
    "    name=\"reviewer\",\n",
    "    agent_config=reviewer_config,\n",
    "    system_message=\"You are a thorough reviewer. Analyze content and provide structured feedback with ratings, strengths, weaknesses, and recommendations.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create the Summarizer agent with structured output\n",
    "summarizer = AssistantAgent(\n",
    "    name=\"summarizer\",\n",
    "    agent_config=summarizer_config,\n",
    "    system_message=\"You are a concise summarizer. Create structured summaries with titles, key points, and conclusions.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create the User Proxy agent (no structured output needed)\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create GroupChat with all agents\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=user_proxy,\n",
    "    agents=[reviewer, summarizer, user_proxy],\n",
    "    group_manager_args={\n",
    "        \"llm_config\": llm_config,  # Use same config for group manager\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"AutoPattern created with structured output agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the GroupChat\n",
    "\n",
    "Now let's initiate the GroupChat. The reviewer and summarizer agents will provide structured responses according to their respective schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the GroupChat conversation\n",
    "result, context, last_agent = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"Please review and summarize this idea: Creating an AI-powered assistant for code review that provides structured feedback on code quality, security, and best practices.\",\n",
    "    max_rounds=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **AgentConfig is Ideal for Structured Outputs**: When you need to enforce structured responses from agents, `AgentConfig` provides a clean and explicit way to specify the `response_format` parameter.\n",
    "\n",
    "2. **Per-Agent Flexibility**: Different agents in the same workflow can have different structured output schemas, allowing for specialized agent roles with specific response formats.\n",
    "\n",
    "3. **Simplicity**: `AgentConfig` simplifies agent-level configuration, making it easier to understand and maintain code that uses structured outputs.\n",
    "\n",
    "4. **Integration with GroupChat**: `AgentConfig` works seamlessly with GroupChat, allowing multiple agents with different structured output schemas to collaborate effectively.\n",
    "\n",
    "5. **Clean System Messages**: With structured outputs, you don't need to include formatting instructions in system messages - the schema enforces the structure automatically.\n",
    "\n",
    "Remember: You can use either `llm_config` (with `LLMConfig`) or `agent_config` (with `AgentConfig`) depending on your needs. For per-agent structured outputs and clearer agent-specific configuration, `AgentConfig` is the preferred choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
