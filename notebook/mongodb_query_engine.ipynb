{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Query Engine Tutorial\n",
    "\n",
    "This notebook demonstrates the use of the `MongoDBQueryEngine` for retrieval-augmented question answering over documents using MongoDB. It shows how to set up the engine with MongoDB and simple text parser using LlamaIndex parsed Markdown files, and execute natural language queries against the indexed data. \n",
    "\n",
    "The `MongoDBQueryEngine` integrates cloud MongoDB Atlas but also MongoDB localhost vector storage with LlamaIndex for efficient document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index==0.12.16\n",
    "%pip install llama-index-llms-langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calling the `MongoDBQueryEngine`, we will create and import our own embedding function. You can replace this with any embedding function built-in from Langchain or Llama-Index or your custom build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=\"\",\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the folder path that contains our document that we want to input. In this case, I will use experimental document from ag2 test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/ag2/test/agents/experimental/document_agent/pdf_parsed/\"\n",
    "# you might need to change the folder path based on which folder you want to input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `MongoDBQueryEngine` with:\n",
    "- MongoDB Atlas Connection String (you can also provide your localhost MongoDB Connection String as well)\n",
    "- Pre-defined embedding function\n",
    "- Database Name\n",
    "- Pre-defined LLM Model (Optional)\n",
    "\n",
    "Beside that, you can also customize your `collection_name` and `index_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.rag.mongodb_query_engine import MongoDBQueryEngine\n",
    "\n",
    "query_engine = MongoDBQueryEngine(\n",
    "    connection_string=\"\", embedding_function=openai_ef, database_name=\"vector_db\", llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is our first time running this and we do not have any database yet so we will call the `init_db` function along with a list of input document or folder path that we want.\n",
    "\n",
    "You can also use this `init_db` to overwrite and re-create your database again as well, simply use the arg `overwrite = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia_10k_2024.md\n",
    "query_engine.init_db(new_doc_paths=[input_dir + \"Toast_financial_report.md\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `query` to answer user input question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the trading symbol for Toast\"\n",
    "answer = query_engine.query(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add-on new document, we can use `add_records`, this could take new document path or new document dir as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.add_records(new_doc_paths_or_urls=[input_dir + \"nvidia_10k_2024.md\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_engine.query(\"How much money did Nvidia spend in research and development\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case that you already have a MongoDB Vector Database and you just want to connect to it without having to initialize it again, you can call the `connect_db`. You can also overwrite and re-setup your connected Vector Database by using the arg `overwrite=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_engine.query(\"How much money did Nvidia spend in research and development\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
