{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neo4jGraphRagCapability with agents for GraphRAG Question & Answering\n",
    "\n",
    "AG2 provides GraphRAG integration using agent capabilities. This is an example to integrate Neo4j (a Property/Knowledge Graph database).\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "llama-index dependencies, which is required to use Neo4j prpoerty graph\n",
    "\n",
    "```bash\n",
    "pip llama-index llama-index-graph-stores-neo4j\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configuration and OpenAI API Key\n",
    "\n",
    "By default, in order to use FalkorDB you need to have an OpenAI key in your environment variable `OPENAI_API_KEY`.\n",
    "\n",
    "You can utilise an OAI_CONFIG_LIST file and extract the OpenAI API key and put it in the environment, as will be shown in the following cell.\n",
    "\n",
    "Alternatively, you can load the environment variable yourself.\n",
    "\n",
    "````{=mdx}\n",
    ":::tip\n",
    "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\", file_location=\"../\")\n",
    "\n",
    "# Put the OpenAI API key into the environment\n",
    "os.environ[\"OPENAI_API_KEY\"] = config_list[0][\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{=mdx}\n",
    ":::important\n",
    "The default model for loading graph data and answering questions using Neo4j is OpenAI's GPT 3.5-turbo, and the default embedding model is OpenAI's text-embedding-3-small,  This can be changed by setting the `model`and 'embed-model' parameter on the Neo4jGraphQueryEngine.\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to allow nested asyncio calls for Neo4j in Jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Knowledge Graph with Your Own Data\n",
    "\n",
    "**Note:** You need to have a Neo4j database running. If you are running one in a Docker container, please ensure your Docker network is setup to allow access to it. \n",
    "\n",
    "In this example, the Neo4j endpoint is set to host=\"bolt://172.17.0.4\" and port=7687, please adjust accordingly. For how to spin up a Neo4j with Docker, you can refer to [this](https://docs.llamaindex.ai/en/stable/examples/property_graph/property_graph_neo4j/#:~:text=stores%2Dneo4j-,Docker%20Setup,%C2%B6,-To%20launch%20Neo4j)\n",
    "\n",
    "Below, we have some sample data from Paul Grahma's [essay](https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt).\n",
    "\n",
    "We then initialise the database with that text document, creating the graph in Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Example\n",
    "\n",
    "In this example, the graph schema is auto-generated. This allows you to load data without specifying the specific types of entities and relationships that will make up the database (however, this may not be optimal and not cost efficient). \n",
    "First, we create a Neo4j property graph with Paul Grahma's essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: \"MATCH (n:`Chunk`)\\nWITH collect(distinct substring(toString(coalesce(n.`doc_id`, '')), 0, 50)) AS `doc_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`document_id`, '')), 0, 50)) AS `document_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`creation_date`, '')), 0, 50)) AS `creation_date_values`,\\n     collect(distinct substring(toString(coalesce(n.`_node_type`, '')), 0, 50)) AS `_node_type_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_type`, '')), 0, 50)) AS `file_type_values`,\\n     collect(distinct substring(toString(coalesce(n.`last_modified_date`, '')), 0, 50)) AS `last_modified_date_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_name`, '')), 0, 50)) AS `file_name_values`,\\n     collect(distinct substring(toString(coalesce(n.`_node_content`, '')), 0, 50)) AS `_node_content_values`,\\n     collect(distinct substring(toString(coalesce(n.`ref_doc_id`, '')), 0, 50)) AS `ref_doc_id_values`,\\n     min(size(coalesce(n.`embedding`, []))) AS `embedding_size_min`, max(size(coalesce(n.`embedding`, []))) AS `embedding_size_max`,\\n     collect(distinct substring(toString(coalesce(n.`text`, '')), 0, 50)) AS `text_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_path`, '')), 0, 50)) AS `file_path_values`,\\n     min(n.`file_size`) AS `file_size_min`,\\n     max(n.`file_size`) AS `file_size_max`,\\n     count(distinct n.`file_size`) AS `file_size_distinct`,\\n     collect(distinct substring(toString(coalesce(n.`id`, '')), 0, 50)) AS `id_values`\\nRETURN {`doc_id`: {values:`doc_id_values`[..10], distinct_count: size(`doc_id_values`)}, `document_id`: {values:`document_id_values`[..10], distinct_count: size(`document_id_values`)}, `creation_date`: {values:`creation_date_values`[..10], distinct_count: size(`creation_date_values`)}, `_node_type`: {values:`_node_type_values`[..10], distinct_count: size(`_node_type_values`)}, `file_type`: {values:`file_type_values`[..10], distinct_count: size(`file_type_values`)}, `last_modified_date`: {values:`last_modified_date_values`[..10], distinct_count: size(`last_modified_date_values`)}, `file_name`: {values:`file_name_values`[..10], distinct_count: size(`file_name_values`)}, `_node_content`: {values:`_node_content_values`[..10], distinct_count: size(`_node_content_values`)}, `ref_doc_id`: {values:`ref_doc_id_values`[..10], distinct_count: size(`ref_doc_id_values`)}, `embedding`: {min_size: `embedding_size_min`, max_size: `embedding_size_max`}, `text`: {values:`text_values`[..10], distinct_count: size(`text_values`)}, `file_path`: {values:`file_path_values`[..10], distinct_count: size(`file_path_values`)}, `file_size`: {min: toString(`file_size_min`), max: toString(`file_size_max`), distinct_count: `file_size_distinct`}, `id`: {values:`id_values`[..10], distinct_count: size(`id_values`)}} AS output\"\n",
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s]\n",
      "Extracting paths from text with schema: 100%|██████████| 22/22 [00:42<00:00,  1.93s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: \"MATCH (n:`Chunk`)\\nWITH collect(distinct substring(toString(coalesce(n.`doc_id`, '')), 0, 50)) AS `doc_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`document_id`, '')), 0, 50)) AS `document_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`creation_date`, '')), 0, 50)) AS `creation_date_values`,\\n     collect(distinct substring(toString(coalesce(n.`_node_type`, '')), 0, 50)) AS `_node_type_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_type`, '')), 0, 50)) AS `file_type_values`,\\n     collect(distinct substring(toString(coalesce(n.`last_modified_date`, '')), 0, 50)) AS `last_modified_date_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_name`, '')), 0, 50)) AS `file_name_values`,\\n     collect(distinct substring(toString(coalesce(n.`_node_content`, '')), 0, 50)) AS `_node_content_values`,\\n     collect(distinct substring(toString(coalesce(n.`ref_doc_id`, '')), 0, 50)) AS `ref_doc_id_values`,\\n     min(size(coalesce(n.`embedding`, []))) AS `embedding_size_min`, max(size(coalesce(n.`embedding`, []))) AS `embedding_size_max`,\\n     collect(distinct substring(toString(coalesce(n.`text`, '')), 0, 50)) AS `text_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_path`, '')), 0, 50)) AS `file_path_values`,\\n     min(n.`file_size`) AS `file_size_min`,\\n     max(n.`file_size`) AS `file_size_max`,\\n     count(distinct n.`file_size`) AS `file_size_distinct`,\\n     collect(distinct substring(toString(coalesce(n.`id`, '')), 0, 50)) AS `id_values`\\nRETURN {`doc_id`: {values:`doc_id_values`[..10], distinct_count: size(`doc_id_values`)}, `document_id`: {values:`document_id_values`[..10], distinct_count: size(`document_id_values`)}, `creation_date`: {values:`creation_date_values`[..10], distinct_count: size(`creation_date_values`)}, `_node_type`: {values:`_node_type_values`[..10], distinct_count: size(`_node_type_values`)}, `file_type`: {values:`file_type_values`[..10], distinct_count: size(`file_type_values`)}, `last_modified_date`: {values:`last_modified_date_values`[..10], distinct_count: size(`last_modified_date_values`)}, `file_name`: {values:`file_name_values`[..10], distinct_count: size(`file_name_values`)}, `_node_content`: {values:`_node_content_values`[..10], distinct_count: size(`_node_content_values`)}, `ref_doc_id`: {values:`ref_doc_id_values`[..10], distinct_count: size(`ref_doc_id_values`)}, `embedding`: {min_size: `embedding_size_min`, max_size: `embedding_size_max`}, `text`: {values:`text_values`[..10], distinct_count: size(`text_values`)}, `file_path`: {values:`file_path_values`[..10], distinct_count: size(`file_path_values`)}, `file_size`: {min: toString(`file_size_min`), max: toString(`file_size_max`), distinct_count: `file_size_distinct`}, `id`: {values:`id_values`[..10], distinct_count: size(`id_values`)}} AS output\"\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.graph_rag.document import Document, DocumentType\n",
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_query_engine import Neo4jGraphQueryEngine\n",
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_rag_capability import Neo4jGraphCapability\n",
    "\n",
    "# Auto generate graph schema from unstructured data\n",
    "input_path = \"../test/agentchat/contrib/graph_rag/paul_graham_essay.txt\"\n",
    "input_documents = [Document(doctype=DocumentType.TEXT, path_or_url=input_path)]\n",
    "\n",
    "# Create FalkorGraphQueryEngine\n",
    "query_engine = Neo4jGraphQueryEngine(\n",
    "    username=\"neo4j\",  # Change if you reset username\n",
    "    password=\"password\",  # Change if you reset password\n",
    "    host=\"bolt://172.17.0.4\",  # Change\n",
    "    port=7687,  # if needed\n",
    "    database=\"neo4j\",  # Change if you want to store the graphh in your custom database\n",
    ")\n",
    "\n",
    "# Ingest data and initialize the database\n",
    "query_engine.init_db(input_doc=input_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add capability to a ConversableAgent and query them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "What happened at Interleaf and Viaweb?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "At Interleaf, a scripting language inspired by Emacs was added, with the scripting language being a dialect of Lisp. At Viaweb, there was a code editor for users to define their own page styles, which involved editing Lisp expressions underneath. Additionally, Viaweb had to recruit an initial set of users privately before launching publicly to ensure they had decent-looking stores.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "How does paul graham do at Interleaf\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Paul Graham did not perform well at Interleaf. He mentioned that he was a bad employee, as he did not understand most of the software due to his lack of knowledge in C and his reluctance to learn it. Additionally, he admitted to being terribly irresponsible during his time at Interleaf.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "What's his relation to Viaweb? Did he do anything there?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Paul Graham worked on Viaweb and had a code editor implemented within the platform.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "What did Paul gramham do for KFC?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Paul Graham did not work for KFC.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What happened at Interleaf and Viaweb?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'At Interleaf, a scripting language inspired by Emacs was added, with the scripting language being a dialect of Lisp. At Viaweb, there was a code editor for users to define their own page styles, which involved editing Lisp expressions underneath. Additionally, Viaweb had to recruit an initial set of users privately before launching publicly to ensure they had decent-looking stores.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'How does paul graham do at Interleaf', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Paul Graham did not perform well at Interleaf. He mentioned that he was a bad employee, as he did not understand most of the software due to his lack of knowledge in C and his reluctance to learn it. Additionally, he admitted to being terribly irresponsible during his time at Interleaf.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': \"What's his relation to Viaweb? Did he do anything there?\", 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Paul Graham worked on Viaweb and had a code editor implemented within the platform.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'What did Paul gramham do for KFC?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Paul Graham did not work for KFC.', 'role': 'user', 'name': 'paul_graham_agent'}], summary='Paul Graham did not work for KFC.', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['How does paul graham do at Interleaf', \"What's his relation to Viaweb? Did he do anything there?\", 'What did Paul gramham do for KFC?', 'exit'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a ConversableAgent (no LLM configuration)\n",
    "graph_rag_agent = ConversableAgent(\n",
    "    name=\"paul_graham_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Associate the capability with the agent\n",
    "graph_rag_capability = Neo4jGraphCapability(query_engine)\n",
    "graph_rag_capability.add_to_agent(graph_rag_agent)\n",
    "\n",
    "# Create a user proxy agent to converse with our RAG agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(graph_rag_agent, message=\"What happened at Interleaf and Viaweb?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
