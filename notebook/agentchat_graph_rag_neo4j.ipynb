{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neo4jGraphRagCapability with agents for GraphRAG Question & Answering\n",
    "\n",
    "AG2 provides GraphRAG integration using agent capabilities. This is an example to integrate Neo4j (a Property/Knowledge Graph database).\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "llama-index dependencies, which is required to use Neo4j prpoerty graph\n",
    "\n",
    "```bash\n",
    "pip install llama-index==0.11.8 llama-index-graph-stores-neo4j==0.3.0 llama-index-core==0.11.8\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configuration and OpenAI API Key\n",
    "\n",
    "By default, in order to use FalkorDB you need to have an OpenAI key in your environment variable `OPENAI_API_KEY`.\n",
    "\n",
    "You can utilise an OAI_CONFIG_LIST file and extract the OpenAI API key and put it in the environment, as will be shown in the following cell.\n",
    "\n",
    "Alternatively, you can load the environment variable yourself.\n",
    "\n",
    "````{=mdx}\n",
    ":::tip\n",
    "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\", file_location=\"../\")\n",
    "\n",
    "# Put the OpenAI API key into the environment\n",
    "os.environ[\"OPENAI_API_KEY\"] = config_list[0][\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to allow nested asyncio calls for Neo4j in Jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Information: Using Neo4j with OpenAI Models ðŸš€\n",
    "\n",
    "> **Important**  \n",
    "> - **Default Models**:\n",
    ">   - **Question Answering**: OpenAI's `GPT-3.5-turbo` with `temperature=0.0`.\n",
    ">   - **Embedding**: OpenAI's `text-embedding-3-small`.\n",
    "> \n",
    "> - **Customization**:\n",
    ">   You can change these defaults by setting the following parameters on the `Neo4jGraphQueryEngine`:\n",
    ">   - `model`: Specify a different LLM model.\n",
    ">   - `temperature`: Specify a different temperature.\n",
    ">   - `embed_model`: Specify a different embedding model.\n",
    "\n",
    "### Additional Notes\n",
    "If you see an **Assertion error**, simply rerun the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Knowledge Graph with Your Own Data\n",
    "\n",
    "**Note:** You need to have a Neo4j database running. If you are running one in a Docker container, please ensure your Docker network is setup to allow access to it. \n",
    "\n",
    "In this example, the Neo4j endpoint is set to host=\"bolt://172.17.0.4\" and port=7687, please adjust accordingly. For how to spin up a Neo4j with Docker, you can refer to [this](https://docs.llamaindex.ai/en/stable/examples/property_graph/property_graph_neo4j/#:~:text=stores%2Dneo4j-,Docker%20Setup,%C2%B6,-To%20launch%20Neo4j)\n",
    "\n",
    "Below, we have some sample data from Paul Grahma's [essay](https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt).\n",
    "\n",
    "We then initialise the database with that text document, creating the graph in Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Example\n",
    "\n",
    "In this example, the graph schema is auto-generated. This allows you to load data without specifying the specific types of entities and relationships that will make up the database (however, this may not be optimal and not cost efficient). \n",
    "First, we create a Neo4j property graph (knowledge graph) with Paul Grahma's essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n",
      "Parsing nodes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.09it/s]\n",
      "Extracting paths from text with schema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:48<00:00,  2.18s/it]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.75s/it]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (e, row) { ... }} {position: line: 10, column: 21, offset: 397} for query: \"\\n                    UNWIND $data AS row\\n                    MERGE (e:__Node__ {id: row.id})\\n                    SET e += apoc.map.clean(row.properties, [], [])\\n                    SET e.name = row.name, e:`__Entity__`\\n                    WITH e, row\\n                    CALL apoc.create.addLabels(e, [row.label])\\n                    YIELD node\\n                    WITH e, row\\n                    CALL {\\n                        WITH e, row\\n                        WITH e, row\\n                        WHERE row.embedding IS NOT NULL\\n                        CALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\\n                        RETURN count(*) AS count\\n                    }\\n                    WITH e, row WHERE row.properties.triplet_source_id IS NOT NULL\\n                    MERGE (c:__Node__ {id: row.properties.triplet_source_id})\\n                    MERGE (e)<-[:MENTIONS]-(c)\\n                    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.graph_rag.document import Document, DocumentType\n",
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_query_engine import Neo4jGraphQueryEngine\n",
    "\n",
    "# Auto generate graph schema from unstructured data\n",
    "input_path = \"../test/agentchat/contrib/graph_rag/paul_graham_essay.txt\"\n",
    "input_documents = [Document(doctype=DocumentType.TEXT, path_or_url=input_path)]\n",
    "\n",
    "# Create FalkorGraphQueryEngine\n",
    "query_engine = Neo4jGraphQueryEngine(\n",
    "    username=\"neo4j\",  # Change if you reset username\n",
    "    password=\"password\",  # Change if you reset password\n",
    "    host=\"bolt://172.17.0.2\",  # Change\n",
    "    port=7687,  # if needed\n",
    "    model=\"gpt-3.5-turbo\",  # default model\n",
    "    temperature=0.0,  # default temperature\n",
    "    database=\"neo4j\",  # Change if you want to store the graphh in your custom database\n",
    ")\n",
    "\n",
    "# Ingest data and initialize the database\n",
    "query_engine.init_db(input_doc=input_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add capability to a ConversableAgent and query them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "What happened at Interleaf and Viaweb?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Interleaf was a company that had smart people and built impressive technology but got crushed by Moore's Law in the 1990s. On the other hand, Viaweb was a company founded by the author and his partner to put art galleries online. However, they realized that art galleries didn't want to be online, and they pivoted to building online stores instead. They developed software to generate web stores and transitioned to creating web apps that allowed users to control the software through a browser, leading to the establishment of Viaweb as a pioneering web application company.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "What did Paul Graham do at Interleaf\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Paul Graham did freelance Lisp hacking work at Interleaf.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Did he work well?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "He demonstrated a strong work ethic and a willingness to explore various projects and opportunities, which ultimately led to successful endeavors such as writing essays, developing spam filters, investing in startups, and founding an investment firm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Did he work well at Interleaf?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "He was nervous about money at Interleaf as he sensed the company was on the way down. He decided to write another book on Lisp to secure his financial situation. Ultimately, he chose to drop out of RISD and pursue other opportunities.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Did Paul Graham like eating burger?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "There is no information provided in the context about Paul Graham's preference for eating burgers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What happened at Interleaf and Viaweb?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': \"Interleaf was a company that had smart people and built impressive technology but got crushed by Moore's Law in the 1990s. On the other hand, Viaweb was a company founded by the author and his partner to put art galleries online. However, they realized that art galleries didn't want to be online, and they pivoted to building online stores instead. They developed software to generate web stores and transitioned to creating web apps that allowed users to control the software through a browser, leading to the establishment of Viaweb as a pioneering web application company.\", 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'What did Paul Graham do at Interleaf', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Paul Graham did freelance Lisp hacking work at Interleaf.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'Did he work well?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'He demonstrated a strong work ethic and a willingness to explore various projects and opportunities, which ultimately led to successful endeavors such as writing essays, developing spam filters, investing in startups, and founding an investment firm.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'Did he work well at Interleaf?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'He was nervous about money at Interleaf as he sensed the company was on the way down. He decided to write another book on Lisp to secure his financial situation. Ultimately, he chose to drop out of RISD and pursue other opportunities.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'Did Paul Graham like eating burger?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': \"There is no information provided in the context about Paul Graham's preference for eating burgers.\", 'role': 'user', 'name': 'paul_graham_agent'}], summary=\"There is no information provided in the context about Paul Graham's preference for eating burgers.\", cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['What did Paul Graham do at Interleaf', 'Did he work well?', 'Did he work well at Interleaf?', 'Did Paul Graham like eating burger?', 'exit'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_rag_capability import Neo4jGraphCapability\n",
    "\n",
    "# Create a ConversableAgent (no LLM configuration)\n",
    "graph_rag_agent = ConversableAgent(\n",
    "    name=\"paul_graham_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Associate the capability with the agent\n",
    "graph_rag_capability = Neo4jGraphCapability(query_engine)\n",
    "graph_rag_capability.add_to_agent(graph_rag_agent)\n",
    "\n",
    "# Create a user proxy agent to converse with our RAG agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(graph_rag_agent, message=\"What happened at Interleaf and Viaweb?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisit the example by defining custom entities, relations and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n",
      "Parsing nodes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.27it/s]\n",
      "Extracting paths from text with schema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:56<00:00,  2.59s/it]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.02it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (e, row) { ... }} {position: line: 10, column: 21, offset: 397} for query: \"\\n                    UNWIND $data AS row\\n                    MERGE (e:__Node__ {id: row.id})\\n                    SET e += apoc.map.clean(row.properties, [], [])\\n                    SET e.name = row.name, e:`__Entity__`\\n                    WITH e, row\\n                    CALL apoc.create.addLabels(e, [row.label])\\n                    YIELD node\\n                    WITH e, row\\n                    CALL {\\n                        WITH e, row\\n                        WITH e, row\\n                        WHERE row.embedding IS NOT NULL\\n                        CALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\\n                        RETURN count(*) AS count\\n                    }\\n                    WITH e, row WHERE row.properties.triplet_source_id IS NOT NULL\\n                    MERGE (c:__Node__ {id: row.properties.triplet_source_id})\\n                    MERGE (e)<-[:MENTIONS]-(c)\\n                    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.graph_rag.document import Document, DocumentType\n",
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_query_engine import Neo4jGraphQueryEngine\n",
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_rag_capability import Neo4jGraphCapability\n",
    "\n",
    "# load document\n",
    "input_path = \"../test/agentchat/contrib/graph_rag/paul_graham_essay.txt\"\n",
    "input_documents = [Document(doctype=DocumentType.TEXT, path_or_url=input_path)]\n",
    "\n",
    "\n",
    "# best practice to use upper-case\n",
    "entities = Literal[\"PERSON\", \"PLACE\", \"ORGANIZATION\"]  #\n",
    "relations = Literal[\"HAS\", \"PART_OF\", \"WORKED_ON\", \"WORKED_WITH\", \"WORKED_AT\"]\n",
    "\n",
    "# define which entities can have which relations\n",
    "validation_schema = {\n",
    "    \"PERSON\": [\"HAS\", \"PART_OF\", \"WORKED_ON\", \"WORKED_WITH\", \"WORKED_AT\"],\n",
    "    \"PLACE\": [\"HAS\", \"PART_OF\", \"WORKED_AT\"],\n",
    "    \"ORGANIZATION\": [\"HAS\", \"PART_OF\", \"WORKED_WITH\"],\n",
    "}\n",
    "\n",
    "# Create FalkorGraphQueryEngine\n",
    "query_engine = Neo4jGraphQueryEngine(\n",
    "    username=\"neo4j\",  # Change if you reset username\n",
    "    password=\"password\",  # Change if you reset password\n",
    "    host=\"bolt://172.17.0.2\",  # Change\n",
    "    port=7687,  # if needed\n",
    "    database=\"neo4j\",  # Change if you want to store the graphh in your custom database\n",
    "    entities=entities,  # possible entities\n",
    "    relations=relations,  # possible relations\n",
    "    validation_schema=validation_schema,  # schema to validate the extracted triplets\n",
    "    strict=True,  # enofrce the extracted triplets to be in the schema\n",
    ")\n",
    "\n",
    "# Ingest data and initialize the database\n",
    "query_engine.init_db(input_doc=input_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add capability to a ConversableAgent and query them again\n",
    "You should find the answers conform to your custom schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Which companies did Paul Graham work for?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Paul Graham worked for Y Combinator (YC).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "who did he worked with?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Jessica\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Give me more people he worked with\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Trevor Blackwell, John Collison, Patrick Collison, Daniel Gackle, Ralph Hazell, Robert Morris, and Harj Taggar.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Did he worked with Joe Biden?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "No, there is no mention or indication in the provided context information that he worked with Joe Biden.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Which companies did Paul Graham work for?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Paul Graham worked for Y Combinator (YC).', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'who did he worked with?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Jessica', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'Give me more people he worked with', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Trevor Blackwell, John Collison, Patrick Collison, Daniel Gackle, Ralph Hazell, Robert Morris, and Harj Taggar.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'Did he worked with Joe Biden?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'No, there is no mention or indication in the provided context information that he worked with Joe Biden.', 'role': 'user', 'name': 'paul_graham_agent'}], summary='No, there is no mention or indication in the provided context information that he worked with Joe Biden.', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['who did he worked with?', 'Give me more people he worked with', 'Did he worked with Joe Biden?', 'exit'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_rag_capability import Neo4jGraphCapability\n",
    "\n",
    "# Create a ConversableAgent (no LLM configuration)\n",
    "graph_rag_agent = ConversableAgent(\n",
    "    name=\"paul_graham_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Associate the capability with the agent\n",
    "graph_rag_capability = Neo4jGraphCapability(query_engine)\n",
    "graph_rag_capability.add_to_agent(graph_rag_agent)\n",
    "\n",
    "# Create a user proxy agent to converse with our RAG agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(graph_rag_agent, message=\"Which companies did Paul Graham work for?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can add new documents to the existing knoweldge graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.01it/s]\n",
      "Extracting paths from text with schema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.14s/it]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (e, row) { ... }} {position: line: 10, column: 21, offset: 397} for query: \"\\n                    UNWIND $data AS row\\n                    MERGE (e:__Node__ {id: row.id})\\n                    SET e += apoc.map.clean(row.properties, [], [])\\n                    SET e.name = row.name, e:`__Entity__`\\n                    WITH e, row\\n                    CALL apoc.create.addLabels(e, [row.label])\\n                    YIELD node\\n                    WITH e, row\\n                    CALL {\\n                        WITH e, row\\n                        WITH e, row\\n                        WHERE row.embedding IS NOT NULL\\n                        CALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\\n                        RETURN count(*) AS count\\n                    }\\n                    WITH e, row WHERE row.properties.triplet_source_id IS NOT NULL\\n                    MERGE (c:__Node__ {id: row.properties.triplet_source_id})\\n                    MERGE (e)<-[:MENTIONS]-(c)\\n                    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "input_path = \"../test/agentchat/contrib/graph_rag/the_matrix.txt\"\n",
    "input_documents = [Document(doctype=DocumentType.TEXT, path_or_url=input_path)]\n",
    "\n",
    "_ = query_engine.add_records(input_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create a new graph rag agent and some quetions related to both 2 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Who acted at 'The Matrix'?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, and Hugo Weaving acted in 'The Matrix'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "Is there any addictional actors?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "No, there is no mention of additional actors in the provided context information.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to paul_graham_agent):\n",
      "\n",
      "How did Paul Graham work at 'The Matrix'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpaul_graham_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Paul Graham did not work at 'The Matrix'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"Who acted at 'The Matrix'?\", 'role': 'assistant', 'name': 'user_proxy'}, {'content': \"Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, and Hugo Weaving acted in 'The Matrix'.\", 'role': 'user', 'name': 'paul_graham_agent'}, {'content': 'Is there any addictional actors?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'No, there is no mention of additional actors in the provided context information.', 'role': 'user', 'name': 'paul_graham_agent'}, {'content': \"How did Paul Graham work at 'The Matrix'\", 'role': 'assistant', 'name': 'user_proxy'}, {'content': \"Paul Graham did not work at 'The Matrix'.\", 'role': 'user', 'name': 'paul_graham_agent'}], summary=\"Paul Graham did not work at 'The Matrix'.\", cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['Is there any addictional actors?', \"How did Paul Graham work at 'The Matrix'\", 'exit'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.graph_rag.neo4j_graph_rag_capability import Neo4jGraphCapability\n",
    "\n",
    "# Create a ConversableAgent (no LLM configuration)\n",
    "graph_rag_agent = ConversableAgent(\n",
    "    name=\"paul_graham_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Associate the capability with the agent\n",
    "graph_rag_capability = Neo4jGraphCapability(query_engine)\n",
    "graph_rag_capability.add_to_agent(graph_rag_agent)\n",
    "\n",
    "# Create a user proxy agent to converse with our RAG agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(graph_rag_agent, message=\"Who acted at 'The Matrix'?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
