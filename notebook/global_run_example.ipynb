{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig, run\n",
    "from autogen.agentchat.groupchat.groupchat import GroupChatManager\n",
    "\n",
    "# todo: rename autogen.messages to autogen.events\n",
    "# rename messages to events\n",
    "# keep all names in autogen.message with deprecation message and import from autogen.events\n",
    "from autogen.events.agent_events import InputRequestEvent\n",
    "from autogen.io.event_processors import ConsoleEventProcessor\n",
    "from autogen.tools import tool\n",
    "\n",
    "llm_config = LLMConfig.from_json(path=\"OAI_CONFIG_LIST\").where(model=[\"gpt-4o-mini\"], api_type=\"openai\")\n",
    "\n",
    "llm_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def get_meaning_of_life():\n",
    "    return \"The meaning of life is 42.\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    agent = ConversableAgent(name=\"Alice\")\n",
    "\n",
    "get_meaning_of_life.register_for_llm(agent)\n",
    "\n",
    "response = run(\n",
    "    agent,\n",
    "    message=\"What is the meaning of life?\",\n",
    "    # I renamed initial_message to message\n",
    "    max_turns=10,\n",
    ")\n",
    "\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.content.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want the initial message to be sent from `agent`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = run(\n",
    "    agent,\n",
    "    message=\"What is the meaning of life?\",\n",
    "    sender=agent,\n",
    "    # if omitted, the default sender will be a auto-created user proxy agent\n",
    "    max_turns=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With console processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def get_meaning_of_life():\n",
    "    return \"The meaning of life is 42.\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    agent = ConversableAgent(name=\"Alice\")\n",
    "\n",
    "get_meaning_of_life.register_for_llm(agent)\n",
    "\n",
    "response = run(\n",
    "    agent,\n",
    "    message=\"What is the meaning of life?\",\n",
    "    max_turns=5,\n",
    "    user_input=True,\n",
    ")\n",
    "\n",
    "processor = ConsoleEventProcessor()\n",
    "processor.process(response)\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    agent_1 = ConversableAgent(name=\"Jane\")\n",
    "    agent_2 = ConversableAgent(name=\"Bob\")\n",
    "\n",
    "response = run(\n",
    "    sender=agent_1,\n",
    "    recipient=agent_2,\n",
    "    message=\"have a joke off\",\n",
    "    max_turns=5\n",
    ")\n",
    "# I used kwargs instead, because the original code\n",
    "# response = run(agent_1, agent_2, message=...)\n",
    "# is supposed to auto-create a user_proxy and send the message from it\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With event processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    agent_1 = ConversableAgent(name=\"Jane\")\n",
    "    agent_2 = ConversableAgent(name=\"Bob\")\n",
    "\n",
    "response = run(\n",
    "    sender=agent_1,\n",
    "    recipient=agent_2,\n",
    "    message=\"have a joke off\",\n",
    "    max_turns=5\n",
    ")\n",
    "\n",
    "ConsoleEventProcessor().process(response)\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi agent run with chat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def submit_plan(plan: str) -> str:\n",
    "    return f\"Plan submitted: {plan}\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    planner = ConversableAgent(\n",
    "        name=\"Planner\",\n",
    "        system_message=\"You are a planner. Collaborate with teacher and reviewer to create lesson plans.\",\n",
    "    )\n",
    "\n",
    "    reviewer = ConversableAgent(\n",
    "        name=\"Reviewer\",\n",
    "        system_message=\"You are a reviewer. Review lesson plans against 4th grade curriculum. Provide max 3 changes.\",\n",
    "    )\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        name=\"Teacher\",\n",
    "        system_message=\"You are a teacher. Choose topics and work with planner and reviewer. Say DONE! when finished.\",\n",
    "    )\n",
    "\n",
    "    chat_manager = GroupChatManager()\n",
    "\n",
    "submit_plan.register_for_llm(teacher)\n",
    "\n",
    "response = run(\n",
    "    planner,\n",
    "    reviewer,\n",
    "    teacher,\n",
    "    message=\"Create lesson plans for 4th grade.\",\n",
    "    chat_manager=chat_manager,\n",
    "    # a user_proxy is auto-created and then sends the message\n",
    ")\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With event processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def submit_plan(plan: str) -> str:\n",
    "    return f\"Plan submitted: {plan}\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    planner = ConversableAgent(\n",
    "        name=\"Planner\",\n",
    "        system_message=\"You are a planner. Collaborate with teacher and reviewer to create lesson plans.\",\n",
    "    )\n",
    "\n",
    "    reviewer = ConversableAgent(\n",
    "        name=\"Reviewer\",\n",
    "        system_message=\"You are a reviewer. Review lesson plans against 4th grade curriculum. Provide max 3 changes.\",\n",
    "    )\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        name=\"Teacher\",\n",
    "        system_message=\"You are a teacher. Choose topics and work with planner and reviewer. Say DONE! when finished.\",\n",
    "    )\n",
    "\n",
    "    chat_manager = GroupChatManager()\n",
    "\n",
    "submit_plan.register_for_llm(teacher)\n",
    "\n",
    "response = run(\n",
    "    planner,\n",
    "    reviewer,\n",
    "    teacher,\n",
    "    initial_message=\"Create lesson plans for 4th grade.\",\n",
    "    chat_manager=chat_manager,\n",
    ")\n",
    "\n",
    "ConsoleEventProcessor().process(response)\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swarm chat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "with llm_config:\n",
    "    # 1. Create our agents\n",
    "    planner_message = \"\"\"You are a classroom lesson planner.\n",
    "    Given a topic, write a lesson plan for a fourth grade class.\n",
    "    If you are given revision feedback, update your lesson plan and record it.\n",
    "    Use the following format:\n",
    "    <title>Lesson plan title</title>\n",
    "    <learning_objectives>Key learning objectives</learning_objectives>\n",
    "    <script>How to introduce the topic to the kids</script>\n",
    "    \"\"\"\n",
    "\n",
    "    planner = ConversableAgent(name=\"planner_agent\", system_message=planner_message)\n",
    "\n",
    "    reviewer_message = \"\"\"You are a classroom lesson reviewer.\n",
    "    You compare the lesson plan to the fourth grade curriculum\n",
    "    and provide a maximum of 3 recommended changes for each review.\n",
    "    Make sure you provide recommendations each time the plan is updated.\n",
    "    \"\"\"\n",
    "\n",
    "    reviewer = ConversableAgent(name=\"reviewer_agent\", system_message=reviewer_message)\n",
    "\n",
    "    teacher_message = \"\"\"You are a classroom teacher.\n",
    "    You decide topics for lessons and work with a lesson planner.\n",
    "    and reviewer to create and finalise lesson plans.\n",
    "    \"\"\"\n",
    "\n",
    "    teacher = ConversableAgent(name=\"teacher_agent\", system_message=teacher_message)\n",
    "\n",
    "    # We will unify GroupChatManager and SwarmManager and only keep the former\n",
    "    chat_manager = GroupChatManager()\n",
    "\n",
    "response = run(\n",
    "    planner,\n",
    "    reviewer,\n",
    "    teacher,\n",
    "    message=\"Today, let's introduce our kids to the solar system.\",\n",
    "    chat_manager=chat_manager,\n",
    "    max_turns=5,\n",
    ")\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation 1: no user agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    chat_manager = GroupChatManager(user_agent=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation 2: user agent is manually provided instead of auto-created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import UserProxyAgent\n",
    "\n",
    "user_proxy = UserProxyAgent()\n",
    "\n",
    "with llm_config:\n",
    "    chat_manager = GroupChatManager(user_agent=user_proxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation 3: no auto-execution of function tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    chat_manager = GroupChatManager(auto_execute_func_tool=False)\n",
    "    # If any agent has function-based tools\n",
    "    # The user needs to provide some agent able to execute the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the design of `initiate_chats` to allow `run` to take a list of chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested inside an agent. No need to change the high-level API. Need to make sure\n",
    "the return type of `run` is aware that the chat may be paused in a nested chat\n",
    "and is able to resume from there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.11-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
