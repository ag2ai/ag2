{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig, run\n",
    "from autogen.agentchat.termination import Keyword, MaxTurns\n",
    "from autogen.events.agent_events import InputRequestEvent\n",
    "from autogen.io.event_processors import ConsoleEventProcessor\n",
    "from autogen.tools import tool\n",
    "\n",
    "llm_config = LLMConfig.from_json(path=\"OAI_CONFIG_LIST\").where(model=[\"gpt-4o-mini\"], api_type=\"openai\")\n",
    "\n",
    "llm_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def get_meaning_of_life():\n",
    "    return \"The meaning of life is 42.\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    agent = ConversableAgent(name=\"Alice\")\n",
    "\n",
    "get_meaning_of_life.register_for_llm(agent)\n",
    "\n",
    "response = run(\n",
    "    agent,  # or receiver=agent\n",
    "    message=\"What is the meaning of life?\",  # or message=\"What is the meaning of life?\"\n",
    "    terminate_on=MaxTurns(4) | Keyword(\"TERMINATE\"),  # implement arithmetic for this\n",
    "    # default values for the following arguments:\n",
    "    # sender=\"user\",  # if not specified, we assume the sender is the user\n",
    "    # run_pattern=RoundRobinRunPattern(),  # default run pattern is round robin\n",
    ")\n",
    "\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.content.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With console processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import UserProxyAgent\n",
    "\n",
    "\n",
    "@tool()\n",
    "def get_meaning_of_life():\n",
    "    return \"The meaning of life is 42.\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    agent = ConversableAgent(name=\"Alice\")\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"use_docker\": False})\n",
    "\n",
    "get_meaning_of_life.register_for_llm(agent)\n",
    "\n",
    "response = run(sender=user_proxy, receiver=agent, message=\"What is the meaning of life?\")\n",
    "\n",
    "processor = ConsoleEventProcessor()\n",
    "processor.process(response)\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    agent_1 = ConversableAgent(name=\"Jane\")\n",
    "    agent_2 = ConversableAgent(name=\"Bob\")\n",
    "\n",
    "response = run(sender=agent_1, receiver=agent_2, message=\"have a joke off\", terminate_on=MaxTurns(5))\n",
    "\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With event processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    agent_1 = ConversableAgent(name=\"Jane\")\n",
    "    agent_2 = ConversableAgent(name=\"Bob\")\n",
    "\n",
    "response = run(sender=agent_1, receiver=agent_2, message=\"have a joke off\", terminate_on=Keyword(\"TERMINATE\"))\n",
    "\n",
    "\n",
    "ConsoleEventProcessor().process(response)\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi agent run with chat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.run_patterns import GroupRunPattern\n",
    "\n",
    "\n",
    "@tool()\n",
    "def submit_plan(plan: str) -> str:\n",
    "    return f\"Plan submitted: {plan}\"\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    planner = ConversableAgent(\n",
    "        name=\"Planner\",\n",
    "        system_message=\"You are a planner. Collaborate with teacher and reviewer to create lesson plans.\",\n",
    "    )\n",
    "\n",
    "    reviewer = ConversableAgent(\n",
    "        name=\"Reviewer\",\n",
    "        system_message=\"You are a reviewer. Review lesson plans against 4th grade curriculum. Provide max 3 changes.\",\n",
    "    )\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        name=\"Teacher\",\n",
    "        system_message=\"You are a teacher. Choose topics and work with planner and reviewer. Say DONE! when finished.\",\n",
    "    )\n",
    "    run_pattern = GroupRunPattern(planner, reviewer, teacher)\n",
    "\n",
    "submit_plan.register_for_llm(teacher)\n",
    "\n",
    "response = run(\n",
    "    receiver=planner,\n",
    "    message=\"Create lesson plans for 4th grade.\",\n",
    "    run_pattern=run_pattern,\n",
    "    terminate_on=Keyword(\"DONE!\") | MaxTurns(10),\n",
    ")\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swarm chat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AfterWorkOption, ConversableAgent\n",
    "from autogen.run_patterns import SwarmRunPattern\n",
    "\n",
    "planner_message = \"\"\"You are a classroom lesson planner.\n",
    "Given a topic, write a lesson plan for a fourth grade class.\n",
    "If you are given revision feedback, update your lesson plan and record it.\n",
    "Use the following format:\n",
    "<title>Lesson plan title</title>\n",
    "<learning_objectives>Key learning objectives</learning_objectives>\n",
    "<script>How to introduce the topic to the kids</script>\n",
    "\"\"\"\n",
    "\n",
    "reviewer_message = \"\"\"You are a classroom lesson reviewer.\n",
    "You compare the lesson plan to the fourth grade curriculum\n",
    "and provide a maximum of 3 recommended changes for each review.\n",
    "Make sure you provide recommendations each time the plan is updated.\n",
    "\"\"\"\n",
    "\n",
    "teacher_message = \"\"\"You are a classroom teacher.\n",
    "You decide topics for lessons and work with a lesson planner.\n",
    "and reviewer to create and finalise lesson plans.\n",
    "\"\"\"\n",
    "\n",
    "with llm_config:\n",
    "    # 1. Create our agents\n",
    "\n",
    "    planner = ConversableAgent(name=\"planner_agent\", system_message=planner_message)\n",
    "    reviewer = ConversableAgent(name=\"reviewer_agent\", system_message=reviewer_message)\n",
    "    teacher = ConversableAgent(name=\"teacher_agent\", system_message=teacher_message)\n",
    "\n",
    "    run_pattern = SwarmRunPattern(planner, reviewer, teacher, after_work=AfterWorkOption.SWARM_MANAGER)\n",
    "\n",
    "response = run(\n",
    "    planner,\n",
    "    message=\"Today, let's introduce our kids to the solar system.\",\n",
    "    run_pattern=run_pattern,\n",
    "    terminate_on=MaxTurns(10),\n",
    ")\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.content.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Protocol, Union\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AgentFactory(Protocol):\n",
    "    def create(self) -> ConversableAgent:\n",
    "        pass\n",
    "\n",
    "MessageTypes = Union[str, list[Any], BaseModel]\n",
    "\n",
    "class Step(Protocol):\n",
    "    def execute(self, message: MessageTypes) -> MessageTypes:\n",
    "        pass\n",
    "\n",
    "class StepFactory(Protocol):\n",
    "    def create(self) -> Step:\n",
    "        pass\n",
    "\n",
    "class AgentStep(Step):\n",
    "    def __init__(self, agent: ConversableAgent) -> None:\n",
    "        self.agent = agent\n",
    "\n",
    "    def factory(self) -> StepFactory:\n",
    "        return self\n",
    "    \n",
    "    def create(self) -> Step:\n",
    "        # clone yourself\n",
    "        return self\n",
    "\n",
    "class SequentialStep(Step):\n",
    "    def __init__(self, steps: list[Step]) -> None:\n",
    "        pass\n",
    "\n",
    "class ParallelStep(Step):\n",
    "    def __init__(self, step_factory: StepFactory, *, batch_size: Optional[int]=None) -> None:\n",
    "        self.step_factory = step_factory\n",
    "\n",
    "    def execute(self, message: list[MessageTypes]) -> list[MessageTypes]:\n",
    "        # make it parallel\n",
    "        steps = [self.step_factory.create() for _ in message]\n",
    "        result = [step.execute(m) for m, step in zip(message, steps)]\n",
    "        return result\n",
    "            \n",
    "\n",
    "class ReduceStep(Step):\n",
    "    def __init__(self, step_factory: StepFactory) -> None:\n",
    "        pass\n",
    "\n",
    "    def execute(self, message: list[MessageTypes]) -> MessageTypes:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    jane = ConversableAgent(name=\"Jane\")\n",
    "    bob = ConversableAgent(name=\"Bob\")\n",
    "\n",
    "step1 = Step.from_agent_run(\n",
    "    sender=jane,\n",
    "    receiver=bob,\n",
    "    terminate_on=Keyword(\"TERMINATE\")\n",
    ")\n",
    "\n",
    "step1.execute(message=\"have a joke off\")\n",
    "\n",
    "pipeline = step1 + (step2 | step3) + step4\n",
    "\n",
    "pipeline.execute([\"Converse\", \"Converse\", \"Converse\", \"Converse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential chat\n",
    "\n",
    "Sequential chat can be implemented by calling the run sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.io.run_response import RunResponseProtocol\n",
    "\n",
    "\n",
    "with llm_config:\n",
    "    planner = ConversableAgent(\n",
    "        name=\"Planner\",\n",
    "        system_message=\"You are a planner. Create lesson plans.\",\n",
    "    )\n",
    "\n",
    "    reviewer = ConversableAgent(\n",
    "        name=\"Reviewer\",\n",
    "        system_message=\"You are a reviewer. Review lesson plans. Provide max 3 changes.\",\n",
    "    )\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        name=\"Teacher\",\n",
    "        system_message=\"You are a teacher. Choose topics and review the final lesson plan. Say DONE! when finished.\",\n",
    "    )\n",
    "    run_pattern = GroupRunPattern(planner, reviewer, teacher)\n",
    "\n",
    "\n",
    "# How about we use the step decorator to define our steps, they could return the run response protocol that will be handled by the pipeline\n",
    "@step()\n",
    "def choose_a_topic(message: str) -> RunResponseProtocol:\n",
    "    return run(\n",
    "        teacher,\n",
    "        message=message,\n",
    "        terminate_on=Keyword(\"DONE!\"),\n",
    "    )\n",
    "\n",
    "@step()\n",
    "def create_lesson_plan(message: str) -> RunResponseProtocol:\n",
    "    return run(\n",
    "        sender=reviewer,\n",
    "        receiver=planner,\n",
    "        message=\"Create lesson plan for the topic of: \" + message,\n",
    "        terminate_on=MaxTurns(3),\n",
    "    )\n",
    "\n",
    "@step()\n",
    "def review_lesson_plan(message: str) -> RunResponseProtocol:\n",
    "    return run(\n",
    "        teacher,\n",
    "        message=\"Review lesson plan: \" + message,\n",
    "        terminate_on=MaxTurns(3),\n",
    "    )\n",
    "\n",
    "pipeline = choose_a_topic + create_lesson_plan + review_lesson_plan\n",
    "\n",
    "response = pipeline.execute([\n",
    "    \"Create a lesson plan for 4th grade\",\n",
    "    \"Create a lesson plan for 5th grade\",\n",
    "    \"Create a lesson plan for 6th grade\",\n",
    "])\n",
    "\n",
    "ConsoleEventProcessor().process(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Chat\n",
    "\n",
    "Nested chat can be implemented using tool calling which initiate a new chat using the run function internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def plan_lesson(topic: str) -> str:\n",
    "    with llm_config:\n",
    "        planner = ConversableAgent(\n",
    "            name=\"Planner\",\n",
    "            system_message=\"You are a planner. Collaborate with reviewer to create a lesson plan.\",\n",
    "        )\n",
    "\n",
    "        reviewer = ConversableAgent(\n",
    "            name=\"Reviewer\",\n",
    "            system_message=\"You are a reviewer. Review lesson plans against 4th grade curriculum. Provide max 3 changes. Say DONE! when satisfied with the lesson plan.\",\n",
    "        )\n",
    "\n",
    "    response = run(\n",
    "        sender=reviewer,\n",
    "        receiver=planner,\n",
    "        message=f\"Create lesson plans for 4th grade on the topic of: {topic}\",\n",
    "        run_pattern=run_pattern,\n",
    "        terminate_on=Keyword(\"DONE!\") | MaxTurns(10),\n",
    "    )\n",
    "\n",
    "    for event in response.events:\n",
    "        print(f\"Got event: {event.type=}, {event=}\")\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            event.content.respond(input(event.prompt))\n",
    "\n",
    "    return response.summary\n",
    "\n",
    "\n",
    "@tool()\n",
    "def submit_plan(plan: str) -> str:\n",
    "    return f\"Plan submitted: {plan}\"\n",
    "\n",
    "\n",
    "teacher = ConversableAgent(\n",
    "    name=\"Teacher\",\n",
    "    system_message=\"You are a teacher. Choose topics and create a plan using plan_lesson. Say DONE! when finished.\",\n",
    ")\n",
    "\n",
    "plan_lesson.register_for_llm(teacher)\n",
    "submit_plan.register_for_llm(teacher)\n",
    "\n",
    "\n",
    "response = run(\n",
    "    teacher,\n",
    "    message=\"Create lesson plans for 4th grade.\",\n",
    "    run_pattern=run_pattern,\n",
    "    terminate_on=Keyword(\"DONE!\") | MaxTurns(10),\n",
    ")\n",
    "\n",
    "for event in response.events:\n",
    "    print(f\"Got event: {event.type=}, {event=}\")\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        event.content.respond(input(event.prompt))\n",
    "\n",
    "print(response.summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
