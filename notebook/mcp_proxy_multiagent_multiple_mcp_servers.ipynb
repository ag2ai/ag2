{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# MCP Multi-Agent Example: Multiagent multiple MCP Server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "this notebook is an example of a multi-agent orchestration where you can run multiple MCP server via an agent tool call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import asynccontextmanager\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from typing import Any, AsyncIterator, Literal\n",
    "\n",
    "import dotenv\n",
    "import nest_asyncio\n",
    "from mcp.client.session import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "from mcp.client.stdio import StdioServerParameters, stdio_client\n",
    "\n",
    "from autogen import LLMConfig\n",
    "from autogen.agentchat import AssistantAgent, ConversableAgent, initiate_group_chat\n",
    "from autogen.agentchat.group import (\n",
    "    AgentTarget,\n",
    "    ReplyResult,\n",
    ")\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.mcp import create_toolkit\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "define LLMConfig for the agent. make sure to set the OPENAI_API_KEY in your environment variables. you can use a .env file or set it directly in your environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "llm_config = LLMConfig(\n",
    "    model=\"o3-mini\",\n",
    "    api_type=\"openai\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "define server file paths for stdio client and server url for sse client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILESYSTEM_SERVER_PATH = Path(\"mcp/mcp_filesystem.py\")\n",
    "ARXIV_SERVER_PATH = Path(\"mcp/mcp_archive.py\")\n",
    "WIKIPEDIA_SERVER_URL = \"http://localhost:8000/sse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EncodingErrorHandlerType = Literal[\"strict\", \"ignore\", \"replace\"]\n",
    "\n",
    "DEFAULT_TEXT_ENCODING = \"utf-8\"\n",
    "DEFAULT_TEXT_ENCODING_ERROR_HANDLER: EncodingErrorHandlerType = \"strict\"\n",
    "DEFAULT_HTTP_REQUEST_TIMEOUT = 5\n",
    "DEFAULT_SSE_EVENT_READ_TIMEOUT = 60 * 5\n",
    "DEFAULT_STREAMABLE_HTTP_REQUEST_TIMEOUT = timedelta(seconds=30)\n",
    "DEFAULT_STREAMABLE_HTTP_SSE_EVENT_READ_TIMEOUT = timedelta(seconds=60 * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "define connection params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MCP server params\n",
    "mcp_connections: dict = {\n",
    "    \"FilesystemServer\": {\n",
    "        \"command\": \"python3\",\n",
    "        \"args\": [FILESYSTEM_SERVER_PATH],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"ArxivServer\": {\n",
    "        \"command\": \"python3\",\n",
    "        \"args\": [ARXIV_SERVER_PATH],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"WikipediaServer\": {\n",
    "        \"url\": WIKIPEDIA_SERVER_URL,\n",
    "        \"transport\": \"sse\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "add methods to create client sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def create_stdio_mcp_session(\n",
    "    *,\n",
    "    command: str,\n",
    "    arguments: list[str],\n",
    "    environment: dict[str, str] | None = None,\n",
    "    working_dir: str | Path | None = None,\n",
    "    encoding: str = DEFAULT_TEXT_ENCODING,\n",
    "    encoding_error_handler: EncodingErrorHandlerType = DEFAULT_TEXT_ENCODING_ERROR_HANDLER,\n",
    "    session_options: dict[str, Any] | None = None,\n",
    ") -> AsyncIterator[ClientSession]:\n",
    "    \"\"\"\n",
    "    Create a new session to an MCP server using stdio\n",
    "\n",
    "    Args:\n",
    "        command: Command to execute\n",
    "        arguments: Arguments for the command\n",
    "        environment: Environment variables for the command\n",
    "        working_dir: Working directory for the command\n",
    "        encoding: Character encoding\n",
    "        encoding_error_handler: How to handle encoding errors\n",
    "        session_options: Additional keyword arguments to pass to the ClientSession\n",
    "    \"\"\"\n",
    "\n",
    "    environment = environment or {}\n",
    "    if \"PATH\" not in environment:\n",
    "        environment[\"PATH\"] = os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "    server_params = StdioServerParameters(\n",
    "        command=command,\n",
    "        args=arguments,\n",
    "        env=environment,\n",
    "        cwd=working_dir,\n",
    "        encoding=encoding,\n",
    "        encoding_error_handler=encoding_error_handler,\n",
    "    )\n",
    "\n",
    "    async with (\n",
    "        stdio_client(server_params) as (reader, writer),\n",
    "        ClientSession(reader, writer, **(session_options or {})) as session,\n",
    "    ):\n",
    "        yield session\n",
    "\n",
    "\n",
    "async def create_sse_mcp_session(\n",
    "    *,\n",
    "    url: str,\n",
    "    headers: dict[str, Any] | None = None,\n",
    "    timeout: float = DEFAULT_HTTP_REQUEST_TIMEOUT,\n",
    "    sse_read_timeout: float = DEFAULT_SSE_EVENT_READ_TIMEOUT,\n",
    "    session_options: dict[str, Any] | None = None,\n",
    "    httpx_client_factory: Any = None,\n",
    ") -> AsyncIterator[ClientSession]:\n",
    "    \"\"\"Create a new session to an MCP server using SSE\n",
    "\n",
    "    Args:\n",
    "        url: URL of the SSE server\n",
    "        headers: HTTP headers to send to the SSE endpoint\n",
    "        timeout: HTTP timeout\n",
    "        sse_read_timeout: SSE read timeout\n",
    "        session_options: Additional keyword arguments to pass to the ClientSession\n",
    "        httpx_client_factory: Custom factory for httpx.AsyncClient (optional)\n",
    "    \"\"\"\n",
    "    kwargs = {}\n",
    "    if httpx_client_factory is not None:\n",
    "        kwargs[\"httpx_client_factory\"] = httpx_client_factory\n",
    "\n",
    "    async with (\n",
    "        sse_client(url, headers, timeout, sse_read_timeout, **kwargs) as (reader, writer),\n",
    "        ClientSession(reader, writer, **(session_options or {})) as session,\n",
    "    ):\n",
    "        yield session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "open a mcp session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def open_mcp_session(\n",
    "    config,\n",
    ") -> AsyncIterator[ClientSession]:\n",
    "    \"\"\"\n",
    "    Open a new session to an MCP server.\n",
    "    Args:\n",
    "        config: Configuration dictionary for the connection\n",
    "    Raises:\n",
    "        KeyError: If required parameters for the specified transport are missing\n",
    "        NotImplementedError: If transport is not recognized\n",
    "\n",
    "    Yields:\n",
    "        A ClientSession\n",
    "    \"\"\"\n",
    "    transport_type = config[\"transport\"]\n",
    "    if transport_type == \"sse\":\n",
    "        if \"url\" not in config:\n",
    "            raise KeyError(\"'url' parameter is required for SSE connection\")\n",
    "        async with create_sse_mcp_session(\n",
    "            url=config[\"url\"],\n",
    "            headers=config.get(\"headers\"),\n",
    "            timeout=config.get(\"timeout\", DEFAULT_HTTP_REQUEST_TIMEOUT),\n",
    "            sse_read_timeout=config.get(\"sse_read_timeout\", DEFAULT_SSE_EVENT_READ_TIMEOUT),\n",
    "            session_options=config.get(\"session_options\"),\n",
    "            httpx_client_factory=config.get(\"httpx_client_factory\"),\n",
    "        ) as session:\n",
    "            yield session\n",
    "    elif transport_type == \"stdio\":\n",
    "        if \"command\" not in config:\n",
    "            raise KeyError(\"'command' parameter is required for stdio connection\")\n",
    "        if \"arguments\" not in config:\n",
    "            raise KeyError(\"'arguments' parameter is required for stdio connection\")\n",
    "        async with create_stdio_mcp_session(\n",
    "            command=config[\"command\"],\n",
    "            arguments=config[\"arguments\"],\n",
    "            environment=config.get(\"environment\"),\n",
    "            working_dir=config.get(\"working_dir\"),\n",
    "            encoding=config.get(\"encoding\", DEFAULT_TEXT_ENCODING),\n",
    "            encoding_error_handler=config.get(\"encoding_error_handler\", DEFAULT_TEXT_ENCODING_ERROR_HANDLER),\n",
    "            session_options=config.get(\"session_options\"),\n",
    "        ) as session:\n",
    "            yield session\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unsupported transport: {transport_type}. Must be one of: 'stdio', 'sse'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "define agent orchestration pattern where mcp_agent is responsible for responding to mcp queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a mcp agent that can use mcp tools to analyze the content of the file and return the result.\n",
    "you have two mcp servers connected to you.\n",
    "1. FilesystemServer\n",
    "2. WikipediaServer\n",
    "3. ArxivServer\n",
    "You can use the FilesystemServer to read files from the filesystem, and you can use the WikipediaServer to search for information on Wikipedia.\n",
    "You can also use the ArxivServer to search for scientific papers on arXiv.\n",
    "you can use the tools of both the servers to analyze the content of the file and return the result.\n",
    "# Note:\n",
    "    - Identify the server name by analyzing the human question/initial message.\n",
    "\"\"\"\n",
    "with llm_config:\n",
    "    mcp_agent = ConversableAgent(\n",
    "        name=\"mcp_agent\",\n",
    "        system_message=system_message,\n",
    "    )\n",
    "    assistant = ConversableAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"\"\"You are an intelligent assistant agent. Your job is to analyze user queries and decide which MCP server/tool is most appropriate to answer the question:\n",
    "        - Use 'FilesystemServer' for file reading, file content analysis, or anything related to local files.\n",
    "        - Use 'WikipediaServer' for general knowledge, facts, or information that can be found on Wikipedia.\n",
    "        - Use 'ArxivServer' for scientific literature, research papers, or academic topics.\n",
    "        Route the query to the correct server/tool and provide clear, concise responses based on the tool's output.\n",
    "        \"\"\",\n",
    "        max_consecutive_auto_reply=3,\n",
    "    )\n",
    "    arxiv_summary_agent = ConversableAgent(\n",
    "        name=\"arxiv_summary_agent\",\n",
    "        system_message=\"\"\"You are an agent specializing in summarizing scientific papers and arXiv responses.\n",
    "        When you receive information from the assistant that originates from ArxivServer, extract the main contributions, summarize the findings,\n",
    "        and present them in a clear, accessible way for a general audience.\"\"\",\n",
    "        max_consecutive_auto_reply=1,\n",
    "    )\n",
    "    file_analysis_agent = ConversableAgent(\n",
    "        name=\"file_analysis_agent\",\n",
    "        system_message=\"\"\"You are an expert in file content analysis.\n",
    "        When provided with file data (from FilesystemServer), extract key information, summarize the main points,\n",
    "        and highlight any anomalies or important findings. Present your analysis in a structured and easy-to-understand format.\"\"\",\n",
    "        max_consecutive_auto_reply=1,\n",
    "    )\n",
    "\n",
    "\n",
    "# define orchestrate a pattern\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=mcp_agent,\n",
    "    agents=[mcp_agent, assistant, arxiv_summary_agent, file_analysis_agent],\n",
    "    group_manager_args={\"llm_config\": llm_config},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prompt = \"\"\"\n",
    "    Run the MCP agent for the given server name and query.\n",
    "    This function executes the MCP agent with the specified query and server name,\n",
    "    returning the result of the MCP agent's processing.\n",
    "    Args:\n",
    "        query (str): The query to be processed by the MCP agent.\n",
    "        server_name (str): The name of the server that is connected to the MCP agent.\n",
    "    Returns:\n",
    "        ReplyResult: The result of the MCP agent's processing.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@mcp_agent.register_for_llm(description=tool_prompt)\n",
    "@assistant.register_for_execution(description=tool_prompt)\n",
    "async def run_mcp_agent_to_client(query: str, server_name: str) -> ReplyResult:\n",
    "    if server_name not in mcp_connections:\n",
    "        raise KeyError(\n",
    "            f\"Couldn't find a server with name '{server_name}', expected one of '{list(mcp_connections.keys())}'\"\n",
    "        )\n",
    "    async with open_mcp_session(mcp_connections[server_name]) as session:\n",
    "        await session.initialize()\n",
    "        toolkit = await create_toolkit(session=session)\n",
    "        agent = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "        toolkit.register_for_llm(agent)\n",
    "        # Make a request using the MCP tool\n",
    "        result = await agent.a_run(\n",
    "            message=query,\n",
    "            tools=toolkit.tools,\n",
    "            max_turns=2,\n",
    "        )\n",
    "        res = await result.process()\n",
    "        return ReplyResult(\n",
    "            message=str(res),\n",
    "            target=AgentTarget(assistant),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, context_variables, last_agent = initiate_group_chat(\n",
    "    messages=\"perform a wikipedia search for the term 'domain-driven design' show me at least 10 results\",\n",
    "    max_rounds=5,\n",
    "    pattern=pattern,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
