{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b04378-221f-45ce-a9cc-cb58467b919d",
   "metadata": {},
   "source": [
    "# Conversational Workflows with MCP: A Shakespearean Take on arXiv Abstracts\n",
    "\n",
    "**Authors:** Licong Xu and Boris Bolliet (Cambridge)\n",
    "\n",
    "**Original Code:** [MCPAgents](https://github.com/CMBAgents/MCPAgents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae38665-8a9d-49d4-919e-7d63b82b7406",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "This cell sets up the environment and imports necessary libraries:\n",
    "\n",
    "- **Pathlib**, **os**, **json**, **asyncio**, etc. for file and system operations.\n",
    "- Imports from the `autogen` and `mcp` libraries, which are used to create conversational agents and connect to an arXiv-related tool server.\n",
    "- `nest_asyncio.apply()` ensures that asynchronous code runs properly in Jupyter notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ed7aaa-e6c9-42c4-bad6-b5c16176ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.sse import sse_client\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from autogen import LLMConfig\n",
    "from autogen.agentchat import AssistantAgent\n",
    "from autogen.mcp import create_toolkit\n",
    "import json\n",
    "import anyio\n",
    "import asyncio\n",
    "\n",
    "# Only needed for Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from autogen.agentchat.group import (\n",
    "    AgentNameTarget,\n",
    "    AgentTarget,\n",
    "    AskUserTarget,\n",
    "    ContextExpression,\n",
    "    ContextStr,\n",
    "    ContextStrLLMCondition,\n",
    "    ContextVariables,\n",
    "    ExpressionAvailableCondition,\n",
    "    ExpressionContextCondition,\n",
    "    GroupChatConfig,\n",
    "    GroupChatTarget,\n",
    "    Handoffs,\n",
    "    NestedChatTarget,\n",
    "    OnCondition,\n",
    "    OnContextCondition,\n",
    "    ReplyResult,\n",
    "    RevertToUserTarget,\n",
    "    SpeakerSelectionResult,\n",
    "    StayTarget,\n",
    "    StringAvailableCondition,\n",
    "    StringContextCondition,\n",
    "    StringLLMCondition,\n",
    "    TerminateTarget,\n",
    ")\n",
    "\n",
    "from autogen.agentchat.group.patterns import (\n",
    "    DefaultPattern,\n",
    "    ManualPattern,\n",
    "    AutoPattern,\n",
    "    RandomPattern,\n",
    "    RoundRobinPattern,\n",
    ")\n",
    "\n",
    "\n",
    "from autogen import ConversableAgent, UpdateSystemMessage\n",
    "from autogen.agents.experimental import DocAgent\n",
    "import os\n",
    "import copy\n",
    "from typing import Any, Dict, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from autogen.agentchat import initiate_group_chat, a_initiate_group_chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afafa04-9f8c-4a45-be92-95bb366d5da4",
   "metadata": {},
   "source": [
    "## Define MCP Server Path\n",
    "\n",
    "Set the path to the **MCP server script**, which will be used to handle tool execution related to arXiv paper retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56fa18f6-1438-482a-83d6-ef2a04254e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_path = Path(\"mcp/mcp_arxiv.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14badc5b-62fd-4978-b175-7a416a5c01ea",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "- Define the **joker agent**, whose role is to make jokes in the style of Shakespeare.\n",
    "- Use a `pydantic` model to structure the joke and explanation.\n",
    "- Set LLM configuration, including temperature, caching, and model.\n",
    "- Define a `ContextVariables` object to inject context (like joke constraints) into the agent's workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14fded9e-0818-413c-8f54-59b16adea138",
   "metadata": {},
   "outputs": [],
   "source": [
    "joker_message = \"\"\"\n",
    "You are the joker in the team. You make jokes. \n",
    "\n",
    "You must obey the following constraints:\n",
    "\n",
    "{joke_constraints}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class JokeResponse(BaseModel):\n",
    "    joke_instructions: str = Field(..., description=\"instruction, not in the style of Shakespeare\")     \n",
    "    joke: str = Field(..., description=\"joke in the style of Shakespeare\")\n",
    "    joke_explanation: str = Field(..., description=\"explanation, not in the style of Shakespeare\")\n",
    "    def format(self) -> str:\n",
    "        return \"\\n\".join([\n",
    "            \"**Joke instructions:**\",\n",
    "            \"\",\n",
    "            self.joke_instructions,\n",
    "            \"\",\n",
    "            \"**Joke:**\",\n",
    "            \"\",\n",
    "            self.joke,\n",
    "            \"\",\n",
    "            \"**Joke explanation:**\",\n",
    "            \"\",\n",
    "            self.joke_explanation\n",
    "        ])\n",
    "\n",
    "\n",
    "default_llm_config = {'cache_seed': 42,\n",
    "                     'temperature': 1.,\n",
    "                     'top_p': 0.05,\n",
    "                     'config_list': [{'model': 'gpt-4o',\n",
    "                                      'api_key': os.getenv('OPENAI_API_KEY'),\n",
    "                                      'api_type': 'openai'}],\n",
    "                     'timeout': 1200}\n",
    "\n",
    "joker_config_list = copy.deepcopy(default_llm_config)\n",
    "joker_config_list['config_list'][0]['response_format'] = JokeResponse\n",
    "\n",
    "\n",
    "joker =  ConversableAgent(\n",
    "    name=\"joker\",\n",
    "    system_message=joker_message,\n",
    "    llm_config = joker_config_list,\n",
    "    update_agent_state_before_reply=[UpdateSystemMessage(joker_message),],\n",
    ")\n",
    "\n",
    "workflow_context = ContextVariables(data={\n",
    "    \"joke_constraints\": \"the joke should make use of the contextual information passed on to you. It should be a paragraph long and use as much detailed information from the context as possible.\",\n",
    "})\n",
    "\n",
    "\n",
    "task = \"\"\"\n",
    "Make a joke based on the title and abstract of an arxiv paper of your choice.\n",
    "\"\"\"\n",
    "\n",
    "initial_agent = joker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bebfe-697a-4ba9-93db-8f2a474d8041",
   "metadata": {},
   "source": [
    "## Create Toolkit and Run\n",
    "\n",
    "1. Asynchronously create a **toolkit** from the client session and registers it to a `mcp_agent` that will search and download arXiv papers.\n",
    "2. Set up a **handoff**: once `mcp_agent` finishes its task, it passes control to `joker`.\n",
    "3. Delete the `.cache/` folder to reset the environment.\n",
    "4. Initialize a **DefaultPattern** for how agents interact.\n",
    "5. Start the **group chat workflow** using `a_initiate_group_chat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5935d8d-e63d-4cdd-b0fc-869064d5e7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all agents reset\n",
      ".cache folder deleted.\n",
      "\u001b[33m_User\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Make a joke based on the title and abstract of an arxiv paper of your choice.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_zedrpbRnAmqlAQDi3pKIfTYo): search_arxiv *****\u001b[0m\n",
      "Arguments: \n",
      "{\"query\":\"quantum computing\",\"max_results\":1}\n",
      "\u001b[32m*****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_arxiv...\n",
      "Call ID: call_zedrpbRnAmqlAQDi3pKIfTYo\n",
      "Input arguments: {'query': 'quantum computing', 'max_results': 1}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_zedrpbRnAmqlAQDi3pKIfTYo) *****\u001b[0m\n",
      "('2208.00733v1', None)\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_xjLQI7Ids7EnHKox0LKtp4Xv): download_paper *****\u001b[0m\n",
      "Arguments: \n",
      "{\"arxiv_id\": \"2208.00733v1\"}\n",
      "\u001b[32m*******************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_p0DABHMWVYazKPPRVtIv83Fy): get_paper_info *****\u001b[0m\n",
      "Arguments: \n",
      "{\"arxiv_id\": \"2208.00733v1\"}\n",
      "\u001b[32m*******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION download_paper...\n",
      "Call ID: call_xjLQI7Ids7EnHKox0LKtp4Xv\n",
      "Input arguments: {'arxiv_id': '2208.00733v1'}\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_paper_info...\n",
      "Call ID: call_p0DABHMWVYazKPPRVtIv83Fy\n",
      "Input arguments: {'arxiv_id': '2208.00733v1'}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_xjLQI7Ids7EnHKox0LKtp4Xv) *****\u001b[0m\n",
      "('Downloaded 2208.00733v1 to 2208.00733v1.pdf', None)\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m***** Response from calling tool (call_p0DABHMWVYazKPPRVtIv83Fy) *****\u001b[0m\n",
      "('{\"title\": \"The Rise of Quantum Internet Computing\", \"abstract\": \"This article highlights quantum Internet computing as referring to\\\\ndistributed quantum computing over the quantum Internet, analogous to\\\\n(classical) Internet computing involving (classical) distributed computing over\\\\nthe (classical) Internet. Relevant to quantum Internet computing would be areas\\\\nof study such as quantum protocols for distributed nodes using quantum\\\\ninformation for computations, quantum cloud computing, delegated verifiable\\\\nblind or private computing, non-local gates, and distributed quantum\\\\napplications, over Internet-scale distances.\"}', None)\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_wVfIpi5lDqam2YjIaPp1ArIL): transfer_to_joker_1 *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION transfer_to_joker_1...\n",
      "Call ID: call_wVfIpi5lDqam2YjIaPp1ArIL\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_wVfIpi5lDqam2YjIaPp1ArIL) *****\u001b[0m\n",
      "Transfer to joker\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoker\u001b[0m (to chat_manager):\n",
      "\n",
      "**Joke instructions:**\n",
      "\n",
      "Create a joke using the title and abstract of the paper 'The Rise of Quantum Internet Computing'.\n",
      "\n",
      "**Joke:**\n",
      "\n",
      "Oh, fair scholars of the quantum realm, gather 'round and lend me thine ears! For I have a tale of the Quantum Internet, where qubits doth dance upon the ether like merry sprites. Imagine, if you will, a quantum cloud computing service, where the only thing more uncertain than the Heisenberg principle is whether your quantum cat video will buffer or not! Verily, in this brave new world of distributed quantum computing, one must ponder: if a qubit falls in the quantum forest and no one is around to observe it, does it still compute? Nay, I say, for in the realm of quantum protocols and non-local gates, even Schrödinger's cat would need a VPN! So, let us raise a toast to the quantum Internet, where the only thing faster than light is the speed at which we lose our classical minds!\n",
      "\n",
      "**Joke explanation:**\n",
      "\n",
      "The joke plays on the concept of quantum Internet computing, which involves distributed quantum computing over the Internet. It humorously imagines the challenges and peculiarities of such a system, like buffering quantum cat videos and the uncertainty principle. The joke also references Schrödinger's cat, a famous thought experiment in quantum mechanics, and uses the idea of a VPN (Virtual Private Network) to add a modern twist. The humor lies in the absurdity and complexity of quantum computing concepts applied to everyday Internet scenarios.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (4e1d6d84-0261-4897-aaee-3f6bfc275aba): No next speaker selected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def create_toolkit_and_run(session: ClientSession) -> None:\n",
    "    # Create a toolkit with available MCP tools\n",
    "    toolkit = await create_toolkit(session=session)\n",
    "    mcp_agent = ConversableAgent(name=\"mcp_agent\", \n",
    "                             system_message=r\"\"\"\n",
    "Download arxiv paper and extract titles and abstracts. \n",
    "                             \"\"\",\n",
    "                             llm_config=LLMConfig(model=\"gpt-4o\", \n",
    "                                                  api_type=\"openai\",\n",
    "                                                  tool_choice=\"required\",\n",
    "                                                  temperature=1,\n",
    "                                                 ))\n",
    "    # Register MCP tools with the agent\n",
    "    toolkit.register_for_llm(mcp_agent)\n",
    "    \n",
    "    toolkit.register_for_execution(mcp_agent)\n",
    "\n",
    "    joker.handoffs.set_after_work(TerminateTarget())\n",
    "    \n",
    "    mcp_agent.handoffs.set_after_work(AgentTarget(joker))\n",
    "\n",
    "\n",
    "    mcp_agent.handoffs.add_llm_conditions([\n",
    "            OnCondition(\n",
    "                target=AgentTarget(joker),\n",
    "                condition=StringLLMCondition(prompt=\"The papers have been downloaded.\"),\n",
    "            ),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    agents=[joker,\n",
    "            mcp_agent,\n",
    "               ]\n",
    "    \n",
    "    for agent in agents:\n",
    "        agent.reset()\n",
    "    print(\"all agents reset\")\n",
    "\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    def delete_cache_folder():\n",
    "        cache_path = os.path.join(os.getcwd(), \".cache\")\n",
    "        if os.path.isdir(cache_path):\n",
    "            shutil.rmtree(cache_path)\n",
    "            print(\".cache folder deleted.\")\n",
    "        else:\n",
    "            print(\"No .cache folder found in current directory.\")\n",
    "    \n",
    "    delete_cache_folder()\n",
    "\n",
    "    # Create the pattern\n",
    "    agent_pattern = DefaultPattern(\n",
    "      agents=[joker, mcp_agent],\n",
    "      initial_agent=mcp_agent,\n",
    "      context_variables=workflow_context,\n",
    "    )\n",
    "    \n",
    "\n",
    "    await a_initiate_group_chat(\n",
    "            pattern=agent_pattern,\n",
    "            messages=task,\n",
    "            max_rounds=20,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    args=[str(mcp_server_path), \"stdio\", \"--storage-path\", \"mcp/arxiv_papers\"]\n",
    ")\n",
    "\n",
    "async with stdio_client(server_params) as (read, write), ClientSession(read, write) as session:\n",
    "    # Initialize the connection\n",
    "    await session.initialize()\n",
    "    await create_toolkit_and_run(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env",
   "language": "python",
   "name": "mcp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
