{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# AG2 + Gemini Thinking Config Variants\n",
    "\n",
    "This notebook shows how to adjust Gemini thinking features in AG2:\n",
    "- `thinking_budget` (token budget for thinking)\n",
    "- `thinking_level` (\"High\" vs \"Low\")\n",
    "- `include_thoughts` (whether to return thought summaries)\n",
    "\n",
    "Reference: [Gemini Thinking Guide](https://ai.google.dev/gemini-api/docs/thinking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY is not set. Please set it in your environment or .env file.\")\n",
    "\n",
    "prompt = \"Solve 12 * 17 + 45, then explain your steps briefly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Ag2 now support `ThinkingConfig` on Gemini \n",
    "ThinkConfig has three configuration:\n",
    "- thinking budget: Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent.\n",
    "- thinking level: The level of thoughts tokens that the model should generate.\n",
    "- iclude_thoughts: Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-3-pro-preview\",\n",
    "        \"api_type\": \"gemini\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_budget\": 2048,\n",
    "        \"thinking_level\": \"High\",\n",
    "        \"include_thoughts\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Vary thinking_budget\n",
    "Budget can vary from 0 meaning no budget, -1 meaning automatic , to custom like for example , 4096 based on the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 4096\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-2.5-flash\",\n",
    "        \"api_type\": \"gemini\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_budget\": budget,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Vary thinking_level\n",
    "You can set that `thinking_level` to \"low\" or \"high\" (which is the default for `gemini-3-pro-preview`). This will indicate to the model if it allowed to do a lot of thinking. Since the thinking process stays dynamic, `high` doesn't mean it will always use a lot of token in its thinking phase, just that it's allowed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"High\"\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-3-pro-preview\",\n",
    "        \"api_type\": \"gemini\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_level\": level,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "when thinking level is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"Low\"\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-2.5-flash\",\n",
    "        \"api_type\": \"gemini\",\n",
    "        \"api_key\": api_key,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent-thoughts\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## include_thoughts\n",
    "- True/False to see thought summaries/no thoughts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-2.5-flash\",\n",
    "        \"api_type\": \"gemini\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_level\": \"High\",\n",
    "        \"include_thoughts\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent-thoughts\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Tips\n",
    "- For long/complex tasks, use a higher `thinking_budget`.\n",
    "- `thinking_level` can be lowered for lighter reasoning.\n",
    "- Set `include_thoughts=True` when you want thought summaries; turn off to reduce output.\n",
    "\n",
    "Reference: [Gemini Thinking Guide](https://ai.google.dev/gemini-api/docs/thinking)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
