{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tvrtko/Documents/projects/AG2/ag2/.venv/lib/python3.11/site-packages/flaml/__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "from autogen import AssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"tags\": [\"gpt-4o-mini\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_Proxy\u001b[0m (to x_assistant):\n",
      "\n",
      "Find out today's hot topic and an influencer who is talking about it on X\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mx_assistant\u001b[0m (to User_Proxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_soyVMz0giWDpkAiYhiKQ7TsC): get_twitter_hot_topic *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m**************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_twitter_hot_topic...\n",
      "Call ID: call_soyVMz0giWDpkAiYhiKQ7TsC\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[33mUser_Proxy\u001b[0m (to x_assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_soyVMz0giWDpkAiYhiKQ7TsC) *****\u001b[0m\n",
      "Hot topic of the day on Twitter is #AI, and an influencer who is talking about it is @elonmusk\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mx_assistant\u001b[0m (to User_Proxy):\n",
      "\n",
      "Today's hot topic on Twitter is **#AI**, and an influencer discussing it is **@elonmusk**.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_Proxy\u001b[0m (to arxiv):\n",
      "\n",
      "Get the abstract of a relevant paper based on Today's hot topic on Twitter is **#AI**, and an influencer discussing it is **@elonmusk**.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33marxiv\u001b[0m (to User_Proxy):\n",
      "\n",
      "To find a relevant paper based on the hot topic of AI and the influencer Elon Musk, I will first search for recent publications or papers related to AI. I will focus on papers that might have been discussed or published around the time when AI is trending on Twitter.\n",
      "\n",
      "Let's start by searching for recent academic papers in the field of AI using an appropriate API or database. I can use the arXiv API, which is a repository of electronic preprints. I will search for papers related to AI and filter them based on their relevance.\n",
      "\n",
      "I will now execute the search for relevant papers. \n",
      "\n",
      "```python\n",
      "import requests\n",
      "\n",
      "# Search for AI-related papers on arXiv\n",
      "search_query = \"AI\"\n",
      "url = f\"http://export.arxiv.org/api/query?search_query=all:{search_query}&start=0&max_results=5\"\n",
      "\n",
      "response = requests.get(url)\n",
      "print(response.text)\n",
      "```\n",
      "\n",
      "Please execute the above code to fetch recent AI-related papers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_Proxy\u001b[0m (to arxiv):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 1, in <module>\n",
      "    import requests\n",
      "ModuleNotFoundError: No module named 'requests'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33marxiv\u001b[0m (to User_Proxy):\n",
      "\n",
      "It seems the code execution failed because the `requests` module is not available in the current environment. Instead, I will use a shell command with `curl` to fetch recent AI-related papers from the arXiv API directly.\n",
      "\n",
      "Hereâ€™s the shell script to perform the search:\n",
      "\n",
      "```sh\n",
      "# filename: fetch_ai_papers.sh\n",
      "curl -s \"http://export.arxiv.org/api/query?search_query=all:AI&start=0&max_results=5\"\n",
      "```\n",
      "\n",
      "Please save the above script in a file named `fetch_ai_papers.sh` and execute it to retrieve the recent AI-related papers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33mUser_Proxy\u001b[0m (to arxiv):\n",
      "\n",
      "exitcode: 127 (execution failed)\n",
      "Code output: \n",
      "tmp_code_7b039c197c7a9a89b6ff4892cb319960.sh: 2: curl: not found\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33marxiv\u001b[0m (to User_Proxy):\n",
      "\n",
      "It appears that the `curl` command is also not available in the current environment. Instead, I will provide you with a direct URL to access the recent AI-related papers on arXiv. You can open this link in your web browser to view the relevant papers.\n",
      "\n",
      "Here's the link to fetch AI-related papers from arXiv:\n",
      "\n",
      "[arXiv: AI-related papers](http://export.arxiv.org/api/query?search_query=all:AI&start=0&max_results=5)\n",
      "\n",
      "Please check this link to find the latest papers related to AI. Once you find a paper of interest, let me know, and I can help you extract its abstract. \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x_assistant = AssistantAgent(name=\"x_assistant\", llm_config=llm_config)\n",
    "\n",
    "\n",
    "@x_assistant.register_for_llm()\n",
    "def get_twitter_hot_topic() -> str:\n",
    "    return \"Hot topic of the day on Twitter is #AI, and an influencer who is talking about it is @elonmusk\"\n",
    "\n",
    "\n",
    "arxiv_researcher = AssistantAgent(name=\"arxiv\", llm_config=llm_config)\n",
    "\n",
    "hot_topic_res = x_assistant.run(\n",
    "    \"Find out today's hot topic and an influencer who is talking about it on X\",\n",
    "    user_proxy_kwargs={\n",
    "        \"is_termination_msg\": lambda x: (x[\"content\"] is not None) and x[\"content\"].endswith(\"TERMINATE\")\n",
    "    },\n",
    ")\n",
    "paper_abstract = arxiv_researcher.run(\n",
    "    \"Get the abstract of a relevant paper based on \" + hot_topic_res,\n",
    "    user_proxy_kwargs={\n",
    "        \"is_termination_msg\": lambda x: (x[\"content\"] is not None) and x[\"content\"].endswith(\"TERMINATE\")\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It appears that the `curl` command is also not available in the current environment. Instead, I will provide you with a direct URL to access the recent AI-related papers on arXiv. You can open this link in your web browser to view the relevant papers.\\n\\nHere's the link to fetch AI-related papers from arXiv:\\n\\n[arXiv: AI-related papers](http://export.arxiv.org/api/query?search_query=all:AI&start=0&max_results=5)\\n\\nPlease check this link to find the latest papers related to AI. Once you find a paper of interest, let me know, and I can help you extract its abstract. \\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2353999307.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Create an X post based on the hot topic and this \" + paper_abstract + \"and mention the influencer\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Secneario 1. This task requires x_assistant's past state\n",
    "post = x_assistant.run(\n",
    "    \"Create an X post based on the hot topic and this \" + paper_abstract + \"and mention the influencer\",\n",
    "    user_proxy_kwargs={\n",
    "        \"is_termination_msg\": lambda x: (x[\"content\"] is not None) and x[\"content\"].endswith(\"TERMINATE\")\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# Scenario 2.  Doing another task that does not require history or past state\n",
    "influencer = x_assistant.run(\n",
    "    \"Find a influencer I should follow\",\n",
    "    clear_history=True,\n",
    "    user_proxy_kwargs={\n",
    "        \"is_termination_msg\": lambda x: (x[\"content\"] is not None) and x[\"content\"].endswith(\"TERMINATE\")\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
