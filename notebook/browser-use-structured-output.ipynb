{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Any, List\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import autogen\n",
    "from autogen.agentchat.conversable_agent import ConversableAgent\n",
    "from autogen.agents.experimental import WebSurferAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\"tags\": [\"gpt-4o-mini\"]},\n",
    ")\n",
    "llm_config = {\"config_list\": config_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer_question(\"What are the top most popular posts on hackernews?\", llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    question: str,\n",
    "    llm_config: dict[str, Any],\n",
    "    max_web_steps: int = 3,\n",
    ") -> str:\n",
    "    class InformationCrumb(BaseModel):\n",
    "        source_url: str\n",
    "        source_title: str\n",
    "        source_summary: str\n",
    "        relevant_info: str\n",
    "\n",
    "    class GatheredInformation(BaseModel):\n",
    "        information: List[InformationCrumb]\n",
    "\n",
    "        def format(self) -> str:\n",
    "            return \"Here is the gathered information: \\n\" + \"\\n\".join(\n",
    "                f\"URL: {info.source_url}\\nTitle: {info.source_title}\\nSummary: {info.source_summary}\\nRelevant Information: {info.relevant_info}\\n\\n\"\n",
    "                for info in self.information\n",
    "            )\n",
    "\n",
    "    websurfer_config = copy.deepcopy(llm_config)\n",
    "\n",
    "    websurfer_config[\"config_list\"][0][\"response_format\"] = GatheredInformation\n",
    "\n",
    "    def is_termination_msg(x):\n",
    "        return x.get(\"content\", \"\") and x.get(\"content\", \"\").startswith(\"Answer confirmed:\")\n",
    "\n",
    "    websurfer = WebSurferAgent(\n",
    "        llm_config=websurfer_config,\n",
    "        name=\"WebSurferAgent\",\n",
    "        system_message=(\n",
    "            \"You are a web surfer agent responsible for gathering information from the web to provide information for answering a question\\n\"\n",
    "            \"You will be asked to find information related to the question and provide a summary of the information gathered.\\n\"\n",
    "            \"The summary should include the URL, title, summary, and relevant information for each piece of information gathered.\\n\"\n",
    "        ),\n",
    "        is_termination_msg=is_termination_msg,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        web_tool_kwargs={\"agent_kwargs\": {\"max_steps\": max_web_steps}},\n",
    "    )\n",
    "\n",
    "    websurfer_critic = ConversableAgent(\n",
    "        name=\"WebSurferCritic\",\n",
    "        system_message=(\n",
    "            \"You are a critic agent responsible for evaluating the answer provided by the web surfer agent.\\n\"\n",
    "            \"You need to confirm wehther the information provided by the websurfer is correct and sufficient to answer the question.\\n\"\n",
    "            \"You can ask the web surfer to provide more information or provide and confirm the answer.\\n\"\n",
    "        ),\n",
    "        llm_config=llm_config,\n",
    "        is_termination_msg=is_termination_msg,\n",
    "        human_input_mode=\"NEVER\",\n",
    "    )\n",
    "\n",
    "    @websurfer.register_for_execution()\n",
    "    @websurfer_critic.register_for_llm(\n",
    "        description=\"Call this method when you agree that the original question can be answered with the gathered information and provide the answer.\"\n",
    "    )\n",
    "    def confirm_answer(answer: str) -> str:\n",
    "        return \"Answer confirmed: \" + answer\n",
    "\n",
    "    websurfer_critic.register_for_execution()(websurfer.tool)\n",
    "\n",
    "    result = websurfer_critic.initiate_chat(\n",
    "        websurfer,\n",
    "        message=\"Please find the answer to this question: \" + question,\n",
    "    )\n",
    "\n",
    "    return result.summary\n",
    "\n",
    "\n",
    "answer_question(\"What are the top most popular posts on hackernews?\", llm_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
