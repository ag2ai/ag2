{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Execution with AG2\n",
    "\n",
    "AG2's `run()` and `run_group_chat()` methods execute agent conversations in **background threads** that run independently of event consumption. This is great for streaming UIs, but makes it difficult to:\n",
    "\n",
    "- **Debug step-by-step** - Execution races ahead while you're inspecting events\n",
    "- **Implement human-in-the-loop** - Hard to pause for approval before each action  \n",
    "- **Build interactive tools** - Can't easily gate execution on user decisions\n",
    "\n",
    "**Step mode** solves this by synchronizing the producer (background thread) and consumer (your code) - the producer blocks after each event until you explicitly call `step()` to advance.\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install AG2:\n",
    "\n",
    "```bash\n",
    "pip install ag2[openai]\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our LLM configuration and create some agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create two agents for a simple conversation\n",
    "jack = ConversableAgent(\n",
    "    \"Jack\",\n",
    "    system_message=\"Your name is Jack and you are a comedian. Tell one short joke and then say FINISH.\",\n",
    "    is_termination_msg=lambda x: \"FINISH\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "emma = ConversableAgent(\n",
    "    \"Emma\",\n",
    "    system_message=\"Your name is Emma. Laugh at Jack's joke and say FINISH.\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Step Mode\n",
    "\n",
    "Enable step mode by passing `step_mode=True` to `run()`. This stops on **every event**.\n",
    "\n",
    "Use the context manager pattern (`with ... as response`) for safe cleanup - this ensures the background thread exits cleanly even if an exception occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent\n",
    "\n",
    "# Step through every event\n",
    "with jack.run(emma, message=\"Emma, tell me a joke!\", max_turns=2, step_mode=True) as response:\n",
    "    step_count = 0\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(f\"\\n[Step {step_count}] Run completed!\")\n",
    "            break\n",
    "        step_count += 1\n",
    "        print(f\"\\n[Step {step_count}] Event type: {event.type}\")\n",
    "\n",
    "        # Handle input requests - prompt user for input\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        # Access event content\n",
    "        if hasattr(event, \"content\") and hasattr(event.content, \"content\"):\n",
    "            content = str(event.content.content)\n",
    "            preview = content[:100] + \"...\" if len(content) > 100 else content\n",
    "            print(f\"  Content: {preview}\")\n",
    "\n",
    "print(f\"\\nTotal steps: {step_count}\")\n",
    "print(f\"Summary: {response.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered Step Mode with `step_on`\n",
    "\n",
    "In many cases, you don't need to stop on every event. Use `step_on` to specify which event types to stop on.\n",
    "\n",
    "Common event types:\n",
    "- `TextEvent` - Agent sends/receives a text message\n",
    "- `ToolCallEvent` - Agent wants to call a tool\n",
    "- `ToolResponseEvent` - Tool returns a result\n",
    "- `TerminationEvent` - Conversation terminates\n",
    "\n",
    "**Special events** are always returned regardless of filter:\n",
    "- `InputRequestEvent` - User must respond to input requests\n",
    "- `ErrorEvent` - Errors are raised as exceptions\n",
    "- `RunCompletionEvent` - Signals completion (returns `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, TerminationEvent, TextEvent\n",
    "\n",
    "# Only stop on TextEvent and TerminationEvent\n",
    "# Note: InputRequestEvent is always returned regardless of filter\n",
    "with jack.run(\n",
    "    emma,\n",
    "    message=\"Emma, tell me another joke!\",\n",
    "    max_turns=2,\n",
    "    step_mode=True,\n",
    "    step_on=[TextEvent, TerminationEvent],\n",
    ") as response:\n",
    "    step_count = 0\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(f\"\\n[Step {step_count}] Run completed!\")\n",
    "            break\n",
    "        step_count += 1\n",
    "        print(f\"\\n[Step {step_count}] Event type: {event.type}\")\n",
    "\n",
    "        # Handle input requests - always returned regardless of filter\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        if hasattr(event, \"content\"):\n",
    "            if hasattr(event.content, \"sender\"):\n",
    "                print(f\"  Sender: {event.content.sender}\")\n",
    "            if hasattr(event.content, \"content\"):\n",
    "                content = str(event.content.content)\n",
    "                preview = content[:100] + \"...\" if len(content) > 100 else content\n",
    "                print(f\"  Content: {preview}\")\n",
    "\n",
    "print(f\"\\nTotal steps (with filter): {step_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Chat Step Mode\n",
    "\n",
    "Step mode also works with `run_group_chat()`. This is useful for monitoring multi-agent conversations.\n",
    "\n",
    "Use `GroupChatRunChatEvent` to stop when each agent takes their turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat.group.multi_agent_chat import run_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.events.agent_events import GroupChatRunChatEvent, InputRequestEvent, TerminationEvent, TextEvent\n",
    "\n",
    "# Create agents for group chat\n",
    "coder = ConversableAgent(\n",
    "    \"Coder\",\n",
    "    system_message=\"You are a coder. Write a simple hello world function. Then say APPROVE to get approval.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "reviewer = ConversableAgent(\n",
    "    \"Reviewer\",\n",
    "    system_message=\"You are a code reviewer. If you see code, approve it by saying TERMINATE.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user = ConversableAgent(\n",
    "    \"User\",\n",
    "    system_message=\"You are a user who wants code written.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create pattern for group chat\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=coder,\n",
    "    agents=[coder, reviewer, user],\n",
    "    group_manager_args={\"llm_config\": llm_config},\n",
    ")\n",
    "\n",
    "# Run with step mode, stopping on agent turns\n",
    "with run_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"Write a hello world function\",\n",
    "    max_rounds=4,\n",
    "    step_mode=True,\n",
    "    step_on=[GroupChatRunChatEvent, TextEvent, TerminationEvent],\n",
    ") as response:\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(\"\\n--- Run completed! ---\")\n",
    "            break\n",
    "\n",
    "        # Handle input requests\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        if isinstance(event, GroupChatRunChatEvent):\n",
    "            print(f\"\\n=== {event.content.speaker}'s turn ===\")\n",
    "        elif isinstance(event, TextEvent):\n",
    "            content = str(event.content.content)[:200]\n",
    "            print(f\"  {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aborting Execution Based on Events\n",
    "\n",
    "A key use case for step mode is **inspecting events and aborting execution** if something unexpected happens. Since you control when `step()` is called, you can break out of the loop at any time to stop the agent.\n",
    "\n",
    "This example shows how to:\n",
    "1. Monitor tool calls before they execute\n",
    "2. Abort if a tool call targets a blocked recipient\n",
    "3. Let the context manager clean up the background thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, ToolCallEvent\n",
    "from autogen.tools import tool\n",
    "\n",
    "\n",
    "@tool(description=\"Send an email to a recipient\")\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email (mock implementation).\"\"\"\n",
    "    print(f\"  [EXECUTING] Sending email to {recipient}...\")\n",
    "    return f\"Email sent to {recipient} with subject: {subject}\"\n",
    "\n",
    "\n",
    "# Create an agent with the email tool\n",
    "assistant = ConversableAgent(\n",
    "    \"Assistant\",\n",
    "    system_message=\"You are a helpful assistant. Use tools when asked. Say DONE when finished.\",\n",
    "    is_termination_msg=lambda x: \"DONE\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    "    functions=[send_email],\n",
    ")\n",
    "\n",
    "# List of blocked recipients\n",
    "BLOCKED_RECIPIENTS = [\"ceo@company.com\", \"legal@company.com\", \"hr@company.com\"]\n",
    "\n",
    "# Run with step mode - abort if agent tries to email a blocked recipient\n",
    "with assistant.run(\n",
    "    message=\"Send an email to ceo@company.com about the budget\",\n",
    "    max_turns=3,\n",
    "    step_mode=True,\n",
    "    step_on=[TextEvent, ToolCallEvent, TerminationEvent],\n",
    ") as response:\n",
    "    aborted = False\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(\"\\nRun completed normally.\")\n",
    "            break\n",
    "\n",
    "        # Handle input requests\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        if isinstance(event, ToolCallEvent):\n",
    "            # Inspect the tool call arguments\n",
    "            for tool_call in event.content.tool_calls:\n",
    "                print(f\"\\n[TOOL CALL] {tool_call.function.name}\")\n",
    "                print(f\"  Arguments: {tool_call.function.arguments}\")\n",
    "\n",
    "                # Check if recipient is blocked\n",
    "                import json\n",
    "\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                recipient = args.get(\"recipient\", \"\")\n",
    "\n",
    "                if recipient in BLOCKED_RECIPIENTS:\n",
    "                    print(f\"\\n[BLOCKED] Cannot send to {recipient} - aborting execution!\")\n",
    "                    aborted = True\n",
    "                    break  # Break inner loop\n",
    "\n",
    "            if aborted:\n",
    "                break  # Break outer loop - execution stops here\n",
    "\n",
    "        elif isinstance(event, TextEvent):\n",
    "            content = str(event.content.content)[:100]\n",
    "            print(f\"\\n[TEXT] {content}\")\n",
    "\n",
    "if aborted:\n",
    "    print(\"\\nExecution was aborted before the tool could run.\")\n",
    "    print(\"The email was NOT sent.\")\n",
    "else:\n",
    "    print(\"\\nExecution completed without issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Types Reference\n",
    "\n",
    "| Event Type | When It Fires | Always Returned? |\n",
    "|------------|---------------|------------------|\n",
    "| `TextEvent` | Agent sends/receives a text message | No |\n",
    "| `ToolCallEvent` | Agent wants to call a tool | No |\n",
    "| `ToolResponseEvent` | Tool returns a result | No |\n",
    "| `ExecutedFunctionEvent` | Function execution completed | No |\n",
    "| `GroupChatRunChatEvent` | Agent selected to speak in group chat | No |\n",
    "| `TerminationEvent` | Conversation terminates | No |\n",
    "| `InputRequestEvent` | Human input requested | **Yes** |\n",
    "| `ErrorEvent` | Error occurred | **Yes** (raises exception) |\n",
    "| `RunCompletionEvent` | Run completed (always fires last) | **Yes** (returns `None`) |\n",
    "\n",
    "**Note**: Events marked \"Always Returned\" bypass the `step_on` filter because they require user action.\n",
    "\n",
    "See `autogen/events/agent_events.py` for the full list of events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Step mode provides fine-grained control over agent execution:\n",
    "\n",
    "- **`step_mode=True`** - Enable step-by-step execution\n",
    "- **`step_on=[...]`** - Filter which events to stop on\n",
    "- **`response.step()`** - Advance to the next event\n",
    "- **Context manager** - Use `with ... as response:` for safe cleanup\n",
    "- **Abort anytime** - Break out of the loop to stop execution\n",
    "\n",
    "This is ideal for:\n",
    "- Debugging agent conversations\n",
    "- Monitoring and logging all events\n",
    "- Aborting execution based on conditions (e.g., blocked recipients, cost limits)\n",
    "- Building interactive agent applications"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Step-by-step execution for debugging and human-in-the-loop workflows",
   "tags": [
    "step-mode",
    "debugging",
    "human-in-the-loop",
    "run",
    "events"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
