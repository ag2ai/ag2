{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Execution with AG2\n",
    "\n",
    "AG2's `run()` and `run_group_chat()` methods execute agent conversations in **background threads** that run independently of event consumption. This is great for streaming UIs, but makes it difficult to:\n",
    "\n",
    "- **Debug step-by-step** - Execution races ahead while you're inspecting events\n",
    "- **Implement human-in-the-loop** - Hard to pause for approval before each action  \n",
    "- **Build interactive tools** - Can't easily gate execution on user decisions\n",
    "\n",
    "**Step mode** solves this by synchronizing the producer (background thread) and consumer (your code) - the producer blocks after each event until you explicitly call `step()` to advance.\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install AG2:\n",
    "\n",
    "```bash\n",
    "pip install ag2[openai]\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our LLM configuration and create some agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create two agents for a simple conversation\n",
    "jack = ConversableAgent(\n",
    "    \"Jack\",\n",
    "    system_message=\"Your name is Jack and you are a comedian. Tell one short joke and then say FINISH.\",\n",
    "    is_termination_msg=lambda x: \"FINISH\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "emma = ConversableAgent(\n",
    "    \"Emma\",\n",
    "    system_message=\"Your name is Emma. Laugh at Jack's joke and say FINISH.\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Step Mode\n",
    "\n",
    "Enable step mode by passing `step_mode=True` to `run()`. This stops on **every event**.\n",
    "\n",
    "Use the context manager pattern (`with ... as response`) for safe cleanup - this ensures the background thread exits cleanly even if an exception occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1] Event type: text\n",
      "  Content: Emma, tell me a joke!\n",
      "\n",
      "[Step 2] Event type: using_auto_reply\n",
      "\n",
      "[Step 3] Event type: text\n",
      "  Content: Sure, Jack! Why don't scientists trust atoms? Because they make up everything! Haha! FINISH.\n",
      "\n",
      "[Step 4] Event type: input_request\n",
      "\n",
      "[Step 5] Event type: text\n",
      "  Content: Thank you!\n",
      "\n",
      "[Step 6] Event type: using_auto_reply\n",
      "\n",
      "[Step 7] Event type: text\n",
      "  Content: You're welcome, Jack! If you need anything else, just let me know!\n",
      "\n",
      "[Step 8] Event type: termination\n",
      "\n",
      "[Step 8] Run completed!\n",
      "\n",
      "Total steps: 8\n",
      "Summary: You're welcome, Jack! If you need anything else, just let me know!\n"
     ]
    }
   ],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent\n",
    "\n",
    "# Step through every event\n",
    "with jack.run(emma, message=\"Emma, tell me a joke!\", max_turns=2, step_mode=True) as response:\n",
    "    step_count = 0\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(f\"\\n[Step {step_count}] Run completed!\")\n",
    "            break\n",
    "        step_count += 1\n",
    "        print(f\"\\n[Step {step_count}] Event type: {event.type}\")\n",
    "\n",
    "        # Handle input requests - prompt user for input\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        # Access event content\n",
    "        if hasattr(event, \"content\") and hasattr(event.content, \"content\"):\n",
    "            content = str(event.content.content)\n",
    "            preview = content[:100] + \"...\" if len(content) > 100 else content\n",
    "            print(f\"  Content: {preview}\")\n",
    "\n",
    "print(f\"\\nTotal steps: {step_count}\")\n",
    "print(f\"Summary: {response.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered Step Mode with `step_on`\n",
    "\n",
    "In many cases, you don't need to stop on every event. Use `step_on` to specify which event types to stop on.\n",
    "\n",
    "Common event types:\n",
    "- `TextEvent` - Agent sends/receives a text message\n",
    "- `ToolCallEvent` - Agent wants to call a tool\n",
    "- `ToolResponseEvent` - Tool returns a result\n",
    "- `TerminationEvent` - Conversation terminates\n",
    "\n",
    "**Special events** are always returned regardless of filter:\n",
    "- `InputRequestEvent` - User must respond to input requests\n",
    "- `ErrorEvent` - Errors are raised as exceptions\n",
    "- `RunCompletionEvent` - Signals completion (returns `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1] Event type: text\n",
      "  Sender: Jack\n",
      "  Content: Emma, tell me another joke!\n",
      "\n",
      "[Step 2] Event type: text\n",
      "  Sender: Emma\n",
      "  Content: Haha, alright Jack, here's one for you: Why did the scarecrow win an award? Because he was outstandi...\n",
      "\n",
      "[Step 3] Event type: input_request\n",
      "\n",
      "[Step 4] Event type: text\n",
      "  Sender: Jack\n",
      "  Content: Best joke!\n",
      "\n",
      "[Step 5] Event type: text\n",
      "  Sender: Emma\n",
      "  Content: Haha, I'm glad you liked it, Jack! Want to hear another one? FINISH.\n",
      "\n",
      "[Step 6] Event type: termination\n",
      "  Sender: Jack\n",
      "\n",
      "[Step 6] Run completed!\n",
      "\n",
      "Total steps (with filter): 6\n"
     ]
    }
   ],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, TerminationEvent, TextEvent\n",
    "\n",
    "# Only stop on TextEvent and TerminationEvent\n",
    "# Note: InputRequestEvent is always returned regardless of filter\n",
    "with jack.run(\n",
    "    emma,\n",
    "    message=\"Emma, tell me another joke!\",\n",
    "    max_turns=2,\n",
    "    step_mode=True,\n",
    "    step_on=[TextEvent, TerminationEvent],\n",
    ") as response:\n",
    "    step_count = 0\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(f\"\\n[Step {step_count}] Run completed!\")\n",
    "            break\n",
    "        step_count += 1\n",
    "        print(f\"\\n[Step {step_count}] Event type: {event.type}\")\n",
    "\n",
    "        # Handle input requests - always returned regardless of filter\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        if hasattr(event, \"content\"):\n",
    "            if hasattr(event.content, \"sender\"):\n",
    "                print(f\"  Sender: {event.content.sender}\")\n",
    "            if hasattr(event.content, \"content\"):\n",
    "                content = str(event.content.content)\n",
    "                preview = content[:100] + \"...\" if len(content) > 100 else content\n",
    "                print(f\"  Content: {preview}\")\n",
    "\n",
    "print(f\"\\nTotal steps (with filter): {step_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Chat Step Mode\n",
    "\n",
    "Step mode also works with `run_group_chat()`. This is useful for monitoring multi-agent conversations.\n",
    "\n",
    "Use `GroupChatRunChatEvent` to stop when each agent takes their turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The group manager doesn't have an LLM Config and it is required for any targets or after works using a GroupManagerTarget. Use the 'llm_config' in the group_manager_args parameter to specify the LLM Config for the group manager.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m run_group_chat(\n\u001b[32m     33\u001b[39m     pattern=pattern,\n\u001b[32m     34\u001b[39m     messages=\u001b[33m\"\u001b[39m\u001b[33mWrite a hello world function\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     step_on=[GroupChatRunChatEvent, TextEvent, TerminationEvent],\n\u001b[32m     38\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         event = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     42\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Run completed! ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ag2/autogen/io/run_response.py:256\u001b[39m, in \u001b[36mRunResponse.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, ErrorEvent):\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._step_controller.terminate()\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m event.content.error  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, InputRequestEvent):\n\u001b[32m    259\u001b[39m     event.content.respond = \u001b[38;5;28;01mlambda\u001b[39;00m response: \u001b[38;5;28mself\u001b[39m.iostream._output_stream.put(response)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ag2/autogen/agentchat/group/multi_agent_chat.py:221\u001b[39m, in \u001b[36mrun_group_chat.<locals>._initiate_group_chat\u001b[39m\u001b[34m(pattern, messages, max_rounds, safeguard_policy, safeguard_llm_config, mask_llm_config, iostream, response)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IOStream.set_default(iostream):\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         chat_result, context_vars, agent = \u001b[43minitiate_group_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m            \u001b[49m\u001b[43msafeguard_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafeguard_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m            \u001b[49m\u001b[43msafeguard_llm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafeguard_llm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmask_llm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_llm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m         IOStream.get_default().send(\n\u001b[32m    231\u001b[39m             RunCompletionEvent(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    232\u001b[39m                 history=chat_result.chat_history,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m             )\n\u001b[32m    238\u001b[39m         )\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ag2/autogen/agentchat/group/multi_agent_chat.py:73\u001b[39m, in \u001b[36minitiate_group_chat\u001b[39m\u001b[34m(pattern, messages, max_rounds, safeguard_policy, safeguard_llm_config, mask_llm_config)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize and run a group chat using a pattern for configuration.\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \u001b[33;03m    \"ConversableAgent\":   Last speaker.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Let the pattern prepare the group chat and all its components\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Only passing the necessary parameters that aren't already in the pattern\u001b[39;00m\n\u001b[32m     59\u001b[39m (\n\u001b[32m     60\u001b[39m     _,  \u001b[38;5;66;03m# agents,\u001b[39;00m\n\u001b[32m     61\u001b[39m     _,  \u001b[38;5;66;03m# wrapped_agents,\u001b[39;00m\n\u001b[32m     62\u001b[39m     _,  \u001b[38;5;66;03m# user_agent,\u001b[39;00m\n\u001b[32m     63\u001b[39m     context_variables,\n\u001b[32m     64\u001b[39m     _,  \u001b[38;5;66;03m# initial_agent,\u001b[39;00m\n\u001b[32m     65\u001b[39m     _,  \u001b[38;5;66;03m# group_after_work,\u001b[39;00m\n\u001b[32m     66\u001b[39m     _,  \u001b[38;5;66;03m# tool_execution,\u001b[39;00m\n\u001b[32m     67\u001b[39m     _,  \u001b[38;5;66;03m# groupchat,\u001b[39;00m\n\u001b[32m     68\u001b[39m     manager,\n\u001b[32m     69\u001b[39m     processed_messages,\n\u001b[32m     70\u001b[39m     last_agent,\n\u001b[32m     71\u001b[39m     _,  \u001b[38;5;66;03m# group_agent_names,\u001b[39;00m\n\u001b[32m     72\u001b[39m     _,  \u001b[38;5;66;03m# temp_user_list,\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m ) = \u001b[43mpattern\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_group_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Apply safeguards if provided\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m safeguard_policy:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ag2/autogen/agentchat/group/patterns/auto.py:120\u001b[39m, in \u001b[36mAutoPattern.prepare_group_chat\u001b[39m\u001b[34m(self, max_rounds, messages)\u001b[39m\n\u001b[32m    117\u001b[39m         agent.description = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Use the parent class's implementation to prepare the agents and group chat\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m components = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_group_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Extract the group_after_work and the rest of the components\u001b[39;00m\n\u001b[32m    126\u001b[39m (\n\u001b[32m    127\u001b[39m     agents,\n\u001b[32m    128\u001b[39m     wrapped_agents,\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     temp_user_list,\n\u001b[32m    140\u001b[39m ) = components\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ag2/autogen/agentchat/group/patterns/pattern.py:153\u001b[39m, in \u001b[36mPattern.prepare_group_chat\u001b[39m\u001b[34m(self, max_rounds, messages)\u001b[39m\n\u001b[32m    142\u001b[39m groupchat = GroupChat(\n\u001b[32m    143\u001b[39m     agents=[tool_executor]\n\u001b[32m    144\u001b[39m     + \u001b[38;5;28mself\u001b[39m.agents\n\u001b[32m   (...)\u001b[39m\u001b[32m    149\u001b[39m     speaker_selection_method=group_transition,\n\u001b[32m    150\u001b[39m )\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# Create the group manager\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m manager = \u001b[43mcreate_group_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroupchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup_manager_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup_after_work\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Point all agent's context variables to this function's context_variables\u001b[39;00m\n\u001b[32m    156\u001b[39m setup_context_variables(\n\u001b[32m    157\u001b[39m     tool_execution=tool_executor,\n\u001b[32m    158\u001b[39m     agents=\u001b[38;5;28mself\u001b[39m.agents,\n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m     context_variables=\u001b[38;5;28mself\u001b[39m.context_variables,\n\u001b[32m    162\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ag2/autogen/agentchat/group/group_utils.py:605\u001b[39m, in \u001b[36mcreate_group_manager\u001b[39m\u001b[34m(groupchat, group_manager_args, agents, group_after_work)\u001b[39m\n\u001b[32m    602\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    604\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_group_manager_target:\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    606\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe group manager doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have an LLM Config and it is required for any targets or after works using a GroupManagerTarget. Use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mllm_config\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in the group_manager_args parameter to specify the LLM Config for the group manager.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    607\u001b[39m         )\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m manager\n",
      "\u001b[31mValueError\u001b[39m: The group manager doesn't have an LLM Config and it is required for any targets or after works using a GroupManagerTarget. Use the 'llm_config' in the group_manager_args parameter to specify the LLM Config for the group manager."
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat.group.multi_agent_chat import run_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.events.agent_events import GroupChatRunChatEvent, InputRequestEvent, TerminationEvent, TextEvent\n",
    "\n",
    "# Create agents for group chat\n",
    "coder = ConversableAgent(\n",
    "    \"Coder\",\n",
    "    system_message=\"You are a coder. Write a simple hello world function. Then say APPROVE to get approval.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "reviewer = ConversableAgent(\n",
    "    \"Reviewer\",\n",
    "    system_message=\"You are a code reviewer. If you see code, approve it by saying TERMINATE.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user = ConversableAgent(\n",
    "    \"User\",\n",
    "    system_message=\"You are a user who wants code written.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create pattern for group chat\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=coder,\n",
    "    agents=[coder, reviewer, user],\n",
    "    group_manager_args={\"llm_config\": llm_config},\n",
    ")\n",
    "\n",
    "# Run with step mode, stopping on agent turns\n",
    "with run_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"Write a hello world function\",\n",
    "    max_rounds=4,\n",
    "    step_mode=True,\n",
    "    step_on=[GroupChatRunChatEvent, TextEvent, TerminationEvent],\n",
    ") as response:\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(\"\\n--- Run completed! ---\")\n",
    "            break\n",
    "\n",
    "        # Handle input requests\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        if isinstance(event, GroupChatRunChatEvent):\n",
    "            print(f\"\\n=== {event.content.speaker}'s turn ===\")\n",
    "        elif isinstance(event, TextEvent):\n",
    "            content = str(event.content.content)[:200]\n",
    "            print(f\"  {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aborting Execution Based on Events\n",
    "\n",
    "A key use case for step mode is **inspecting events and aborting execution** if something unexpected happens. Since you control when `step()` is called, you can break out of the loop at any time to stop the agent.\n",
    "\n",
    "This example shows how to:\n",
    "1. Monitor tool calls before they execute\n",
    "2. Abort if a tool call targets a blocked recipient\n",
    "3. Let the context manager clean up the background thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, ToolCallEvent\n",
    "from autogen.tools import tool\n",
    "\n",
    "\n",
    "@tool(description=\"Send an email to a recipient\")\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email (mock implementation).\"\"\"\n",
    "    print(f\"  [EXECUTING] Sending email to {recipient}...\")\n",
    "    return f\"Email sent to {recipient} with subject: {subject}\"\n",
    "\n",
    "\n",
    "# Create an agent with the email tool\n",
    "assistant = ConversableAgent(\n",
    "    \"Assistant\",\n",
    "    system_message=\"You are a helpful assistant. Use tools when asked. Say DONE when finished.\",\n",
    "    is_termination_msg=lambda x: \"DONE\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    "    functions=[send_email],\n",
    ")\n",
    "\n",
    "# List of blocked recipients\n",
    "BLOCKED_RECIPIENTS = [\"ceo@company.com\", \"legal@company.com\", \"hr@company.com\"]\n",
    "\n",
    "# Run with step mode - abort if agent tries to email a blocked recipient\n",
    "with assistant.run(\n",
    "    message=\"Send an email to ceo@company.com about the budget\",\n",
    "    max_turns=3,\n",
    "    step_mode=True,\n",
    "    step_on=[TextEvent, ToolCallEvent, TerminationEvent],\n",
    ") as response:\n",
    "    aborted = False\n",
    "    while True:\n",
    "        event = response.step()\n",
    "        if event is None:\n",
    "            print(\"\\nRun completed normally.\")\n",
    "            break\n",
    "\n",
    "        # Handle input requests\n",
    "        if isinstance(event, InputRequestEvent):\n",
    "            user_input = input(\"  Input requested: \")\n",
    "            event.content.respond(user_input)\n",
    "            continue\n",
    "\n",
    "        if isinstance(event, ToolCallEvent):\n",
    "            # Inspect the tool call arguments\n",
    "            for tool_call in event.content.tool_calls:\n",
    "                print(f\"\\n[TOOL CALL] {tool_call.function.name}\")\n",
    "                print(f\"  Arguments: {tool_call.function.arguments}\")\n",
    "\n",
    "                # Check if recipient is blocked\n",
    "                import json\n",
    "\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                recipient = args.get(\"recipient\", \"\")\n",
    "\n",
    "                if recipient in BLOCKED_RECIPIENTS:\n",
    "                    print(f\"\\n[BLOCKED] Cannot send to {recipient} - aborting execution!\")\n",
    "                    aborted = True\n",
    "                    break  # Break inner loop\n",
    "\n",
    "            if aborted:\n",
    "                break  # Break outer loop - execution stops here\n",
    "\n",
    "        elif isinstance(event, TextEvent):\n",
    "            content = str(event.content.content)[:100]\n",
    "            print(f\"\\n[TEXT] {content}\")\n",
    "\n",
    "if aborted:\n",
    "    print(\"\\nExecution was aborted before the tool could run.\")\n",
    "    print(\"The email was NOT sent.\")\n",
    "else:\n",
    "    print(\"\\nExecution completed without issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Types Reference\n",
    "\n",
    "| Event Type | When It Fires | Always Returned? |\n",
    "|------------|---------------|------------------|\n",
    "| `TextEvent` | Agent sends/receives a text message | No |\n",
    "| `ToolCallEvent` | Agent wants to call a tool | No |\n",
    "| `ToolResponseEvent` | Tool returns a result | No |\n",
    "| `ExecutedFunctionEvent` | Function execution completed | No |\n",
    "| `GroupChatRunChatEvent` | Agent selected to speak in group chat | No |\n",
    "| `TerminationEvent` | Conversation terminates | No |\n",
    "| `InputRequestEvent` | Human input requested | **Yes** |\n",
    "| `ErrorEvent` | Error occurred | **Yes** (raises exception) |\n",
    "| `RunCompletionEvent` | Run completed (always fires last) | **Yes** (returns `None`) |\n",
    "\n",
    "**Note**: Events marked \"Always Returned\" bypass the `step_on` filter because they require user action.\n",
    "\n",
    "See `autogen/events/agent_events.py` for the full list of events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Step mode provides fine-grained control over agent execution:\n",
    "\n",
    "- **`step_mode=True`** - Enable step-by-step execution\n",
    "- **`step_on=[...]`** - Filter which events to stop on\n",
    "- **`response.step()`** - Advance to the next event\n",
    "- **Context manager** - Use `with ... as response:` for safe cleanup\n",
    "- **Abort anytime** - Break out of the loop to stop execution\n",
    "\n",
    "This is ideal for:\n",
    "- Debugging agent conversations\n",
    "- Monitoring and logging all events\n",
    "- Aborting execution based on conditions (e.g., blocked recipients, cost limits)\n",
    "- Building interactive agent applications"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Step-by-step execution for debugging and human-in-the-loop workflows",
   "tags": [
    "step-mode",
    "debugging",
    "human-in-the-loop",
    "run",
    "events"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
