{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Structured Outputs with output_format\n",
    "\n",
    "This notebook demonstrates how to use Anthropic's structured outputs feature using the `output_format` parameter. Anthropic's structured outputs allow you to enforce a specific JSON schema for the model's response, ensuring consistent and validated output.\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install `ag2` with Anthropic support:\n",
    "\n",
    "pip install -U ag2[anthropic]\n",
    "```\n",
    "\n",
    "> **Note:** Structured outputs require `anthropic` SDK >= 0.39.0. If you have an older version, the client will automatically fall back to legacy JSON mode with a warning.\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding output_format\n",
    "\n",
    "Anthropic's `output_format` parameter accepts a JSON schema that defines the structure of the response. The schema must follow this format:\n",
    "\n",
    "n\n",
    "{\n",
    "    \"type\": \"json_schema\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"field_name\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"field_name\"],\n",
    "        \"additionalProperties\": false\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Using output_format directly\n",
    "\n",
    "Let's create a simple example that extracts contact information using structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# Define the output format schema\n",
    "output_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\"},\n",
    "            \"email\": {\"type\": \"string\"},\n",
    "            \"age\": {\"type\": \"integer\"},\n",
    "            \"interests\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"name\", \"email\", \"age\", \"interests\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create LLM config with output_format\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"api_type\": \"anthropic\",\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "            \"output_format\": output_format,  # Direct output_format usage\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create agents\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"ContactExtractor\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Extract contact information from user messages and return it in the specified JSON format.\",\n",
    ")\n",
    "\n",
    "# Test the structured output\n",
    "result = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"My name is John Doe, I'm 30 years old, my email is john@example.com, and I love Python and AI.\",\n",
    "    max_turns=1,\n",
    ")\n",
    "\n",
    "print(result.chat_history[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Using response_format (converted to output_format)\n",
    "\n",
    "You can also use `response_format` with a Pydantic model, which will be automatically converted to `output_format`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define a Pydantic model\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    age: int\n",
    "    interests: list[str]\n",
    "\n",
    "\n",
    "# Create LLM config with response_format (will be converted to output_format)\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"api_type\": \"anthropic\",\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "            \"response_format\": ContactInfo,  # Pydantic model - auto-converted\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"ContactExtractor\", llm_config=llm_config, system_message=\"Extract contact information from user messages.\"\n",
    ")\n",
    "\n",
    "result = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"I'm Jane Smith, 28 years old, email jane@example.com, interested in machine learning and data science.\",\n",
    "    max_turns=1,\n",
    ")\n",
    "\n",
    "print(result.chat_history[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Complex nested schema\n",
    "\n",
    "Here's an example with a more complex nested structure for math problem solving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a complex output format for step-by-step math reasoning\n",
    "math_output_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"steps\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"step_number\": {\"type\": \"integer\"},\n",
    "                        \"explanation\": {\"type\": \"string\"},\n",
    "                        \"calculation\": {\"type\": \"string\"},\n",
    "                    },\n",
    "                    \"required\": [\"step_number\", \"explanation\", \"calculation\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            },\n",
    "            \"final_answer\": {\"type\": \"string\"},\n",
    "            \"confidence\": {\"type\": \"string\", \"enum\": [\"high\", \"medium\", \"low\"]},\n",
    "        },\n",
    "        \"required\": [\"steps\", \"final_answer\", \"confidence\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"api_type\": \"anthropic\",\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "            \"output_format\": math_output_format,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "math_assistant = AssistantAgent(\n",
    "    name=\"MathSolver\", llm_config=llm_config, system_message=\"Solve math problems step by step, showing your reasoning.\"\n",
    ")\n",
    "\n",
    "result = user_proxy.initiate_chat(math_assistant, message=\"Solve for x: 3x + 7 = 22\", max_turns=1)\n",
    "\n",
    "print(result.chat_history[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using the AnthropicClient directly\n",
    "\n",
    "You can also use the `AnthropicClient` directly for more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.oai.anthropic import AnthropicClient\n",
    "\n",
    "# Initialize the client\n",
    "client = AnthropicClient(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# Define output format\n",
    "output_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"summary\": {\"type\": \"string\"},\n",
    "            \"key_points\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"neutral\", \"negative\"]},\n",
    "        },\n",
    "        \"required\": [\"summary\", \"key_points\", \"sentiment\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create a completion with structured output\n",
    "response = client.create({\n",
    "    \"model\": \"claude-sonnet-4-5\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Analyze this text: 'The new product launch was a huge success. Sales increased by 50% and customer feedback has been overwhelmingly positive.'\",\n",
    "        }\n",
    "    ],\n",
    "    \"output_format\": output_format,\n",
    "    \"max_tokens\": 500,\n",
    "})\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "1. **output_format vs response_format**: \n",
    "   - `output_format` is the native Anthropic parameter (dict with `type: \"json_schema\"`)\n",
    "   - `response_format` can be a Pydantic model or dict, and will be automatically converted to `output_format`\n",
    "\n",
    "2. **Schema Requirements**:\n",
    "   - Must have `type: \"object\"` at the root\n",
    "   - Should set `additionalProperties: false` to enforce strict schema\n",
    "   - All required fields must be listed in the `required` array\n",
    "\n",
    "3. **SDK Version**: Requires `anthropic` SDK >= 0.39.0. Older versions will fall back to legacy JSON mode with a warning.\n",
    "\n",
    "4. **Beta API**: The client automatically uses Anthropic's beta API (`beta.messages.create`) when structured outputs are enabled, adding the required `betas: [\"structured-outputs-2025-11-13\"]` header.\n",
    "\n",
    "For more information, see the [Anthropic structured outputs documentation](https://docs.anthropic.com/en/docs/build-with-claude/structured-outputs)."
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "This notebook demonstrates the use of Anthropic's structured outputs feature using the `output_format` parameter.",
   "tags": [
    "integration",
    "structured output",
    "anthropic",
    "output_format",
    "response_format",
    "json_schema",
    "claude-sonnet-4-5"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
