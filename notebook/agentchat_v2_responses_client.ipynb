{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Responses API V2 Client - Complete Guide\n",
    "\n",
    "This notebook demonstrates the `OpenAIResponsesV2Client` which implements the new OpenAI Responses API with rich `UnifiedResponse` objects.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Stateful Conversations**: Maintain conversation context via `previous_response_id`\n",
    "- **Built-in Tools**: Web search, image generation, apply_patch\n",
    "- **Rich Content Blocks**: TextContent, ReasoningContent, CitationContent, ImageContent, ToolCallContent\n",
    "- **Multimodal Support**: Send and receive images\n",
    "- **Structured Output**: Pydantic models and JSON schema support\n",
    "- **Cost Tracking**: Token and image generation cost tracking\n",
    "- **Agent Integration**: Works with AG2 agents for single, two-agent, and group chat\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AG2 requires `Python>=3.9`. Install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ag2[openai]\" -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Set your OpenAI API key as an environment variable or pass it directly to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key (or use environment variable OPENAI_API_KEY)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Basic Usage\n",
    "\n",
    "The `OpenAIResponsesV2Client` returns rich `UnifiedResponse` objects with typed content blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_0d04c8f4ca158d66006980752f2d70819c8e7bba42b01dd1f6\n",
      "Model: gpt-4.1-2025-04-14\n",
      "Content: I'm an AI language model created by OpenAI, here to help answer your questions, have conversations, and assist with a wide range of topics. I don't have feelings, but thank you for asking—I'm always ready to help!\n",
      "\n",
      "**About me:**  \n",
      "- I can understand and generate text, images, and more.\n",
      "- My knowledge extends up to June 2024.\n",
      "- I don't have personal experiences or emotions, but I can explain concepts, solve problems, and simulate conversation.\n",
      "\n",
      "**What is a machine?**  \n",
      "A **machine** is any device or system that uses energy to perform a specific task, often making work easier, faster, or more efficient. Machines can be as simple as a lever or wheel, or as complex as a computer or robot. They are usually made up of components like gears, levers, motors, or electronic circuits that work together to achieve a specific function.\n",
      "\n",
      "*Examples of machines include:*  \n",
      "- A car (converts fuel into motion)\n",
      "- A washing machine (cleans clothes)\n",
      "- A computer (processes information)\n",
      "\n",
      "Let me know if you want more details about any specific kind of machine!\n"
     ]
    }
   ],
   "source": [
    "from autogen.llm_clients.openai_resposnes_v2_client import OpenAIResponsesV2Client\n",
    "\n",
    "# Create the V2 client\n",
    "client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Make a simple request\n",
    "response = client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"how are you? tell me about yourself? and what is a machine?\"}]\n",
    "})\n",
    "\n",
    "# Access the response\n",
    "print(f\"Response ID: {response.id}\")\n",
    "print(f\"Model: {response.model}\")\n",
    "print(f\"Content: {response.messages[0].get_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding UnifiedResponse Structure\n",
    "\n",
    "The `UnifiedResponse` contains rich, typed content blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages: 1\n",
      "Usage: {'prompt_tokens': 22, 'completion_tokens': 231, 'total_tokens': 253, 'token_cost': 0.001892, 'image_cost': 0.0}\n",
      "Cost: $0.001892\n",
      "\n",
      "Role: assistant\n",
      "  Text: I'm an AI language model created by OpenAI, here to help answer your questions, have conversations, ...\n"
     ]
    }
   ],
   "source": [
    "from autogen.llm_clients.models.content_blocks import (\n",
    "    TextContent,\n",
    "    ReasoningContent,\n",
    "    CitationContent,\n",
    "    ImageContent,\n",
    "    ToolCallContent,\n",
    "    GenericContent,\n",
    ")\n",
    "\n",
    "# Inspect the response structure\n",
    "print(f\"Number of messages: {len(response.messages)}\")\n",
    "print(f\"Usage: {response.usage}\")\n",
    "print(f\"Cost: ${response.cost:.6f}\")\n",
    "\n",
    "# Iterate through content blocks\n",
    "for msg in response.messages:\n",
    "    print(f\"\\nRole: {msg.role}\")\n",
    "    for block in msg.content:\n",
    "        if isinstance(block, TextContent):\n",
    "            print(f\"  Text: {block.text[:100]}...\" if len(block.text) > 100 else f\"  Text: {block.text}\")\n",
    "        elif isinstance(block, ReasoningContent):\n",
    "            print(f\"  Reasoning: {block.text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Stateful Conversations\n",
    "\n",
    "The Responses API is **stateful** - it maintains conversation context server-side using `previous_response_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Got it, Alice! I’ll remember your name. How can I help you today?\n",
      "Response ID: resp_07cf7e90399d7a6c0069807553d864819e94e6e0e46ed47bbe\n"
     ]
    }
   ],
   "source": [
    "# Create a new client for stateful conversation\n",
    "stateful_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# First message\n",
    "response1 = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"My name is Alice. Remember this.\"}]\n",
    "})\n",
    "print(f\"Response 1: {response1.messages[0].get_text()}\")\n",
    "print(f\"Response ID: {response1.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 2: Your name is Alice. How can I assist you today?\n",
      "\n",
      "The model remembered the context from the previous turn!\n"
     ]
    }
   ],
   "source": [
    "# Second message - the client automatically tracks state\n",
    "response2 = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]\n",
    "})\n",
    "print(f\"Response 2: {response2.messages[0].get_text()}\")\n",
    "print(f\"\\nThe model remembered the context from the previous turn!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reset: You haven't told me your name yet! If you'd like to share it, I can use it in our conversation.\n",
      "\n",
      "The model no longer has context from previous conversation.\n"
     ]
    }
   ],
   "source": [
    "# Reset conversation state to start fresh\n",
    "stateful_client.reset_conversation()\n",
    "\n",
    "response3 = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]\n",
    "})\n",
    "print(f\"After reset: {response3.messages[0].get_text()}\")\n",
    "print(\"\\nThe model no longer has context from previous conversation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual State Control\n",
    "\n",
    "You can also manually control the conversation state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: resp_07cf7e90399d7a6c00698076e79244819e91adf42a6bbb50d6\n",
      "Updated state: resp_07cf7e90399d7a6c00698076f07280819ea8ea0382e7d2f7f0\n"
     ]
    }
   ],
   "source": [
    "# Get current state\n",
    "current_state = stateful_client._get_previous_response_id()\n",
    "print(f\"Current state: {current_state}\")\n",
    "\n",
    "# Manually set state to continue a specific conversation\n",
    "stateful_client._set_previous_response_id(\"resp_07cf7e90399d7a6c0069807553d864819e94e6e0e46ed47bbe\")\n",
    "\n",
    "# Or pass previous_response_id directly in params\n",
    "response = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Continue from here\"}],\n",
    "    \"previous_response_id\": \"resp_07cf7e90399d7a6c0069807553d864819e94e6e0e46ed47bbe\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Multimodal Support\n",
    "\n",
    "Send images in your messages using various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multimodal message with an image URL\n",
    "multimodal_message = OpenAIResponsesV2Client.create_multimodal_message(\n",
    "    text=\"What do you see in this image?\",\n",
    "    images=[\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"],\n",
    "    role=\"user\"\n",
    ")\n",
    "\n",
    "print(\"Multimodal message structure:\")\n",
    "print(multimodal_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send multimodal request\n",
    "mm_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = mm_client.create({\n",
    "    \"model\": \"gpt-4.1\",  # Use a vision-capable model\n",
    "    \"messages\": [multimodal_message]\n",
    "})\n",
    "\n",
    "print(f\"Image description: {response.messages[0].get_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Image Content\n",
    "\n",
    "You can also create image content directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image content from URL\n",
    "image_content = OpenAIResponsesV2Client.create_image_content(\n",
    "    image_url=\"https://example.com/image.jpg\"\n",
    ")\n",
    "print(f\"Image content: {image_content}\")\n",
    "\n",
    "# Or from base64 data URI\n",
    "# image_content = OpenAIResponsesV2Client.create_image_content(\n",
    "#     data_uri=\"data:image/png;base64,iVBORw0KGgo...\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Built-in Tools\n",
    "\n",
    "The Responses API provides built-in tools that don't require function definitions.\n",
    "\n",
    "## 4.1 Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable web search\n",
    "search_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = search_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What are the latest news about AI?\"}],\n",
    "    \"built_in_tools\": [\"web_search\"]\n",
    "})\n",
    "\n",
    "print(f\"Response: {response.messages[0].get_text()[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract citations from the response\n",
    "citations = OpenAIResponsesV2Client.get_citations(response)\n",
    "\n",
    "print(f\"\\nFound {len(citations)} citations:\")\n",
    "for citation in citations[:5]:  # Show first 5\n",
    "    print(f\"  - {citation.title}: {citation.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable image generation\n",
    "image_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Configure image output parameters\n",
    "image_client.set_image_output_params(\n",
    "    quality=\"high\",\n",
    "    size=\"1024x1024\",\n",
    "    output_format=\"png\"\n",
    ")\n",
    "\n",
    "response = image_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Generate an image of a sunset over mountains\"}],\n",
    "    \"built_in_tools\": [\"image_generation\"]\n",
    "})\n",
    "\n",
    "# Extract generated images\n",
    "images = OpenAIResponsesV2Client.get_generated_images(response)\n",
    "print(f\"Generated {len(images)} image(s)\")\n",
    "\n",
    "if images:\n",
    "    print(f\"Image data URI (truncated): {images[0].data_uri[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image generation costs\n",
    "print(f\"Image costs: ${image_client.get_image_costs():.4f}\")\n",
    "print(f\"Total costs: ${image_client.get_total_costs():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Define a Pydantic model for structured output\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    occupation: str\n",
    "\n",
    "# Request structured output\n",
    "struct_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = struct_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Generate a fictional person's profile\"}],\n",
    "    \"response_format\": Person\n",
    "})\n",
    "\n",
    "# Get the parsed object\n",
    "parsed = OpenAIResponsesV2Client.get_parsed_object(response)\n",
    "if parsed:\n",
    "    print(f\"Name: {parsed.name}\")\n",
    "    print(f\"Age: {parsed.age}\")\n",
    "    print(f\"Occupation: {parsed.occupation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Cost Tracking\n",
    "\n",
    "The V2 client tracks both token costs and image generation costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Make several requests\n",
    "for i in range(3):\n",
    "    response = cost_client.create({\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": f\"Count to {i+1}\"}]\n",
    "    })\n",
    "    \n",
    "    # Per-request cost\n",
    "    usage = OpenAIResponsesV2Client.get_usage(response)\n",
    "    print(f\"Request {i+1}: {usage['total_tokens']} tokens, ${usage['cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cumulative usage\n",
    "cumulative = cost_client.get_cumulative_usage()\n",
    "print(f\"\\nCumulative Usage:\")\n",
    "print(f\"  Total prompt tokens: {cumulative['prompt_tokens']}\")\n",
    "print(f\"  Total completion tokens: {cumulative['completion_tokens']}\")\n",
    "print(f\"  Total tokens: {cumulative['total_tokens']}\")\n",
    "print(f\"  Token cost: ${cumulative['token_cost']:.6f}\")\n",
    "print(f\"  Image cost: ${cumulative['image_cost']:.6f}\")\n",
    "print(f\"  Total cost: ${cumulative['total_cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset cost tracking\n",
    "cost_client.reset_all_costs()\n",
    "print(f\"After reset: ${cost_client.get_total_costs():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom pricing for fine-tuned models\n",
    "custom_client = OpenAIResponsesV2Client()\n",
    "custom_client.set_custom_price(\n",
    "    input_price_per_1k=0.003,\n",
    "    output_price_per_1k=0.006\n",
    ")\n",
    "\n",
    "response = custom_client.create({\n",
    "    \"model\": \"ft:gpt-4.1:my-org:custom-model\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    "})\n",
    "\n",
    "print(f\"Cost with custom pricing: ${custom_client.cost(response):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. V1 Backward Compatibility\n",
    "\n",
    "For code that expects ChatCompletion format, use `create_v1_compatible()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Get ChatCompletion-like response\n",
    "response = v1_client.create_v1_compatible({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    "})\n",
    "\n",
    "# Access like standard ChatCompletion\n",
    "print(f\"Type: {type(response).__name__}\")\n",
    "print(f\"Content: {response.choices[0].message.content}\")\n",
    "print(f\"Tokens: {response.usage.total_tokens}\")\n",
    "print(f\"Cost: ${response.cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Agent Integration\n",
    "\n",
    "The V2 client integrates with AG2 agents for conversational AI workflows.\n",
    "\n",
    "## 7.1 Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "# Configure LLM with Responses API\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"api_type\": \"responses\",  # Use Responses API\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\"config_list\": config_list}\n",
    "\n",
    "# Create a single assistant agent\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "# Start a conversation\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What is the capital of France?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Two-Agent Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two specialized agents\n",
    "researcher = autogen.AssistantAgent(\n",
    "    name=\"researcher\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a research assistant. Your job is to:\n",
    "    1. Analyze questions thoroughly\n",
    "    2. Provide detailed, factual information\n",
    "    3. Cite sources when possible\"\"\"\n",
    ")\n",
    "\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"critic\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a critical reviewer. Your job is to:\n",
    "    1. Review the researcher's findings\n",
    "    2. Point out any gaps or inaccuracies\n",
    "    3. Suggest improvements\n",
    "    Say 'TERMINATE' when the research is satisfactory.\"\"\"\n",
    ")\n",
    "\n",
    "# Two-agent collaboration\n",
    "researcher.initiate_chat(\n",
    "    critic,\n",
    "    message=\"Research the benefits and drawbacks of renewable energy sources.\",\n",
    "    max_turns=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple specialized agents for group chat\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"planner\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a project planner. Break down tasks into actionable steps.\n",
    "    Focus on creating clear, organized plans.\"\"\"\n",
    ")\n",
    "\n",
    "developer = autogen.AssistantAgent(\n",
    "    name=\"developer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a software developer. Implement solutions based on the plan.\n",
    "    Write clean, well-documented code.\"\"\"\n",
    ")\n",
    "\n",
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a code reviewer. Review implementations for:\n",
    "    1. Correctness\n",
    "    2. Best practices\n",
    "    3. Potential improvements\n",
    "    Say 'TERMINATE' when the solution is complete and reviewed.\"\"\"\n",
    ")\n",
    "\n",
    "user_proxy_gc = autogen.UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group chat\n",
    "group_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy_gc, planner, developer, reviewer],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "# Start the group chat\n",
    "user_proxy_gc.initiate_chat(\n",
    "    manager,\n",
    "    message=\"Create a Python function that calculates the Fibonacci sequence up to n terms.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Advanced: Custom Function Tools\n",
    "\n",
    "Combine built-in tools with custom function tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # Mock implementation\n",
    "    return f\"The weather in {city} is sunny, 72°F\"\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Define tool schemas\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Evaluate a math expression\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\"type\": \"string\", \"description\": \"Math expression\"}\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Tools defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom tools with the V2 client\n",
    "tools_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = tools_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What's 25 * 4 + 10?\"}],\n",
    "    \"tools\": tools\n",
    "})\n",
    "\n",
    "# Check for tool calls\n",
    "for msg in response.messages:\n",
    "    for block in msg.content:\n",
    "        if isinstance(block, ToolCallContent):\n",
    "            print(f\"Tool call: {block.name}({block.arguments})\")\n",
    "        elif isinstance(block, TextContent):\n",
    "            print(f\"Text: {block.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "The `OpenAIResponsesV2Client` provides:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Stateful Conversations** | Automatic context tracking via `previous_response_id` |\n",
    "| **Rich Content Blocks** | TextContent, ReasoningContent, CitationContent, ImageContent, ToolCallContent |\n",
    "| **Built-in Tools** | Web search, image generation, apply_patch |\n",
    "| **Multimodal Support** | Send and receive images |\n",
    "| **Structured Output** | Pydantic models and JSON schemas |\n",
    "| **Cost Tracking** | Token and image generation cost tracking |\n",
    "| **V1 Compatibility** | `create_v1_compatible()` for ChatCompletion format |\n",
    "| **Agent Integration** | Works with AG2 single, two-agent, and group chat |\n",
    "\n",
    "For more information, see the [AG2 documentation](https://docs.ag2.ai)."
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "OpenAI Responses API V2 Client with rich UnifiedResponse objects, stateful conversations, and agent integration",
   "tags": [
    "openai",
    "responses-api",
    "v2-client",
    "multimodal",
    "agents"
   ]
  },
  "kernelspec": {
   "display_name": "ag2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
