{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Responses API V2 Client - Complete Guide\n",
    "\n",
    "This notebook demonstrates the `OpenAIResponsesV2Client` which implements the new OpenAI Responses API with rich `UnifiedResponse` objects.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Stateful Conversations**: Maintain conversation context via `previous_response_id`\n",
    "- **Built-in Tools**: Web search, image generation, apply_patch\n",
    "- **Rich Content Blocks**: TextContent, ReasoningContent, CitationContent, ImageContent, ToolCallContent\n",
    "- **Multimodal Support**: Send and receive images\n",
    "- **Structured Output**: Pydantic models and JSON schema support\n",
    "- **Cost Tracking**: Token and image generation cost tracking\n",
    "- **Agent Integration**: Works with AG2 agents for single, two-agent, and group chat\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AG2 requires `Python>=3.9`. Install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ag2[openai]\" -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Set your OpenAI API key as an environment variable or pass it directly to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key (or use environment variable OPENAI_API_KEY)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Basic Usage\n",
    "\n",
    "The `OpenAIResponsesV2Client` returns rich `UnifiedResponse` objects with typed content blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.llm_clients.openai_resposnes_v2_client import OpenAIResponsesV2Client\n",
    "\n",
    "# Create the V2 client\n",
    "client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Make a simple request\n",
    "# response = client.create({\n",
    "#     \"model\": \"gpt-4.1\",\n",
    "#     \"messages\": [{\"role\": \"user\", \"content\": \"how are you? tell me about yourself? and what is a machine? in one line\"}]\n",
    "# })\n",
    "\n",
    "# # Access the response\n",
    "# print(f\"Response ID: {response.id}\")\n",
    "# print(f\"Model: {response.model}\")\n",
    "# print(f\"Content: {response.messages[0].get_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding UnifiedResponse Structure\n",
    "\n",
    "The `UnifiedResponse` contains rich, typed content blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages: 1\n",
      "Usage: {'prompt_tokens': 25, 'completion_tokens': 37, 'total_tokens': 62, 'token_cost': 0.00034599999999999995, 'image_cost': 0.0}\n",
      "Cost: $0.000346\n",
      "\n",
      "Role: assistant\n",
      "  Text: I'm an AI language model created by OpenAI, here to assist you with information and tasks.  \n",
      "A machi...\n"
     ]
    }
   ],
   "source": [
    "from autogen.llm_clients.models.content_blocks import (\n",
    "    TextContent,\n",
    "    ReasoningContent,\n",
    "    CitationContent,\n",
    "    ImageContent,\n",
    "    ToolCallContent,\n",
    "    GenericContent,\n",
    ")\n",
    "\n",
    "# Inspect the response structure\n",
    "print(f\"Number of messages: {len(response.messages)}\")\n",
    "print(f\"Usage: {response.usage}\")\n",
    "print(f\"Cost: ${response.cost:.6f}\")\n",
    "\n",
    "# Iterate through content blocks\n",
    "for msg in response.messages:\n",
    "    print(f\"\\nRole: {msg.role}\")\n",
    "    for block in msg.content:\n",
    "        if isinstance(block, TextContent):\n",
    "            print(f\"  Text: {block.text[:100]}...\" if len(block.text) > 100 else f\"  Text: {block.text}\")\n",
    "        elif isinstance(block, ReasoningContent):\n",
    "            print(f\"  Reasoning: {block.text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Stateful Conversations\n",
    "\n",
    "The Responses API is **stateful** - it maintains conversation context server-side using `previous_response_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Got it, Alice! I'll remember that your name is Alice for our conversation. How can I assist you today?\n",
      "Response ID: resp_09bcfb641a3514e0006980bd6f775881a2a4cec47716322369\n"
     ]
    }
   ],
   "source": [
    "# Create a new client for stateful conversation\n",
    "stateful_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# First message\n",
    "response1 = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"My name is Alice. Remember this.\"}]\n",
    "})\n",
    "print(f\"Response 1: {response1.messages[0].get_text()}\")\n",
    "print(f\"Response ID: {response1.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 2: Your name is Alice.\n",
      "\n",
      "The model remembered the context from the previous turn!\n"
     ]
    }
   ],
   "source": [
    "# Second message - the client automatically tracks state\n",
    "response2 = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]\n",
    "})\n",
    "print(f\"Response 2: {response2.messages[0].get_text()}\")\n",
    "print(f\"\\nThe model remembered the context from the previous turn!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reset: I don’t have access to your name unless you tell me! How would you like me to address you?\n",
      "\n",
      "The model no longer has context from previous conversation.\n"
     ]
    }
   ],
   "source": [
    "# Reset conversation state to start fresh\n",
    "stateful_client.reset_conversation()\n",
    "\n",
    "response3 = stateful_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]\n",
    "})\n",
    "print(f\"After reset: {response3.messages[0].get_text()}\")\n",
    "print(\"\\nThe model no longer has context from previous conversation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual State Control\n",
    "\n",
    "You can also manually control the conversation state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: resp_03268ea8f0ea1a85006980bdcf50648196a66e866209ec4c60\n",
      "response_a1_id resp_00f1ce2a12188a60006980bde2a71881a3b67c1b878e195dab\n",
      "response_b1_id resp_00f1ce2a12188a60006980bde2a71881a3b67c1b878e195dab\n"
     ]
    }
   ],
   "source": [
    "# Get current state\n",
    "current_state = stateful_client._get_previous_response_id()\n",
    "print(f\"Current state: {current_state}\")\n",
    "\n",
    "# Or pass previous_response_id directly in params\n",
    "\n",
    "# Get a fresh response ID\n",
    "response_a = client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, my name is Alice\"}]\n",
    "})\n",
    "\n",
    "response_a_id = client._get_previous_response_id()\n",
    "\n",
    "response_b = client.create({\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello, my name is Hatter\"}]\n",
    "})\n",
    "\n",
    "response_b_id = client._get_previous_response_id()\n",
    "\n",
    "# Use the fresh ID immediately\n",
    "client._set_previous_response_id(response_a.id)\n",
    "response_a1 = client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}],\n",
    "    # \"previous_response_id\": response_a.id  # Use the real, fresh ID\n",
    "})\n",
    "\n",
    "response_a1.messages[0].get_text()\n",
    "\n",
    "client._set_previous_response_id(response_b.id)\n",
    "response_b1 = client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}],\n",
    "    # \"previous_response_id\": response_b.id  # Use the real, fresh ID\n",
    "})\n",
    "response_a1_id = client._get_previous_response_id()\n",
    "response_b1_id = client._get_previous_response_id()\n",
    "\n",
    "print(\"response_a1_id\", response_a1_id)\n",
    "print(\"response_b1_id\", response_b1_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Multimodal Support\n",
    "\n",
    "Send images in your messages using various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multimodal message with an image URL\n",
    "multimodal_message = OpenAIResponsesV2Client.create_multimodal_message(\n",
    "    text=\"What do you see in this image?\",\n",
    "    images=[\"https://images.unsplash.com/photo-1587300003388-59208cc962cb?w=400\"],\n",
    "    role=\"user\"\n",
    ")\n",
    "\n",
    "print(\"Multimodal message structure:\")\n",
    "print(multimodal_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send multimodal request\n",
    "mm_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = mm_client.create({\n",
    "    \"model\": \"gpt-4.1\",  # Use a vision-capable model\n",
    "    \"messages\": [multimodal_message]\n",
    "})\n",
    "\n",
    "print(f\"Image description: {response.messages[0].get_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Built-in Tools\n",
    "\n",
    "The Responses API provides built-in tools that don't require function definitions.\n",
    "\n",
    "## 4.1 Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable web search\n",
    "search_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = search_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What are the latest news about AI?\"}],\n",
    "    \"built_in_tools\": [\"web_search\"]\n",
    "})\n",
    "\n",
    "print(f\"Response: {response.messages[0].get_text()[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract citations from the response\n",
    "citations = OpenAIResponsesV2Client.get_citations(response)\n",
    "\n",
    "print(f\"\\nFound {len(citations)} citations:\")\n",
    "for citation in citations[:5]:  # Show first 5\n",
    "    print(f\"  - {citation.title}: {citation.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import base64\n",
    "# Enable image generation\n",
    "image_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# # Configure image output parameters\n",
    "# image_client.set_image_output_params(\n",
    "#     quality=\"high\",\n",
    "#     size=\"1024x1024\",\n",
    "#     output_format=\"png\"\n",
    "# )\n",
    "\n",
    "response = image_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Generate an image of a tree with fruits\"}],\n",
    "    \"built_in_tools\": [\"image_generation\"]\n",
    "})\n",
    "\n",
    "# Extract generated images\n",
    "images = OpenAIResponsesV2Client.get_generated_images(response)\n",
    "print(f\"Generated {len(images)} image(s)\")\n",
    "\n",
    "if images:\n",
    "    # Get the data URI\n",
    "    data_uri = images[0].data_uri\n",
    "    \n",
    "    # Extract base64 data (remove the \"data:image/png;base64,\" prefix)\n",
    "    if data_uri and data_uri.startswith(\"data:\"):\n",
    "        # Split on comma to get base64 data\n",
    "        base64_data = data_uri.split(\",\", 1)[1]\n",
    "        \n",
    "        # Display the image\n",
    "        display(Image(data=base64.b64decode(base64_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image generation costs\n",
    "print(f\"Image costs: ${image_client.get_image_costs():.4f}\")\n",
    "print(f\"Total costs: ${image_client.get_total_costs():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Lena Fitzgerald' age=34 occupation='Environmental Scientist'\n",
      "---------------------------------\n",
      "Name: Lena Fitzgerald\n",
      "Age: 34\n",
      "Occupation: Environmental Scientist\n"
     ]
    }
   ],
   "source": [
    "from autogen.llm_clients.openai_resposnes_v2_client import  OpenAIResponsesV2Client\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define a Pydantic model for structured output\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    occupation: str\n",
    "\n",
    "# Request structured output\n",
    "struct_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = struct_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Generate a fictional person's profile\"}],\n",
    "    \"response_format\": Person\n",
    "})\n",
    "\n",
    "# Get the parsed object\n",
    "parsed = OpenAIResponsesV2Client.get_parsed_object(response)\n",
    "\n",
    "if parsed:\n",
    "    print(parsed)\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Name: {parsed.name}\")\n",
    "    print(f\"Age: {parsed.age}\")\n",
    "    print(f\"Occupation: {parsed.occupation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Cost Tracking\n",
    "\n",
    "The V2 client tracks both token costs and image generation costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 1: 13 tokens, $0.000038\n",
      "Request 2: 28 tokens, $0.000080\n",
      "Request 3: 45 tokens, $0.000126\n"
     ]
    }
   ],
   "source": [
    "cost_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Make several requests\n",
    "for i in range(3):\n",
    "    response = cost_client.create({\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": f\"Count to {i+1}\"}]\n",
    "    })\n",
    "    \n",
    "    # Per-request cost\n",
    "    usage = OpenAIResponsesV2Client.get_usage(response)\n",
    "    print(f\"Request {i+1}: {usage['total_tokens']} tokens, ${usage['cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cumulative usage\n",
    "cumulative = cost_client.get_cumulative_usage()\n",
    "print(f\"\\nCumulative Usage:\")\n",
    "print(f\"  Total prompt tokens: {cumulative['prompt_tokens']}\")\n",
    "print(f\"  Total completion tokens: {cumulative['completion_tokens']}\")\n",
    "print(f\"  Total tokens: {cumulative['total_tokens']}\")\n",
    "print(f\"  Token cost: ${cumulative['token_cost']:.6f}\")\n",
    "print(f\"  Image cost: ${cumulative['image_cost']:.6f}\")\n",
    "print(f\"  Total cost: ${cumulative['total_cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset cost tracking\n",
    "cost_client.reset_all_costs()\n",
    "print(f\"After reset: ${cost_client.get_total_costs():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom pricing for fine-tuned models\n",
    "custom_client = OpenAIResponsesV2Client()\n",
    "custom_client.set_custom_price(\n",
    "    input_price_per_1k=0.003,\n",
    "    output_price_per_1k=0.006\n",
    ")\n",
    "\n",
    "response = custom_client.create({\n",
    "    \"model\": \"ft:gpt-4.1:my-org:custom-model\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    "})\n",
    "\n",
    "print(f\"Cost with custom pricing: ${custom_client.cost(response):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. V1 Backward Compatibility\n",
    "\n",
    "For code that expects ChatCompletion format, use `create_v1_compatible()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_client = OpenAIResponsesV2Client()\n",
    "\n",
    "# Get ChatCompletion-like response\n",
    "response = v1_client.create_v1_compatible({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    "})\n",
    "\n",
    "# Access like standard ChatCompletion\n",
    "print(f\"Type: {type(response).__name__}\")\n",
    "print(f\"Content: {response.choices[0].message.content}\")\n",
    "print(f\"Tokens: {response.usage.total_tokens}\")\n",
    "print(f\"Cost: ${response.cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Agent Integration\n",
    "\n",
    "The V2 client integrates with AG2 agents for conversational AI workflows.\n",
    "\n",
    "## 7.1 Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "# Configure LLM with Responses API\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"api_type\": \"responses\",  # Use Responses API\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\"config_list\": config_list}\n",
    "\n",
    "# Create a single assistant agent\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "# Start a conversation\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What is the capital of France?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Two-Agent Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two specialized agents\n",
    "researcher = autogen.AssistantAgent(\n",
    "    name=\"researcher\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a research assistant. Your job is to:\n",
    "    1. Analyze questions thoroughly\n",
    "    2. Provide detailed, factual information\n",
    "    3. Cite sources when possible\"\"\"\n",
    ")\n",
    "\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"critic\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a critical reviewer. Your job is to:\n",
    "    1. Review the researcher's findings\n",
    "    2. Point out any gaps or inaccuracies\n",
    "    3. Suggest improvements\n",
    "    Say 'TERMINATE' when the research is satisfactory.\"\"\"\n",
    ")\n",
    "\n",
    "# Two-agent collaboration\n",
    "researcher.initiate_chat(\n",
    "    critic,\n",
    "    message=\"Research the benefits and drawbacks of renewable energy sources.\",\n",
    "    max_turns=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple specialized agents for group chat\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"planner\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a project planner. Break down tasks into actionable steps.\n",
    "    Focus on creating clear, organized plans.\"\"\"\n",
    ")\n",
    "\n",
    "developer = autogen.AssistantAgent(\n",
    "    name=\"developer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a software developer. Implement solutions based on the plan.\n",
    "    Write clean, well-documented code.\"\"\"\n",
    ")\n",
    "\n",
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a code reviewer. Review implementations for:\n",
    "    1. Correctness\n",
    "    2. Best practices\n",
    "    3. Potential improvements\n",
    "    Say 'TERMINATE' when the solution is complete and reviewed.\"\"\"\n",
    ")\n",
    "\n",
    "user_proxy_gc = autogen.UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group chat\n",
    "group_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy_gc, planner, developer, reviewer],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "# Start the group chat\n",
    "user_proxy_gc.initiate_chat(\n",
    "    manager,\n",
    "    message=\"Create a Python function that calculates the Fibonacci sequence up to n terms.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Advanced: Custom Function Tools\n",
    "\n",
    "Combine built-in tools with custom function tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # Mock implementation\n",
    "    return f\"The weather in {city} is sunny, 72°F\"\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Define tool schemas\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Evaluate a math expression\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\"type\": \"string\", \"description\": \"Math expression\"}\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Tools defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom tools with the V2 client\n",
    "tools_client = OpenAIResponsesV2Client()\n",
    "\n",
    "response = tools_client.create({\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What's 25 * 4 + 10?\"}],\n",
    "    \"tools\": tools\n",
    "})\n",
    "\n",
    "# Check for tool calls\n",
    "for msg in response.messages:\n",
    "    for block in msg.content:\n",
    "        if isinstance(block, ToolCallContent):\n",
    "            print(f\"Tool call: {block.name}({block.arguments})\")\n",
    "        elif isinstance(block, TextContent):\n",
    "            print(f\"Text: {block.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "The `OpenAIResponsesV2Client` provides:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Stateful Conversations** | Automatic context tracking via `previous_response_id` |\n",
    "| **Rich Content Blocks** | TextContent, ReasoningContent, CitationContent, ImageContent, ToolCallContent |\n",
    "| **Built-in Tools** | Web search, image generation, apply_patch |\n",
    "| **Multimodal Support** | Send and receive images |\n",
    "| **Structured Output** | Pydantic models and JSON schemas |\n",
    "| **Cost Tracking** | Token and image generation cost tracking |\n",
    "| **V1 Compatibility** | `create_v1_compatible()` for ChatCompletion format |\n",
    "| **Agent Integration** | Works with AG2 single, two-agent, and group chat |\n",
    "\n",
    "For more information, see the [AG2 documentation](https://docs.ag2.ai)."
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "OpenAI Responses API V2 Client with rich UnifiedResponse objects, stateful conversations, and agent integration",
   "tags": [
    "openai",
    "responses-api",
    "v2-client",
    "multimodal",
    "agents"
   ]
  },
  "kernelspec": {
   "display_name": "ag2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
