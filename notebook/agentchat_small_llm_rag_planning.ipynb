{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small, Local Model Multi-Agent RAG with Document and Web Search\n",
    "\n",
    "Can you create effective agents with small, 8B parameter models? Yes, you can! \n",
    "\n",
    "The following notebook demonstrates specific tactics that can help get the best performance out of small models. It demonstrates this by combining the use of tool (document and web search) along with a high level planner, critic agents, and adapting the plan as it goes. Some of the pricipals emodied in this example are as follows:\n",
    "\n",
    "The workflow operates as follows:\n",
    "\n",
    "1. The `Planner` generates a plan based on user instructions.\n",
    "2. The plan is executed sequentially through multiple iterations.\n",
    "  - Each iteration begins with determining the next step in the plan. If no previous outputs exist, it directly executes the first step; otherwise, it evaluates the success of prior steps using the Generic Assistant before proceeding.\n",
    "  - Steps are carried out by the Research Assistant, leveraging web search and document searches to gather information.\n",
    "3. After each step execution, the Reflection Assistant assesses its success and determines subsequent actions based on this evaluation.\n",
    "4. The final output is a summarized response addressing the user's initial query using contextual information accumulated throughout the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Ensure the autogen python package is installed, along with a few LangChain libraries for retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install autogen langchain_community langchain-milvus langchain_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Model\n",
    "\n",
    "Here, we need to download an embeddings model for the vector database we will be setting up for document retrieval. In this example, we are using the IBM Granite embeddings model. It comes in a few different flavors, which can be found on [Hugging Face](https://huggingface.co/ibm-granite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"ibm-granite/granite-embedding-30m-english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the vector database\n",
    "\n",
    "In this example, we are using Milvus as our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus\n",
    "import tempfile\n",
    "\n",
    "db_file = tempfile.NamedTemporaryFile(prefix=\"milvus_\", suffix=\".db\", delete=False).name\n",
    "print(f\"The vector database will be saved to {db_file}\")\n",
    "\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings_model,\n",
    "    connection_args={\"uri\": db_file},\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    index_params={\"index_type\": \"AUTOINDEX\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idenfiy documents to ingest\n",
    "\n",
    "In the following code, you provide a list of folders and document extensions that you would like to ingest into your vector database for future retrieval.\n",
    "Be sure to personalize the identified directories and file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "# Specify the file extensions you would like to include (e.g., '.txt', '.md')\n",
    "allowed_extensions = {\".txt\", \".md\"}\n",
    "\n",
    "# Update this to include the directories you want to scan\n",
    "source_directories = [\n",
    "    Path(\"~/Downloads/\").expanduser(),\n",
    "    Path(\"~/Documents/\").expanduser()  # Add more directories as needed\n",
    "]\n",
    "\n",
    "# Collect files from all specified directories\n",
    "sources = []\n",
    "for source_directory in source_directories:\n",
    "    sources.extend(\n",
    "        file for file in source_directory.glob(\"**/*\")  # Includes all files and subdirectories recursively\n",
    "        if file.is_file() and file.suffix in allowed_extensions  # Include only files with specific extensions\n",
    "    )\n",
    "\n",
    "# Load and process the files\n",
    "documents = []\n",
    "for file in sources:\n",
    "    loader = TextLoader(file)  # Initialize TextLoader for each file\n",
    "    documents.extend(loader.load())  # Load and extend the documents list\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Now `texts` contains the processed and split documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest the documents\n",
    "\n",
    "Finally, after chunking the documents, load them into the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Prompts\n",
    "\n",
    "The following are the prompts for the agents that we will define later. Try running with these prompts intitially, and update them later if needed for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANNER_MESSAGE = (\n",
    "    \"\"\"You are a task planner. You will be given some information your job is to think step by step and enumerate the steps to complete a performance assessment of a given user, using the provided context to guide you.\n",
    "    You will not execute the steps yourself, but provide the steps to a helper who will execute them. Make sure each step consists of a single operation, not a series of operations. The helper has the following capabilities:\n",
    "    1. Search through a collection of documents provided by the user. These are the user's own documents and will likely not have latest news or other information you can find on the internet.\n",
    "    2. Synthesize, summarize and classify the information received.\n",
    "    3. Search the internet\n",
    "    Please output the step using a properly formatted python dictionary and list. It must be formatted exactly as below:\n",
    "    ```{\"plan\": [\"Step 1\", \"Step 2\"]}```\n",
    "\n",
    "    Respond only with the plan json with no additional fields and no additional text. Here are a few examples:\n",
    "    Example 1: \n",
    "    User query: Write a performance self-assessment for Joe, consisting of a high-level overview of achievements for the year, a listing of the business impacts for each of these achievements, a list of skills developed and ways he's collaborated with the team.\n",
    "    Your response:\n",
    "    ```{\"plan\": [\"Query documents for all contributions involving Joe this year\", \"Quantify the business impact for Joe's contributions\", \"Enumerate the skills Joe has developed this year\", \"List several examples of how Joe's work has been accomplished via team collaboration\", \"Formulate the performance review based on collected information\"]}```\n",
    "\n",
    "    Example 2:\n",
    "    User query: Find the latest news about the technologies I'm working on.\n",
    "    Your response:\n",
    "    ```{\"plan\": [\"Query documents for technologies used\", \"Search the internet for the latest news about each technology\"]}```\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "ASSISTANT_PROMPT = (\n",
    "    \"\"\"You are an AI assistant.\n",
    "    When you receive a message, figure out a solution and provide a final answer. The message will be accompanied with contextual information. Use the contextual information to help you provide a solution.\n",
    "    Make sure to provide a thorough answer that directly addresses the message you received.\n",
    "    The context may contain extraneous information that does not apply to your instruction. If so, just extract whatever is useful or relevant and use it to complete your instruction.\n",
    "    When the context does not include enough information to complete the task, use your available tools to retrieve the specific information you need.\n",
    "    When you are using knowledge and web search tools to complete the instruction, answer the instruction only using the results from the search; do no supplement with your own knowledge.\n",
    "    Be persistent in finding the information you need before giving up.\n",
    "    If the task is able to be accomplished without using tools, then do not make any tool calls.\n",
    "    When you have accomplished the instruction posed to you, you will reply with the text: ##SUMMARY## - followed with an answer.\n",
    "    Important: If you are unable to accomplish the task, whether it's because you could not retrieve sufficient data, or any other reason, reply only with ##TERMINATE##.\n",
    "\n",
    "    # Tool Use\n",
    "    You have access to the following tools. Only use these available tools and do not attempt to use anything not listed - this will cause an error.\n",
    "    Respond in the format: <function_call> {\"name\": function name, \"arguments\": dictionary of argument name and its value}. Do not use variables.\n",
    "    Only call one tool at a time.\n",
    "    When suggesting tool calls, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "REFLECTION_ASSISTANT_PROMPT = (\n",
    "    \"\"\"You are an assistant. Please tell me what is the next step that needs to be taken in a plan in order to accomplish a given task.\n",
    "    You will receive json in the following format, and will respond with a single line of instruction.\n",
    "\n",
    "    {\n",
    "        \"Goal\": The original query from the user. Every time you create a reply, it must be guided by the task of fulfilling this goal. Do not veer off course.,\n",
    "        \"Plan\": An array that enumerates every step of the plan,\n",
    "        \"Previous Step\": The step taken immediately prior to this message.\n",
    "        \"Previous Output\": The output generated by the last step taken.\n",
    "        \"Steps Taken\": A sequential array of steps that have already been executed prior to the last step,\n",
    "\n",
    "    }\n",
    "\n",
    "    Instructions:\n",
    "        1. If the very last step of the plan has already been executed, or the goal has already been achieved regardless of what step is next, then reply with the exact text: ##TERMINATE##\n",
    "        2. Look at the \"Previous Step\". If the previous step was not successful and it is integral to acheiving the goal, think of how it can be retried with better instructions. Inspect why the previous step was not successful, and modify the instruction to find another way to achieve the step's objective in a way that won't repeat the same error.\n",
    "        3. If the last previous was successful, determine what the next step will be. Always prefer to execute the next sequential step in the plan unless the previous step was unsuccessful and you need to re-run the previous step using a modified instruction.\n",
    "        4. When determining the next step, you may use the \"Previous Step\", \"Previous Output\", and \"Steps Taken\" to give you contextual information to decide what next step to take.\n",
    "\n",
    "    Be persistent and resourceful to make sure you reach the goal.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "CRITIC_PROMPT = (\n",
    "    \"\"\"The previous instruction was {last_step} \\nThe following is the output of that instruction.\n",
    "    if the output of the instruction completely satisfies the instruction, then reply with ##YES##.\n",
    "    For example, if the instruction is to list companies that use AI, then the output contains a list of companies that use AI.\n",
    "    If the output contains the phrase 'I'm sorry but...' then it is likely not fulfilling the instruction. \\n\n",
    "    If the output of the instruction does not properly satisfy the instruction, then reply with ##NO## and the reason why.\n",
    "    For example, if the instruction was to list companies that use AI but the output does not contain a list of companies, or states that a list of companies is not available, then the output did not properly satisfy the instruction.\n",
    "    If it does not satisfy the instruction, please think about what went wrong with the previous instruction and give me an explanation along with the text ##NO##. \\n\n",
    "    Previous step output: \\n {last_output}\"\"\"\n",
    ")\n",
    "\n",
    "SEARCH_TERM_ASSISTANT_PROMPT = (\n",
    "    \"\"\"You are an expert at creating precise, complete, and accurate web search queries. When given a description of what a user is looking for, you will generate a fully formed, optimized search query that can be used directly in a search engine to find the most relevant information.\n",
    "\n",
    "    Key Requirements:\n",
    "\n",
    "        Stick to the Description: Use only the information explicitly provided in the description. Do not add, assume, or invent details that are not stated.\n",
    "        Be Complete and Concise: The search query must contain all necessary keywords and phrases required to fulfill the description without being unnecessarily verbose.\n",
    "        Avoid Vague or Placeholder Terms: Do not include incomplete terms (e.g., no placeholder variables or references to unspecified concepts).\n",
    "        Use Proper Context and Refinement: Include context, if applicable (e.g., location, date, format). Utilize search modifiers like quotes, \"site:\", \"filetype:\", or Boolean operators (AND, OR, NOT) to refine the query when appropriate.\n",
    "        Avoid Hallucination: Do not make up or fabricate any details that are not explicitly stated in the description.\n",
    "\n",
    "    Example Input:\n",
    "    \"Find the latest research papers about AI-driven medical imaging published in 2023.\"\n",
    "\n",
    "    Example Output:\n",
    "    \"latest research papers on AI-driven medical imaging 2023\"\n",
    "\n",
    "    Another Example Input:\n",
    "    \"Find a website that lists the top restaurants in Paris with outdoor seating.\"\n",
    "\n",
    "    Example Output:\n",
    "    \"top restaurants in Paris with outdoor seating\"\n",
    "\n",
    "    Incorrect Example Input:\n",
    "    \"Find the population of Atlantis.\"\n",
    "\n",
    "    Incorrect Example Output:\n",
    "    \"population of Atlantis 2023\" (This is incorrect because the existence or details about Atlantis are not explicitly stated in the input and must not be assumed.)\n",
    "\n",
    "    Your Turn:\n",
    "    Generate a complete, accurate, and optimized search query based on the description provided below:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Variables\n",
    "\n",
    "Customize the following LLM configuration variables as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM to use for all agents. The value below corresponds to its name in Ollama.\n",
    "default_model = \"granite3.1-dense:8b\"\n",
    "\n",
    "# Open API URL - In this case, Ollama running locally. Any Open API compatible URL can be used.\n",
    "base_url = \"http://localhost:11434/v1\"\n",
    "\n",
    "# API key for LLM Inferencing. This default value  can be used when running Ollama locally.\n",
    "api_key = \"ollama\"\n",
    "\n",
    "# Model temperature. A lower temperature gives more predictible results.\n",
    "model_temp = 0\n",
    "\n",
    "# Maximum number of steps that are allowed to be executed in a plan (prevents a never-ending loop)\n",
    "max_plan_steps = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGen Agent Setup\n",
    "\n",
    "Initializes the LLM config and all of the agents of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import coding, ConversableAgent\n",
    "\n",
    "##################\n",
    "# AutoGen Config\n",
    "##################\n",
    "# LLM Config\n",
    "llm_config = {\n",
    "    \"config_list\": [{\n",
    "        \"model\": default_model,\n",
    "        \"base_url\": base_url,\n",
    "        \"api_key\": api_key,\n",
    "        \"cache_seed\": None,\n",
    "        \"price\": [0.0, 0.0],\n",
    "    }],\n",
    "    \"temperature\": model_temp,\n",
    "}\n",
    "\n",
    "# Generic Assistant - Used for general inquiry. Does not call tools.\n",
    "generic_assistant = ConversableAgent(\n",
    "    name=\"Generic_Assistant\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Search Term Assistant - Used for finding relevant search terms for a user's query\n",
    "web_search_assistant = ConversableAgent(\n",
    "    name=\"Web_Search_Term_Assistant\",\n",
    "    system_message=SEARCH_TERM_ASSISTANT_PROMPT,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Provides the initial high level plan\n",
    "planner = ConversableAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=PLANNER_MESSAGE,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# The assistant agent is responsible for executing each step of the plan, including calling tools\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Research_Assistant\",\n",
    "    system_message=ASSISTANT_PROMPT,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"tool_response\" not in msg and msg[\"content\"] == \"\"\n",
    ")\n",
    "\n",
    "# Reflection Assistant: Reflect on plan progress and give the next step\n",
    "reflection_assistant = ConversableAgent(\n",
    "    name=\"ReflectionAssistant\",\n",
    "    system_message=REFLECTION_ASSISTANT_PROMPT,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# User Proxy chats with assistant on behalf of user and executes tools\n",
    "code_exec = coding.LocalCommandLineCodeExecutor(\n",
    "    timeout=10,\n",
    "    work_dir=\"code_exec\",\n",
    ")\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"executor\": code_exec},\n",
    "    is_termination_msg=lambda msg: \"##SUMMARY##\" in msg[\"content\"] or \"## Summary\" in msg[\"content\"] or \"##TERMINATE##\" in msg[\"content\"] or (\"tool_calls\" not in msg and msg[\"content\"] == \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Search Tool\n",
    "\n",
    "The following function is registered as a tool for searching the previously created vector database for relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2506: UserWarning: Function 'personal_knowledge_search' is being overridden.\n",
      "  if name in self._function_map:\n",
      "/Users/kelly/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2587: UserWarning: Function 'personal_knowledge_search' is being overridden.\n",
      "  warnings.warn(f\"Function '{tool_sig['function']['name']}' is being overridden.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "@assistant.register_for_llm(name=\"personal_knowledge_search\", description=\"Searches personal documents according to a given query\")\n",
    "@user_proxy.register_for_execution(name=\"personal_knowledge_search\")\n",
    "def do_knowledge_search(search_instruction: Annotated[str, \"search instruction\"]) -> str:\n",
    "    \"\"\"Given an instruction on what knowledge you need to find, search the user's documents for information particular to them, their projects, and their domain.\n",
    "    This is simple document search, it cannot perform any other complex tasks.\n",
    "    This will not give you any results from the internet. Do not assume it can retrieve the latest news pertaining to any subject.\"\"\"\n",
    "    if not search_instruction:\n",
    "        return \"Please provide a search query.\"\n",
    "\n",
    "    messages = \"\"\n",
    "    #docs = vector_db.similarity_search(search_instruction)\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"fetch_k\": 10, \"max_tokens\": 500})\n",
    "\n",
    "    docs = retriever.invoke(search_instruction)\n",
    "    print(f\"{len(docs)} documents returned\")\n",
    "    for d in docs:\n",
    "        print(d)\n",
    "        print(d.page_content)\n",
    "        messages += d.page_content + \"\\n\"\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Search Tool\n",
    "\n",
    "The following is a tool that can be registerd for web search usage.\n",
    "For a quick and easy demonstration, the implementation below uses the `googlesearch-python` library to perform the search, which is not offically supported by Google.\n",
    "If you require the web search tool beyond a PoC, you should use the official library and APIs of your favorite search provider, or a multi-engine service such as Tavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2506: UserWarning: Function 'web_search' is being overridden.\n",
      "  if name in self._function_map:\n",
      "/Users/kelly/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2587: UserWarning: Function 'web_search' is being overridden.\n",
      "  warnings.warn(f\"Function '{tool_sig['function']['name']}' is being overridden.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from datetime import date\n",
    "from googlesearch import search\n",
    "from typing import Annotated\n",
    "\n",
    "@assistant.register_for_llm(name=\"web_search\", description=\"Searches the web according to a given query\")\n",
    "@user_proxy.register_for_execution(name=\"web_search\")\n",
    "def do_web_search(search_instruction: Annotated[str,\"Provide a detailed search instruction that incorporates specific features, goals, and contextual details related to the query. \\\n",
    "                                                Identify and include relevant aspects from any provided context, such as key topics, technologies, challenges, timelines, or use cases. \\\n",
    "                                                Construct the instruction to enable a targeted search by specifying important attributes, keywords, and relationships within the context.\"]) -> str:\n",
    "    \"\"\"This function is used for searching the web for information that can only be found on the internet, not in the users personal notes.\n",
    "    \"\"\"\n",
    "    if not search_instruction:\n",
    "        return \"Please provide a search query.\"\n",
    "\n",
    "    # First, we convert the incoming query into a search term.\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    chat_result = user_proxy.initiate_chat(\n",
    "        recipient=web_search_assistant,\n",
    "        message=\"Today's date is \" + today + \". \" + search_instruction,\n",
    "        max_turns=1,\n",
    "    )\n",
    "    summary = chat_result.chat_history[-1]['content']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        response = search(summary, advanced=True)\n",
    "        for result in response:\n",
    "            entry = {}\n",
    "            if type(result) is not str:\n",
    "                entry['title'] = result.title\n",
    "                entry['url'] = result.url\n",
    "                entry['description'] = result.description\n",
    "                results.append(entry)\n",
    "            else:\n",
    "                results.append(result)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(traceback.format_exc())\n",
    "        return(f\"Unable to execute search query due to the following exception: {e}\")\n",
    "\n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan parser\n",
    "\n",
    "When the initial plan is formed, the LLM should output the plan in JSON format. The following parses the response from the planner and returns the response as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import json\n",
    "\n",
    "def parse_response(message: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse the response from the planner and return the response as a dictionary.\n",
    "    \"\"\"\n",
    "    # Parse the response content\n",
    "    json_response = {}\n",
    "    # if message starts with ``` and ends with ``` then remove them\n",
    "    if message.startswith(\"```\"):\n",
    "        message = message[3:]\n",
    "    if message.endswith(\"```\"):\n",
    "        message = message[:-3]\n",
    "    if message.startswith(\"json\"):\n",
    "        message = message[4:]\n",
    "    if message.startswith(\"python\"):\n",
    "        message = message[6:]\n",
    "    message = message.strip()\n",
    "    try:\n",
    "        json_response: dict[str, Any] = json.loads(message)\n",
    "    except Exception as e:\n",
    "        # If the response is not a valid JSON, try pass it using string matching.\n",
    "        # This should seldom be triggered\n",
    "        print(f\"LLM response was not properly formed JSON. Will try to use it as is. LLM response: \\\"{message}\\\". Error: {e}\")\n",
    "        message = message.replace(\"\\\\n\", \"\\n\")\n",
    "        message = message.replace(\"\\n\", \" \")  # type: ignore\n",
    "        if (\"plan\" in message and \"next_step\" in message):\n",
    "            start = message.index(\"plan\") + len(\"plan\")\n",
    "            end = message.index(\"next_step\")\n",
    "            json_response[\"plan\"] = message[start:end].replace('\"', '').strip()\n",
    "\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Worflow\n",
    "\n",
    "Here is the meat of the agentic workflow.\n",
    "They key point here is that extract maximum performance a set of agents that are called in sequence, and the data passed between them is curated and trimmed, rather than passing around the full chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Begin Agentic Workflow\n",
    "#########################\n",
    "\n",
    "def run_agentic_workflow(user_message: str) -> str:\n",
    "    \"\"\"\n",
    "    Run the agentic workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a plan\n",
    "    raw_plan = user_proxy.initiate_chat(message=user_message, max_turns=1, recipient=planner).chat_history[-1][\"content\"]\n",
    "    plan_dict = parse_response(raw_plan)\n",
    "\n",
    "    # Start executing plan\n",
    "    answer_output = []  # This variable tracks the output of previous successful steps as context for executing the next step\n",
    "    steps_taken = []  # A list of steps already executed\n",
    "    last_output = \"\"  # Output of the single previous step gets put here\n",
    "\n",
    "    for _ in range(max_plan_steps):\n",
    "        if last_output == \"\":\n",
    "            # This is the first step of the plan since there's no previous output\n",
    "            instruction = plan_dict['plan'][0]\n",
    "        else:\n",
    "            # Previous steps in the plan have already been executed.\n",
    "            reflection_message = last_step\n",
    "            # Ask the critic if the previous step was properly accomplished\n",
    "            was_job_accomplished = user_proxy.initiate_chat(recipient=generic_assistant, max_turns=1,\n",
    "                                                            message=CRITIC_PROMPT.format(last_step=last_step, last_output=last_output)).chat_history[-1][\"content\"]\n",
    "            # If it was not accomplished, make sure an explanation is provided for the reflection assistant\n",
    "            if \"##NO##\" in was_job_accomplished:\n",
    "                reflection_message = f\"The previous step was {last_step} but it was not accomplished satisfactorily due to the following reason: \\n {was_job_accomplished}.\"\n",
    "\n",
    "            # Then, ask the reflection agent for the next step\n",
    "            message = {\n",
    "                \"Goal\": user_message,\n",
    "                \"Plan\": str(plan_dict),\n",
    "                \"Last Step\": reflection_message,\n",
    "                \"Last Step Output\": str(last_output),\n",
    "                \"Steps Taken\": str(steps_taken),\n",
    "            }\n",
    "            instruction = user_proxy.initiate_chat(recipient=reflection_assistant, max_turns=1, message=str(message)).chat_history[-1][\"content\"]\n",
    "\n",
    "            # Only append the previous step and its output to the record if it accomplished its task successfully.\n",
    "            # It was found that storing information about unsuccesful steps causes more confusion than help to the agents\n",
    "            if not \"##NO##\" in was_job_accomplished:\n",
    "                answer_output.append(last_output)\n",
    "                steps_taken.append(last_step)\n",
    "\n",
    "            if \"##TERMINATE##\" in instruction:\n",
    "                # A termination message means there are no more steps to take. Exit the loop.\n",
    "                break\n",
    "\n",
    "        # Now that we have determined the next step to take, execute it\n",
    "        prompt = instruction\n",
    "        if answer_output:\n",
    "            prompt += f\"\\n Contextual Information: \\n{answer_output}\"\n",
    "        output = user_proxy.initiate_chat(recipient=assistant, max_turns=3, message=prompt)\n",
    "\n",
    "        # Sort through the chat history and extract out replies from the assistant (We don't need the full results of the tool calls, just the assistant's summary)\n",
    "        previous_output = []\n",
    "        for chat_item in output.chat_history:\n",
    "            if chat_item[\"content\"] and chat_item[\"name\"] == \"Research_Assistant\":\n",
    "                previous_output.append(chat_item[\"content\"])\n",
    "        \n",
    "        # It was found in testing that the output of the assistant will often contain the right information, but it will not be formatted in a manner that directly answers the instruction\n",
    "        # Therefore, the critic will take the assistant's output and reformat it to more directly answer the instruction that was given to the assistant\n",
    "        critic_output = user_proxy.initiate_chat(recipient=generic_assistant, max_turns=1, message=f\"The instruction is: {instruction} Please directly answer the instruction given the following data: {previous_output}\")\n",
    "\n",
    "        # The previous instruction and its output will be recorded for the next iteration to inspect before determining the next step of the plan\n",
    "        last_output = critic_output.chat_history[-1][\"content\"]\n",
    "        last_step = instruction\n",
    "    \n",
    "    # Now that we've gathered all the information we need, we will summarize it to directly answer the original prompt\n",
    "    final_prompt = f\"Answer the user's query: {user_message}. Using the following contextual informaiton only: {answer_output}\"\n",
    "    final_output = user_proxy.initiate_chat(message=final_prompt, max_turns=1, recipient=generic_assistant).chat_history[-1][\"content\"]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a query\n",
    "\n",
    "Below is an example query. You can replace it with your own query based upon the types of information you have loaded into the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Planner):\n",
      "\n",
      "Identify open action items in my projects and see if you can search the internet for soluitons for each\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to User):\n",
      "\n",
      "```{\"plan\": [\"Query documents for all open action items in user's projects\", \"For each identified action item, search the internet for potential solutions or best practices\"]}```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "Query documents for all open action items in user's projects\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mResearch_Assistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_0yq6og74): personal_knowledge_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Search personal documents for all open action items in user's projects.\"}\n",
      "\u001b[32m**************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION personal_knowledge_search...\u001b[0m\n",
      "4 documents returned\n",
      "page_content='- Alex Johnson outlined the next steps and action items:\n",
      "    - **Research:** Conduct further research on existing Kubernetes operators for long-running batch jobs.\n",
      "    - **Design:** Based on the discussion, start designing the architecture of the new operator.\n",
      "    - **Implementation:** Once the design is finalized, start implementing the operator.\n",
      "    - **Testing:** After implementation, conduct thorough testing to ensure the operator meets all the requirements and design specifications.\n",
      "    - **Documentation:** Document the operator's architecture, design, and usage for future reference and onboarding of new team members.\n",
      "\n",
      "**Action Items:**\n",
      "\n",
      "- Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "- Pat Smith: Start designing the architecture of the new operator.\n",
      "- Taylor Brown: Assist in research and design efforts as needed.\n",
      "- Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.' metadata={'source': '/Users/kelly/Documents/obsidian/k8s operator meeting.md', 'pk': 455514110378901514}\n",
      "- Alex Johnson outlined the next steps and action items:\n",
      "    - **Research:** Conduct further research on existing Kubernetes operators for long-running batch jobs.\n",
      "    - **Design:** Based on the discussion, start designing the architecture of the new operator.\n",
      "    - **Implementation:** Once the design is finalized, start implementing the operator.\n",
      "    - **Testing:** After implementation, conduct thorough testing to ensure the operator meets all the requirements and design specifications.\n",
      "    - **Documentation:** Document the operator's architecture, design, and usage for future reference and onboarding of new team members.\n",
      "\n",
      "**Action Items:**\n",
      "\n",
      "- Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "- Pat Smith: Start designing the architecture of the new operator.\n",
      "- Taylor Brown: Assist in research and design efforts as needed.\n",
      "- Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\n",
      "page_content='- Pat Smith and Taylor Brown discussed the design considerations:\n",
      "    - **Operator Architecture:** The operator should be designed as a set of Kubernetes custom resources and controllers. It should also provide a web interface for easy management.\n",
      "    - **Job Scheduling:** The operator should support various job scheduling policies, such as periodic, cron-based, or on-demand.\n",
      "    - **Resource Management:** The operator should be able to manage resources efficiently. It should support resource requests and limits for each job and allocate resources dynamically based on job requirements.\n",
      "    - **Job Lifecycle Management:** The operator should handle the entire job lifecycle, including creation, deployment, scaling, and termination. It should also provide a way to rollback jobs in case of failures.\n",
      "\n",
      "**5. Next Steps and Action Items**' metadata={'source': '/Users/kelly/Documents/obsidian/k8s operator meeting.md', 'pk': 455514110378901513}\n",
      "- Pat Smith and Taylor Brown discussed the design considerations:\n",
      "    - **Operator Architecture:** The operator should be designed as a set of Kubernetes custom resources and controllers. It should also provide a web interface for easy management.\n",
      "    - **Job Scheduling:** The operator should support various job scheduling policies, such as periodic, cron-based, or on-demand.\n",
      "    - **Resource Management:** The operator should be able to manage resources efficiently. It should support resource requests and limits for each job and allocate resources dynamically based on job requirements.\n",
      "    - **Job Lifecycle Management:** The operator should handle the entire job lifecycle, including creation, deployment, scaling, and termination. It should also provide a way to rollback jobs in case of failures.\n",
      "\n",
      "**5. Next Steps and Action Items**\n",
      "page_content='- Project Update: Discussed the progress made so far on building the Python application that uses generative AI to summarize meetings.\n",
      "- Tech Stack Update:\n",
      "    - Python: Still using Python for development.\n",
      "    - Generative AI: Researching and testing different models, currently considering transformers and LSTM.\n",
      "    - Meeting Transcription API: Integrated a transcription API into the application.\n",
      "    - Summarization Algorithm: Developed a basic summarization algorithm that uses attention mechanisms to identify and extract key points from transcriptions.\n",
      "- Challenges:\n",
      "    - Ensuring the generative AI model can accurately identify and summarize key points from meetings, especially in noisy or accents-heavy recordings.\n",
      "    - Handling different speech patterns and accents in meeting attendees.\n",
      "    - Maintaining the privacy and confidentiality of meeting attendees.\n",
      "- Next Steps:\n",
      "    - Test the summarization algorithm with more sample meetings to improve its accuracy.\n",
      "    - Implement a feedback mechanism that allows users to rate the summary quality and provide suggestions for improvement.\n",
      "    - Deploy the application to a staging environment for further testing and user feedback.\n",
      "- Action Items:\n",
      "    - Continue researching and testing different generative AI models.\n",
      "    - Implement a feedback mechanism in the application.\n",
      "    - Deploy the application to a staging environment.\n",
      "- Meeting Adjourned: The meeting was adjourned after discussing the project progress, tech stack update, challenges, next steps, and action items.' metadata={'source': '/Users/kelly/Documents/obsidian/sept 16th meeting.md', 'pk': 455514110378901517}\n",
      "- Project Update: Discussed the progress made so far on building the Python application that uses generative AI to summarize meetings.\n",
      "- Tech Stack Update:\n",
      "    - Python: Still using Python for development.\n",
      "    - Generative AI: Researching and testing different models, currently considering transformers and LSTM.\n",
      "    - Meeting Transcription API: Integrated a transcription API into the application.\n",
      "    - Summarization Algorithm: Developed a basic summarization algorithm that uses attention mechanisms to identify and extract key points from transcriptions.\n",
      "- Challenges:\n",
      "    - Ensuring the generative AI model can accurately identify and summarize key points from meetings, especially in noisy or accents-heavy recordings.\n",
      "    - Handling different speech patterns and accents in meeting attendees.\n",
      "    - Maintaining the privacy and confidentiality of meeting attendees.\n",
      "- Next Steps:\n",
      "    - Test the summarization algorithm with more sample meetings to improve its accuracy.\n",
      "    - Implement a feedback mechanism that allows users to rate the summary quality and provide suggestions for improvement.\n",
      "    - Deploy the application to a staging environment for further testing and user feedback.\n",
      "- Action Items:\n",
      "    - Continue researching and testing different generative AI models.\n",
      "    - Implement a feedback mechanism in the application.\n",
      "    - Deploy the application to a staging environment.\n",
      "- Meeting Adjourned: The meeting was adjourned after discussing the project progress, tech stack update, challenges, next steps, and action items.\n",
      "page_content='- Project Overview: Building a Python application that uses generative AI to summarize meetings.\n",
      "- Objective: To create an automated system that can analyze and condense the key points from meetings, making it easier for attendees to review and take action on the discussion.\n",
      "- Tech Stack:\n",
      "    - Python: For the development of the application.\n",
      "    - Generative AI: To be determined (e.g., transformers, LSTM, etc.)\n",
      "    - Meeting Transcription API: To convert audio or video recordings into text format.\n",
      "    - Summarization Algorithm: To identify and extract the most important points from the transcriptions.\n",
      "- Steps:\n",
      "    1. Choose a generative AI model that is suitable for summarization tasks.\n",
      "    2. Integrate a meeting transcription API into the application to convert audio or video recordings into text format.\n",
      "    3. Develop a summarization algorithm that can identify and extract the most important points from the transcriptions.\n",
      "    4. Test the application with sample meetings to ensure it works as expected.\n",
      "    5. Deploy the application and make it accessible to users.\n",
      "- Challenges:\n",
      "    - Ensuring the generative AI model can accurately identify and summarize key points from meetings.\n",
      "    - Handling different accents, speech patterns, and background noise in audio or video recordings.\n",
      "    - Maintaining the privacy and confidentiality of meeting attendees.\n",
      "- Next Steps:\n",
      "    - Research and select a suitable generative AI model for summarization tasks.\n",
      "    - Integrate a meeting transcription API into the application.\n",
      "    - Develop a summarization algorithm that can accurately identify and extract key points from transcriptions.\n",
      "    - Test the application with sample meetings to ensure it works as expected.\n",
      "    - Deploy the application and make it accessible to users.\n",
      "- Action Items:\n",
      "    - Research and select a suitable generative AI model for summarization tasks.\n",
      "    - Integrate a meeting transcription API into the application.\n",
      "    - Develop a summarization algorithm that can accurately identify and extract key points from transcriptions.\n",
      "    - Test the application with sample meetings to ensure it works as expected.\n",
      "    - Deploy the application and make it accessible to users.\n",
      "- Meeting Adjourned: The meeting was adjourned after discussing the project details, tech stack, steps, challenges, next steps, and action items.' metadata={'source': '/Users/kelly/Documents/obsidian/sept 13 meeting.md', 'pk': 455514110378901505}\n",
      "- Project Overview: Building a Python application that uses generative AI to summarize meetings.\n",
      "- Objective: To create an automated system that can analyze and condense the key points from meetings, making it easier for attendees to review and take action on the discussion.\n",
      "- Tech Stack:\n",
      "    - Python: For the development of the application.\n",
      "    - Generative AI: To be determined (e.g., transformers, LSTM, etc.)\n",
      "    - Meeting Transcription API: To convert audio or video recordings into text format.\n",
      "    - Summarization Algorithm: To identify and extract the most important points from the transcriptions.\n",
      "- Steps:\n",
      "    1. Choose a generative AI model that is suitable for summarization tasks.\n",
      "    2. Integrate a meeting transcription API into the application to convert audio or video recordings into text format.\n",
      "    3. Develop a summarization algorithm that can identify and extract the most important points from the transcriptions.\n",
      "    4. Test the application with sample meetings to ensure it works as expected.\n",
      "    5. Deploy the application and make it accessible to users.\n",
      "- Challenges:\n",
      "    - Ensuring the generative AI model can accurately identify and summarize key points from meetings.\n",
      "    - Handling different accents, speech patterns, and background noise in audio or video recordings.\n",
      "    - Maintaining the privacy and confidentiality of meeting attendees.\n",
      "- Next Steps:\n",
      "    - Research and select a suitable generative AI model for summarization tasks.\n",
      "    - Integrate a meeting transcription API into the application.\n",
      "    - Develop a summarization algorithm that can accurately identify and extract key points from transcriptions.\n",
      "    - Test the application with sample meetings to ensure it works as expected.\n",
      "    - Deploy the application and make it accessible to users.\n",
      "- Action Items:\n",
      "    - Research and select a suitable generative AI model for summarization tasks.\n",
      "    - Integrate a meeting transcription API into the application.\n",
      "    - Develop a summarization algorithm that can accurately identify and extract key points from transcriptions.\n",
      "    - Test the application with sample meetings to ensure it works as expected.\n",
      "    - Deploy the application and make it accessible to users.\n",
      "- Meeting Adjourned: The meeting was adjourned after discussing the project details, tech stack, steps, challenges, next steps, and action items.\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_0yq6og74) *****\u001b[0m\n",
      "- Alex Johnson outlined the next steps and action items:\n",
      "    - **Research:** Conduct further research on existing Kubernetes operators for long-running batch jobs.\n",
      "    - **Design:** Based on the discussion, start designing the architecture of the new operator.\n",
      "    - **Implementation:** Once the design is finalized, start implementing the operator.\n",
      "    - **Testing:** After implementation, conduct thorough testing to ensure the operator meets all the requirements and design specifications.\n",
      "    - **Documentation:** Document the operator's architecture, design, and usage for future reference and onboarding of new team members.\n",
      "\n",
      "**Action Items:**\n",
      "\n",
      "- Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "- Pat Smith: Start designing the architecture of the new operator.\n",
      "- Taylor Brown: Assist in research and design efforts as needed.\n",
      "- Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\n",
      "- Pat Smith and Taylor Brown discussed the design considerations:\n",
      "    - **Operator Architecture:** The operator should be designed as a set of Kubernetes custom resources and controllers. It should also provide a web interface for easy management.\n",
      "    - **Job Scheduling:** The operator should support various job scheduling policies, such as periodic, cron-based, or on-demand.\n",
      "    - **Resource Management:** The operator should be able to manage resources efficiently. It should support resource requests and limits for each job and allocate resources dynamically based on job requirements.\n",
      "    - **Job Lifecycle Management:** The operator should handle the entire job lifecycle, including creation, deployment, scaling, and termination. It should also provide a way to rollback jobs in case of failures.\n",
      "\n",
      "**5. Next Steps and Action Items**\n",
      "- Project Update: Discussed the progress made so far on building the Python application that uses generative AI to summarize meetings.\n",
      "- Tech Stack Update:\n",
      "    - Python: Still using Python for development.\n",
      "    - Generative AI: Researching and testing different models, currently considering transformers and LSTM.\n",
      "    - Meeting Transcription API: Integrated a transcription API into the application.\n",
      "    - Summarization Algorithm: Developed a basic summarization algorithm that uses attention mechanisms to identify and extract key points from transcriptions.\n",
      "- Challenges:\n",
      "    - Ensuring the generative AI model can accurately identify and summarize key points from meetings, especially in noisy or accents-heavy recordings.\n",
      "    - Handling different speech patterns and accents in meeting attendees.\n",
      "    - Maintaining the privacy and confidentiality of meeting attendees.\n",
      "- Next Steps:\n",
      "    - Test the summarization algorithm with more sample meetings to improve its accuracy.\n",
      "    - Implement a feedback mechanism that allows users to rate the summary quality and provide suggestions for improvement.\n",
      "    - Deploy the application to a staging environment for further testing and user feedback.\n",
      "- Action Items:\n",
      "    - Continue researching and testing different generative AI models.\n",
      "    - Implement a feedback mechanism in the application.\n",
      "    - Deploy the application to a staging environment.\n",
      "- Meeting Adjourned: The meeting was adjourned after discussing the project progress, tech stack update, challenges, next steps, and action items.\n",
      "- Project Overview: Building a Python application that uses generative AI to summarize meetings.\n",
      "- Objective: To create an automated system that can analyze and condense the key points from meetings, making it easier for attendees to review and take action on the discussion.\n",
      "- Tech Stack:\n",
      "    - Python: For the development of the application.\n",
      "    - Generative AI: To be determined (e.g., transformers, LSTM, etc.)\n",
      "    - Meeting Transcription API: To convert audio or video recordings into text format.\n",
      "    - Summarization Algorithm: To identify and extract the most important points from the transcriptions.\n",
      "- Steps:\n",
      "    1. Choose a generative AI model that is suitable for summarization tasks.\n",
      "    2. Integrate a meeting transcription API into the application to convert audio or video recordings into text format.\n",
      "    3. Develop a summarization algorithm that can identify and extract the most important points from the transcriptions.\n",
      "    4. Test the application with sample meetings to ensure it works as expected.\n",
      "    5. Deploy the application and make it accessible to users.\n",
      "- Challenges:\n",
      "    - Ensuring the generative AI model can accurately identify and summarize key points from meetings.\n",
      "    - Handling different accents, speech patterns, and background noise in audio or video recordings.\n",
      "    - Maintaining the privacy and confidentiality of meeting attendees.\n",
      "- Next Steps:\n",
      "    - Research and select a suitable generative AI model for summarization tasks.\n",
      "    - Integrate a meeting transcription API into the application.\n",
      "    - Develop a summarization algorithm that can accurately identify and extract key points from transcriptions.\n",
      "    - Test the application with sample meetings to ensure it works as expected.\n",
      "    - Deploy the application and make it accessible to users.\n",
      "- Action Items:\n",
      "    - Research and select a suitable generative AI model for summarization tasks.\n",
      "    - Integrate a meeting transcription API into the application.\n",
      "    - Develop a summarization algorithm that can accurately identify and extract key points from transcriptions.\n",
      "    - Test the application with sample meetings to ensure it works as expected.\n",
      "    - Deploy the application and make it accessible to users.\n",
      "- Meeting Adjourned: The meeting was adjourned after discussing the project details, tech stack, steps, challenges, next steps, and action items.\n",
      "\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mResearch_Assistant\u001b[0m (to User):\n",
      "\n",
      "##SUMMARY##\n",
      "\n",
      "The open action items in user's projects are as follows:\n",
      "\n",
      "1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "2. Pat Smith: Start designing the architecture of the new operator.\n",
      "3. Taylor Brown: Assist in research and design efforts as needed.\n",
      "4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\n",
      "5. Continue researching and testing different generative AI models for summarization tasks.\n",
      "6. Implement a feedback mechanism in the application.\n",
      "7. Deploy the application to a staging environment for further testing and user feedback.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Generic_Assistant):\n",
      "\n",
      "The instruction is: Query documents for all open action items in user's projects Please directly answer the instruction given the following data: [\"##SUMMARY##\\n\\nThe open action items in user's projects are as follows:\\n\\n1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\\n2. Pat Smith: Start designing the architecture of the new operator.\\n3. Taylor Brown: Assist in research and design efforts as needed.\\n4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\\n5. Continue researching and testing different generative AI models for summarization tasks.\\n6. Implement a feedback mechanism in the application.\\n7. Deploy the application to a staging environment for further testing and user feedback.\"]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGeneric_Assistant\u001b[0m (to User):\n",
      "\n",
      "1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "2. Pat Smith: Start designing the architecture of the new operator.\n",
      "3. Taylor Brown: Assist in research and design efforts as needed.\n",
      "4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\n",
      "5. Continue researching and testing different generative AI models for summarization tasks.\n",
      "6. Implement a feedback mechanism in the application.\n",
      "7. Deploy the application to a staging environment for further testing and user feedback.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Generic_Assistant):\n",
      "\n",
      "The previous instruction was Query documents for all open action items in user's projects \n",
      "The following is the output of that instruction.\n",
      "    if the output of the instruction completely satisfies the instruction, then reply with ##YES##.\n",
      "    For example, if the instruction is to list companies that use AI, then the output contains a list of companies that use AI.\n",
      "    If the output contains the phrase 'I'm sorry but...' then it is likely not fulfilling the instruction. \n",
      "\n",
      "    If the output of the instruction does not properly satisfy the instruction, then reply with ##NO## and the reason why.\n",
      "    For example, if the instruction was to list companies that use AI but the output does not contain a list of companies, or states that a list of companies is not available, then the output did not properly satisfy the instruction.\n",
      "    If it does not satisfy the instruction, please think about what went wrong with the previous instruction and give me an explanation along with the text ##NO##. \n",
      "\n",
      "    Previous step output: \n",
      " 1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "2. Pat Smith: Start designing the architecture of the new operator.\n",
      "3. Taylor Brown: Assist in research and design efforts as needed.\n",
      "4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\n",
      "5. Continue researching and testing different generative AI models for summarization tasks.\n",
      "6. Implement a feedback mechanism in the application.\n",
      "7. Deploy the application to a staging environment for further testing and user feedback.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGeneric_Assistant\u001b[0m (to User):\n",
      "\n",
      "##YES##\n",
      "\n",
      "The output provided contains all open action items from the user's projects, as per the instruction. These include:\n",
      "\n",
      "1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\n",
      "2. Pat Smith: Start designing the architecture of the new operator.\n",
      "3. Taylor Brown: Assist in research and design efforts as needed.\n",
      "4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\n",
      "5. Continue researching and testing different generative AI models for summarization tasks.\n",
      "6. Implement a feedback mechanism in the application.\n",
      "7. Deploy the application to a staging environment for further testing and user feedback.\n",
      "\n",
      "Each item is clearly stated as an action to be taken, with no 'I'm sorry but...' phrase indicating unavailability or failure to fulfill the instruction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to ReflectionAssistant):\n",
      "\n",
      "{'Goal': 'Identify open action items in my projects and see if you can search the internet for soluitons for each', 'Plan': '{\\'plan\\': [\"Query documents for all open action items in user\\'s projects\", \\'For each identified action item, search the internet for potential solutions or best practices\\']}', 'Last Step': \"Query documents for all open action items in user's projects\", 'Last Step Output': '1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\\n2. Pat Smith: Start designing the architecture of the new operator.\\n3. Taylor Brown: Assist in research and design efforts as needed.\\n4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\\n5. Continue researching and testing different generative AI models for summarization tasks.\\n6. Implement a feedback mechanism in the application.\\n7. Deploy the application to a staging environment for further testing and user feedback.', 'Steps Taken': '[]'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mReflectionAssistant\u001b[0m (to User):\n",
      "\n",
      "1. For each identified action item, search the internet for potential solutions or best practices.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "1. For each identified action item, search the internet for potential solutions or best practices.\n",
      " Contextual Information: \n",
      "['1. Jamie Lee: Research existing Kubernetes operators for long-running batch jobs.\\n2. Pat Smith: Start designing the architecture of the new operator.\\n3. Taylor Brown: Assist in research and design efforts as needed.\\n4. Alex Johnson: Coordinate the next steps, assign tasks, and ensure timely completion of action items.\\n5. Continue researching and testing different generative AI models for summarization tasks.\\n6. Implement a feedback mechanism in the application.\\n7. Deploy the application to a staging environment for further testing and user feedback.']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mResearch_Assistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_b6dubw0x): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Kubernetes operators for long-running batch jobs\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_evbqgel5): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Best practices for designing Kubernetes operators\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_7yur9r0p): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Generative AI models for summarization tasks\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Kubernetes operators for long-running batch jobs\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"Kubernetes operators for managing long-running batch jobs 2025-01-23\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"Kubernetes operators for managing long-running batch jobs 2025-01-23\"\n",
      "SearchResult(url=https://cloud.google.com/kubernetes-engine/docs/best-practices/batch-platform-on-gke, title=Best practices for running batch workloads on GKE - Google Cloud, description= This page introduces the best practices for building and optimizing batch processing platforms with Google Kubernetes Engine (GKE). )\n",
      "SearchResult(url=https://github.com/lukaszraczylo/jobs-manager-operator, title=Kubernetes jobs management operator. Schedule long ... - GitHub, description= This operator is responsible for managing the lifecycle of complicated workflows which consist of multiple jobs and making their management easy. )\n",
      "SearchResult(url=https://medium.com/google-cloud/kubernetes-running-background-tasks-with-batch-jobs-56482fbc853, title=Kubernetes: Running Background Tasks With Batch-Jobs - Medium, description= Aug 7, 2018  ·  In this article we are going to look at how to run a batch-job in a few different ways: one-time, sequential, and parallel. )\n",
      "SearchResult(url=https://kubernetes.io/docs/concepts/workloads/controllers/job/, title=Jobs | Kubernetes, description= A Job creates one or more Pods and will continue to retry execution of the Pods until a specified number of them successfully terminate. )\n",
      "SearchResult(url=https://kedify.io/resources/blog/kedas-dynamic-scheduling-fixes-kubernetes-long-running-workloads/, title=KEDA's dynamic scheduling fixes Kubernetes long-running workloads, description= Jan 17, 2024  ·  ScaledJobs in Kubernetes offer a robust solution for handling long-running workloads, effectively addressing the inefficiencies of wasted processing time. )\n",
      "SearchResult(url=https://cloud.google.com/kubernetes-engine/docs/tutorials/batch-ml-workload, title=Deploy a batch machine learning workload | Kubernetes Engine, description= This tutorial demonstrates how to use Google Kubernetes Engine (GKE) to manage fault-tolerant batch workloads while keeping your costs low. )\n",
      "SearchResult(url=https://www.reddit.com/r/kubernetes/comments/174g4a1/handling_long_running_tasks/, title=Handling long running tasks - kubernetes - Reddit, description= Oct 10, 2023  ·  The HPA is checking the length of a AWS SQS. What would you recommend to handle the long running jobs? I thought about moving them to AWS Batch. )\n",
      "SearchResult(url=https://betterprogramming.pub/kubernetes-was-never-designed-for-batch-jobs-f59be376a338, title=Kubernetes Was Never Designed for Batch Jobs - Better Programming, description= Sep 1, 2022  ·  In this post, we'll make the case that Kubernetes is philosophically biased towards microservices over batch jobs. )\n",
      "SearchResult(url=https://www.cncf.io/blog/2021/01/25/armada-how-to-run-millions-of-batch-jobs-over-thousands-of-compute-nodes-using-kubernetes/, title=Armada – how to run millions of batch jobs over thousands of ..., description= Jan 25, 2021  ·  Crucially we were able to demonstrate that with no special tuning Kubernetes was more than capable of handling thousands of containers starting ... )\n",
      "SearchResult(url=https://dev.to/aws-builders/data-on-kubernetes-part-3-managing-workflows-with-job-schedulers-and-batch-oriented-workflow-orchestrators-1a8f, title=Data on Kubernetes: Part 3 - Managing Workflows with Job ..., description= Jul 22, 2024  ·  Sensors: they are special operators used to monitor (or poll) long-running tasks, files, database rows, S3 keys, other DAGs/tasks, etc. )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Best practices for designing Kubernetes operators\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"Best practices for designing Kubernetes operators in 2025\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"Best practices for designing Kubernetes operators in 2025\"\n",
      "SearchResult(url=https://www.groundcover.com/blog/kubernetes-operator, title=What is a Kubernetes Operator? Best Practices & Examples, description= Apr 7, 2024  ·  When creating custom resource definitions for an operator, stick to the basics and avoid unnecessary parameters. This not only makes operators ... )\n",
      "SearchResult(url=https://www.redhat.com/en/blog/kubernetes-operators-best-practices, title=Kubernetes Operators Best Practices - Red Hat, description= Jun 11, 2019  ·  This document presents a set of best practices to keep in mind when designing and developing operators using the Operator SDK. )\n",
      "SearchResult(url=https://www.strongdm.com/blog/kubernetes-security-best-practices, title=15 Kubernetes Security Best Practices in 2025 - StrongDM, description= 1. Implement Role-Based Access Control (RBAC) · 2. Use Network Policies to Control Traffic · 3. Secure Secrets Management · 4. Enforce Immutable Container Images. )\n",
      "SearchResult(url=https://kubernetes.io/docs/concepts/extend-kubernetes/operator/, title=Operator pattern - Kubernetes, description= Jul 16, 2024  ·  Read an article from Google Cloud about best practices for building operators. Items on this page refer to third party products or projects ... )\n",
      "SearchResult(url=https://alain-airom.medium.com/kubernetes-operators-patterns-and-best-practices-b7fbaa4cbd1, title=Kubernetes Operators Patterns and Best Practices, description= Jul 8, 2022  ·  The Kubernetes Operator Patterns and Best Practices project provides a reference that includes a sample application that is deployed and managed by sample ... )\n",
      "SearchResult(url=https://www.reddit.com/r/kubernetes/comments/1gy0ti3/best_way_to_learn_how_to_write_operators/, title=Best way to learn how to write Operators? : r/kubernetes - Reddit, description= Nov 23, 2024  ·  I would like to learn how to write and maintain my own operators. I learn best by doing, meaning writing some basic operators and progressing. )\n",
      "SearchResult(url=https://www.redhat.com/en/blog/7-best-practices-for-writing-kubernetes-operators-an-sre-perspective, title=7 Best Practices for Writing Kubernetes Operators: An SRE ..., description= Aug 5, 2020  ·  7 Best Practices for Writing Kubernetes Operators: An SRE Perspective · 1: Use the Operator SDK · 2: Avoid Overstuffed Functions · 3: Idempotent ... )\n",
      "SearchResult(url=https://www.reddit.com/r/kubernetes/comments/z4coc6/resources_for_operatorscontrollers_best_practices/, title=Resources for operators/controllers best practices? : r/kubernetes, description= Nov 26, 2022  ·  You'll need to design your reconcilers properly to avoid blocking for too long, for example using appropriate timeouts or simply avoiding ... )\n",
      "SearchResult(url=https://www.pulumi.com/blog/kubernetes-best-practices-i-wish-i-had-known-before/, title=Kubernetes Best Practices I Wish I Had Known Before | Pulumi Blog, description= 3 days ago  ·  1. Don't Skimp on Resource Requests and Limits · 2. Namespace Like Your Life Depends on It · 3. Avoid Running Multiple Containers in One Pod ... )\n",
      "SearchResult(url=https://infisical.com/blog/kubernetes-secrets-management-2025, title=Kubernetes Secrets Management in 2025 - A Complete Guide (with ..., description= Dec 9, 2024  ·  A comprehensive guide to the best practices for managing secrets in K8s. As a DevOps or platform engineer, you know the pain of managing ... )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Generative AI models for summarization tasks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"generative AI models for text summarization 2025\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"generative AI models for text summarization 2025\"\n",
      "SearchResult(url=https://scholar.google.com/scholar?q=generative+AI+models+for+text+summarization+2025&hl=en&as_sdt=0&as_vis=1&oi=scholart, title=, description=)\n",
      "SearchResult(url=https://www.fullstackacademy.com/blog/best-generative-ai-tools, title=12 Top-Rated Generative AI Tools in 2025: Your Expert Guide, description= Claude AI  is a powerful language model developed by Anthropic, designed for a wide range of natural language tasks, including content generation, summarization, and translation. Key Features: Generates human-quality text in various styles and formats. Supports language translation and summarization. )\n",
      "SearchResult(url=https://narrato.io/blog/best-ai-text-summarizer-tools-for-2025/, title=5 Best AI Text Summarizer Tools for 2025 - Narrato, description= Dec 4, 2024  ·  Top AI text summarizer tools for 2025 · 1. Narrato AI text summarizer · 2. Summarizing Tool · 3. Paraphraser.io · 4. Editpad AI summarizer · 5. AI ... )\n",
      "SearchResult(url=https://clickup.com/blog/ai-document-summarizers/, title=10 Best AI Article & Document Summarizers in 2025 - ClickUp, description= Jan 3, 2025  ·  Jasper is well-known for being an AI content generator built for enterprise teams. But one of its features also includes the AI text summarizer. )\n",
      "SearchResult(url=https://www.edenai.co/post/best-summarization-apis, title=Best Text summarization APIs in 2025 - Eden AI, description= Hugging Face's text summarization models leverage state-of-the-art transformer architectures to generate accurate and concise summaries from input text. )\n",
      "SearchResult(url=https://medium.com/@jam.canda/best-ai-text-summarization-tools-in-2025-7a95e07a2afb, title=Best AI Text Summarization Tools in 2025 | by Jam Canda - Medium, description= Jan 15, 2025  ·  In 2025, we can expect to see even more advanced AI summarization features: Processing complex documents in real-time; Verifying accuracy ... )\n",
      "SearchResult(url=https://hatchworks.com/blog/gen-ai/generative-ai/, title=2025 Guide to Generative AI: Techniques, Tools & Trends, description= Dec 2, 2024  ·  In this guide, we'll introduce you to the burgeoning world of generative AI applications. We'll explore its capabilities, dive into its many use cases, and ... )\n",
      "SearchResult(url=https://www.splunk.com/en_us/blog/learn/generative-ai.html, title=Generative AI in 2025: What Is GenAI? - Splunk, description= Dec 13, 2024  ·  Short for Generative AI, Gen AI is a type of artificial intelligence that creates new content, such as text, images, music, audio, and videos. )\n",
      "SearchResult(url=https://www.analyticsvidhya.com/blog/2024/04/text-summarization-tools/, title=Top 8 Text Summarization Tools in 2025 - Analytics Vidhya, description= Dec 3, 2024  ·  Discover top 8 AI-powered text summarization tools in 2025. Efficient, customizable, and time-saving solutions for professionals. )\n",
      "SearchResult(url=https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/top-generative-ai-tools, title=Top Generative AI Tools for 2025 - Simplilearn.com, description= 3 days ago  ·  Here is an overview of key features, pros and cons, working and pricing of the top 20 generative AI tools. )\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_b6dubw0x) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_evbqgel5) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_7yur9r0p) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mResearch_Assistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_malkonbj): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Kubernetes operators for long-running batch jobs best practices\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_xxad7tan): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Designing architecture of a new operator for Kubernetes\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_nuzmoble): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Assistance in research and design efforts for Kubernetes operators\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_d8qgjq4c): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Generative AI models for summarization tasks\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_orrfdz67): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Implementing feedback mechanisms in applications\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_zb3mk0p7): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Deploying applications to staging environments\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Kubernetes operators for long-running batch jobs best practices\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"Kubernetes operators for long-running batch jobs best practices 2025-01-23\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"Kubernetes operators for long-running batch jobs best practices 2025-01-23\"\n",
      "SearchResult(url=https://cloud.google.com/kubernetes-engine/docs/best-practices/batch-platform-on-gke, title=Best practices for running batch workloads on GKE - Google Cloud, description= This page introduces the best practices for building and optimizing batch processing platforms with Google Kubernetes Engine (GKE). )\n",
      "SearchResult(url=https://medium.com/google-cloud/kubernetes-running-background-tasks-with-batch-jobs-56482fbc853, title=Kubernetes: Running Background Tasks With Batch-Jobs - Medium, description= Aug 7, 2018  ·  In this article we are going to look at how to run a batch-job in a few different ways: one-time, sequential, and parallel. )\n",
      "SearchResult(url=https://sdk.operatorframework.io/docs/best-practices/best-practices/, title=Operator Best Practices, description= Jun 21, 2023  ·  Like all containers on Kubernetes, Operators need not run as root unless absolutely necessary. · Operators should not self-register their CRDs. )\n",
      "SearchResult(url=https://kubernetes.io/docs/concepts/workloads/controllers/job/, title=Jobs | Kubernetes, description= A simple case is to create one Job object in order to reliably run one Pod to completion. The Job object will start a new Pod if the first Pod fails or is ... )\n",
      "SearchResult(url=https://www.groundcover.com/blog/kubernetes-operator, title=What is a Kubernetes Operator? Best Practices & Examples, description= Apr 7, 2024  ·  Discover everything you need to know about how Kubernetes operators work, when to use them, and examples and best practices for working with ... )\n",
      "SearchResult(url=https://cloud.google.com/kubernetes-engine/docs/tutorials/batch-ml-workload, title=Deploy a batch machine learning workload | Kubernetes Engine, description= This tutorial demonstrates how to use Google Kubernetes Engine (GKE) to manage fault-tolerant batch workloads while keeping your costs low. )\n",
      "SearchResult(url=https://betterprogramming.pub/kubernetes-was-never-designed-for-batch-jobs-f59be376a338, title=Kubernetes Was Never Designed for Batch Jobs - Better Programming, description= Sep 1, 2022  ·  In this post, we'll make the case that Kubernetes is philosophically biased towards microservices over batch jobs. )\n",
      "SearchResult(url=https://spring.io/blog/2021/01/27/spring-batch-on-kubernetes-efficient-batch-processing-at-scale, title=Spring Batch on Kubernetes: Efficient batch processing at scale, description= Jan 28, 2021  ·  In this blog post, I introduce some of the challenges a batch developer or architect may face when designing and running batch applications at scale. )\n",
      "SearchResult(url=https://www.cncf.io/blog/2021/01/25/armada-how-to-run-millions-of-batch-jobs-over-thousands-of-compute-nodes-using-kubernetes/, title=Armada – how to run millions of batch jobs over thousands of ..., description= Jan 25, 2021  ·  Write some software to add queuing and fair share, without needing to alter Kubernetes itself. Leave Kubernetes to do the hard work of node- ... )\n",
      "SearchResult(url=https://www.reddit.com/r/kubernetes/comments/x38kn1/kubernetes_was_never_designed_for_batch_jobs/, title=Kubernetes was never designed for batch jobs - Reddit, description= Sep 1, 2022  ·  We do lots of batch processing on Kubernetes, both with Argo as well as just using k8s Jobs or CronJobs. It works really well, is easy, reliable ... )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Designing architecture of a new operator for Kubernetes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"Kubernetes operator design guidelines 2025\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"Kubernetes operator design guidelines 2025\"\n",
      "SearchResult(url=https://kubernetes.io/docs/concepts/extend-kubernetes/operator/, title=Operator pattern - Kubernetes, description= Jul 16, 2024  ·  Kubernetes' operator pattern concept lets you extend the cluster's behaviour without modifying the code of Kubernetes itself by linking ... )\n",
      "SearchResult(url=https://developers.redhat.com/articles/2024/01/29/developers-guide-kubernetes-operators, title=The developer's guide to Kubernetes Operators, description= Jan 29, 2024  ·  This guide will list components you need to know to get started developing operators using the Operator Framework. )\n",
      "SearchResult(url=https://www.groundcover.com/blog/kubernetes-operator, title=What is a Kubernetes Operator? Best Practices & Examples, description= Apr 7, 2024  ·  A Kubernetes operator is a way to manage applications or other resources in Kubernetes using custom resource definitions and the Kubernetes API. )\n",
      "SearchResult(url=https://dev.to/jimjunior/building-a-kubernetes-operator-a-practical-guide-2lna, title=Building a Kubernetes Operator | A Practical Guide - DEV Community, description= Dec 28, 2024  ·  2025: Your year to build apps that sell. Dive into hands-on resources and actionable strategies designed to help you build and sell apps on ... )\n",
      "SearchResult(url=https://infisical.com/blog/kubernetes-secrets-management-2025, title=Kubernetes Secrets Management in 2025 - A Complete Guide (with ..., description= Dec 9, 2024  ·  A comprehensive guide to the best practices for managing secrets in K8s. As a DevOps or platform engineer, you know the pain of managing ... )\n",
      "SearchResult(url=https://medium.com/developingnodes/mastering-kubernetes-operators-your-definitive-guide-to-starting-strong-70ff43579eb9, title=Writing your first Kubernetes Operator: A Definitive Guide to Starting ..., description= Nov 11, 2023  ·  In this comprehensive guide, we'll start our journey through the fundamentals of controllers, operators, CRD, and best practices surrounding Operators. )\n",
      "SearchResult(url=https://developers.redhat.com/articles/2024/08/21/design-kubernetes-operator-rest-resources, title=Designing K8s operators for managing REST resources, description= Aug 22, 2024  ·  This article provides a conceptual, technology-agnostic overview on how to design an operator that will leverage the REST API of your application. )\n",
      "SearchResult(url=https://www.cncf.io/blog/2022/06/15/kubernetes-operators-what-are-they-some-examples/, title=Kubernetes Operators: what are they? Some examples | CNCF, description= Jun 15, 2022  ·  Operators are patterns that extend the behavior of the cluster without changing the Kubernetes code. Its APIs act as custom resource controllers. )\n",
      "SearchResult(url=https://overcast.blog/kubernetes-operators-in-depth-guide-with-examples-044a591b690e, title=Kubernetes Operators: In-Depth Guide with Examples - overcast blog, description= Feb 13, 2024  ·  This guide will cover the basics and delve into advanced topics, including creating your Operator, optimization techniques, and best practices. )\n",
      "SearchResult(url=https://iximiuz.com/en/posts/kubernetes-operator-pattern/, title=Exploring Kubernetes Operator Pattern - iximiuz, description= Nov 18, 2023  ·  In this article, I'll try to take a closer look at the Operators pattern, see which Kubernetes parts are involved in operators implementation, and what makes ... )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Assistance in research and design efforts for Kubernetes operators\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"Kubernetes operator development resources 2025\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"Kubernetes operator development resources 2025\"\n",
      "SearchResult(url=https://developers.redhat.com/articles/2024/01/29/developers-guide-kubernetes-operators, title=The developer's guide to Kubernetes Operators, description= Jan 29, 2024  ·  This guide will list components you need to know to get started developing operators using the Operator Framework. )\n",
      "SearchResult(url=https://www.reddit.com/r/kubernetes/comments/11ef1jd/question_resources_to_learn_k8s_operator/, title=Question: Resources to learn K8s operator programming - Reddit, description= Feb 28, 2023  ·  What are some best-in-class resources (books, tutorials, courses, etc) to start learning K8s custom operator programming? Thanks. )\n",
      "SearchResult(url=https://devopsdays.org/events/2025-zurich/program/rabieh-fashwall/, title=Building Infrastructure Tools with Kubernetes Operators and Go, description= In this hands-on workshop, participants will learn how to build powerful infrastructure management tools using Kubernetes (K8s) Operators written in Go. )\n",
      "SearchResult(url=https://medium.com/developingnodes/mastering-kubernetes-operators-your-definitive-guide-to-starting-strong-70ff43579eb9, title=Writing your first Kubernetes Operator: A Definitive Guide to Starting ..., description= Nov 11, 2023  ·  In this comprehensive guide, we'll start our journey through the fundamentals of controllers, operators, CRD, and best practices surrounding Operators. )\n",
      "SearchResult(url=https://developers.redhat.com/articles/2024/08/21/design-kubernetes-operator-rest-resources, title=Designing K8s operators for managing REST resources, description= Aug 22, 2024  ·  This article provides a conceptual, technology-agnostic overview on how to design an operator that will leverage the REST API of your application. )\n",
      "SearchResult(url=https://kubernetes.io/docs/concepts/extend-kubernetes/operator/, title=Operator pattern - Kubernetes, description= Jul 16, 2024  ·  Operators are software extensions to Kubernetes that make use of custom resources to manage applications and their components. )\n",
      "SearchResult(url=https://www.groundcover.com/blog/kubernetes-operator, title=What is a Kubernetes Operator? Best Practices & Examples, description= Apr 7, 2024  ·  A Kubernetes operator is a way to manage applications or other resources in Kubernetes using custom resource definitions and the Kubernetes API. )\n",
      "SearchResult(url=https://www.cncf.io/blog/2022/06/15/kubernetes-operators-what-are-they-some-examples/, title=Kubernetes Operators: what are they? Some examples | CNCF, description= Jun 15, 2022  ·  Operators are patterns that extend the behavior of the cluster without changing the Kubernetes code. Its APIs act as custom resource controllers. )\n",
      "SearchResult(url=https://dev.to/ashokan/build-a-kubernetes-operator-with-python-27e1, title=Building a Kubernetes operator with Python - DEV Community, description= Jan 13, 2025  ·  We'll cover key concepts, choose a framework, walk through a simple example, and provide kubectl commands for deployment and verification. Why ... )\n",
      "SearchResult(url=https://sumeetmore.medium.com/lets-develop-kubernetes-operator-in-c-898d03731c2c, title=Let's develop Kubernetes Operator in C# | by Sumeet More | Medium, description= Sep 29, 2024  ·  We can develop Kubernetes operator to do N tasks but in this blogpost, I am taking a simple example. In our example, we will create custom resource definition( ... )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Generative AI models for summarization tasks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"generative AI models for text summarization 2025\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"generative AI models for text summarization 2025\"\n",
      "SearchResult(url=https://scholar.google.com/scholar?q=generative+AI+models+for+text+summarization+2025&hl=en&as_sdt=0&as_vis=1&oi=scholart, title=, description=)\n",
      "SearchResult(url=https://www.fullstackacademy.com/blog/best-generative-ai-tools, title=12 Top-Rated Generative AI Tools in 2025: Your Expert Guide, description= Claude AI  is a powerful language model developed by Anthropic, designed for a wide range of natural language tasks, including content generation, summarization, and translation. Key Features: Generates human-quality text in various styles and formats. Supports language translation and summarization. )\n",
      "SearchResult(url=https://narrato.io/blog/best-ai-text-summarizer-tools-for-2025/, title=5 Best AI Text Summarizer Tools for 2025 - Narrato, description= Dec 4, 2024  ·  Top AI text summarizer tools for 2025 · 1. Narrato AI text summarizer · 2. Summarizing Tool · 3. Paraphraser.io · 4. Editpad AI summarizer · 5. AI ... )\n",
      "SearchResult(url=https://clickup.com/blog/ai-document-summarizers/, title=10 Best AI Article & Document Summarizers in 2025 - ClickUp, description= Jan 3, 2025  ·  Jasper is well-known for being an AI content generator built for enterprise teams. But one of its features also includes the AI text summarizer. )\n",
      "SearchResult(url=https://www.edenai.co/post/best-summarization-apis, title=Best Text summarization APIs in 2025 - Eden AI, description= Hugging Face's text summarization models leverage state-of-the-art transformer architectures to generate accurate and concise summaries from input text. )\n",
      "SearchResult(url=https://medium.com/@jam.canda/best-ai-text-summarization-tools-in-2025-7a95e07a2afb, title=Best AI Text Summarization Tools in 2025 | by Jam Canda - Medium, description= Jan 15, 2025  ·  In 2025, we can expect to see even more advanced AI summarization features: Processing complex documents in real-time; Verifying accuracy ... )\n",
      "SearchResult(url=https://hatchworks.com/blog/gen-ai/generative-ai/, title=2025 Guide to Generative AI: Techniques, Tools & Trends, description= Dec 2, 2024  ·  In this guide, we'll introduce you to the burgeoning world of generative AI applications. We'll explore its capabilities, dive into its many use cases, and ... )\n",
      "SearchResult(url=https://www.splunk.com/en_us/blog/learn/generative-ai.html, title=Generative AI in 2025: What Is GenAI? - Splunk, description= Dec 13, 2024  ·  Short for Generative AI, Gen AI is a type of artificial intelligence that creates new content, such as text, images, music, audio, and videos. )\n",
      "SearchResult(url=https://docs.oracle.com/en-us/iaas/Content/generative-ai/summarize-models.htm, title=About the Summarization Models in Generative AI, description= Nov 15, 2024  ·  We recommend that you use the chat models instead which offer the same summarization capabilities, including control over summary length and style. )\n",
      "SearchResult(url=https://www.analyticsvidhya.com/blog/2024/04/text-summarization-tools/, title=Top 8 Text Summarization Tools in 2025 - Analytics Vidhya, description= Dec 3, 2024  ·  Discover top 8 AI-powered text summarization tools in 2025. Efficient, customizable, and time-saving solutions for professionals. )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Implementing feedback mechanisms in applications\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"implementing feedback mechanisms in applications 2025\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"implementing feedback mechanisms in applications 2025\"\n",
      "SearchResult(url=https://www.bmc.net/blog/general-blog-posts/feedback-mechanisms-in-hrm, title=Guide to Feedback Mechanisms in HR Management 2025, description= Dec 25, 2024  ·  The goal of feedback mechanisms is to improve individual and organizational performance, foster open communication, and address issues ... )\n",
      "SearchResult(url=https://matterapp.com/blog/continuous-feedback-loop, title=3 Continuous Feedback Loop Strategies in 2025 - Matter, description= Dec 13, 2024  ·  Implementing ongoing feedback loops can be as simple as sending out an email survey every week, then brainstorming about the results. Some ... )\n",
      "SearchResult(url=https://www.achievers.com/blog/employee-feedback-tools/, title=10 best employee feedback tools to boost engagement in 2025, description= Jan 13, 2025  ·  Discover the top employee feedback tools to enhance workplace engagement and performance. Ideal for HR professionals and managers. )\n",
      "SearchResult(url=https://www.mentimeter.com/blog/business/feedback-tools, title=Top 10 employee feedback tools to try in 2025 - Mentimeter, description= Nov 29, 2024  ·  We researched the top employee feedback tools to help you make data-driven decisions that improve morale, boost productivity, and drive success. )\n",
      "SearchResult(url=https://www.reddit.com/r/LangChain/comments/16n4fug/how_to_leverage_user_feedback_into_my_llm/, title=How to leverage user feedback into my LLM application? - Reddit, description= Sep 19, 2023  ·  I'm looking for inspiration on how to leverage the user feedback. Do you guys have implemented such user feedback thing and how do you use it? )\n",
      "SearchResult(url=https://uxcam.com/blog/product-feedback-loop/, title=Product Feedback Loop - How to Implement One for Mobile Apps, description= Nov 23, 2023  ·  A product feedback loop is the ongoing process of collecting, analyzing, and integrating feedback from users, customers, team members, and stakeholders into ... )\n",
      "SearchResult(url=https://cerovac.com/a11y/2024/11/why-should-all-organizations-establish-feedback-mechanisms-for-accessibility/, title=Why should all organizations establish feedback mechanisms for ..., description= Nov 2, 2024  ·  Web Accessibility Directive (WAD) made feedback mechanism a must for public sector websites and mobile applications in the European Union. )\n",
      "SearchResult(url=https://customerthink.com/turning-feedback-into-action-implementing-changes-based-on-customer-input/, title=Implementing Changes Based on Customer Input - CustomerThink, description= Aug 8, 2024  ·  Response systems are feedback mechanisms placed on websites or applications to improve the response rate. They improve the way businesses ... )\n",
      "SearchResult(url=https://userpilot.com/blog/customer-feedback-systems/, title=Creating Customer Feedback Systems: A Step-By-Step Guide, description= A customer feedback system is a framework of tools and processes for collecting, organizing, and analyzing customer feedback to obtain actionable insights. )\n",
      "SearchResult(url=https://www.culturemonkey.io/employee-engagement/feedback-mechanisms/, title=Feedback mechanisms: Types, and ways to improve the process in ..., description= Aug 16, 2024  ·  Here are 15+ feedback mechanisms that organizations should consider implementing: Real-time feedback tools: Utilize digital platforms and apps ... )\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_search...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Web_Search_Term_Assistant):\n",
      "\n",
      "Today's date is 2025-01-23. Deploying applications to staging environments\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWeb_Search_Term_Assistant\u001b[0m (to User):\n",
      "\n",
      "\"deploying applications to staging environments 2025-01-23\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching.... \"deploying applications to staging environments 2025-01-23\"\n",
      "SearchResult(url=https://medium.com/@sorindumitrescu/how-we-create-new-staging-environments-in-minutes-multiple-times-a-day-ab51832f3a1e, title=How we create new staging environments in minutes - Medium, description= Dec 20, 2023  ·  In this article, we will explore how to use environment blueprints in Bunnyshell to effortlessly create and deploy environments in minutes, with just a few ... )\n",
      "SearchResult(url=https://medium.com/swlh/how-to-set-up-your-staging-environment-for-web-applications-480e0138e620, title=How to Set Up Your Staging Environment for Web Applications, description= Dec 1, 2020  ·  We merge the staging branch into our production branch and thereby deploy all of our new features that have been tested on master/staging to our production ... )\n",
      "SearchResult(url=https://www.reddit.com/r/devops/comments/cfkz47/how_to_set_up_database_for_staging_environment/, title=How to set up Database for staging environment? : r/devops - Reddit, description= Jul 20, 2019  ·  We want to create a staging environment wherein the staging database is consistent with the data in the production database. )\n",
      "SearchResult(url=https://devops.com/software-deployment-security-risks-and-best-practices/, title=Software Deployment Security: Risks and Best Practices, description= Nov 2, 2023  ·  It starts with installing the software system, which involves copying and configuring the software application on the servers where it will run. )\n",
      "SearchResult(url=https://community.ibm.com/community/user/events/calendar?CalendarEventKey=491b7920-5882-4655-8541-018f3e62403d&CommunityKey=0533aa67-cf3c-4222-bf9b-018c6f7a901c, title=Upcoming Events - IBM TechXchange Community, description= We've been working on a JAX-PRC pre-deploy tool to help migrate your applications from WebSphere to Liberty and we're excited to share the latest updates. )\n",
      "SearchResult(url=https://flatirons.com/blog/what-is-a-staging-environment-a-complete-guide-in-2024/, title=What Is a Staging Environment? A Complete Guide in 2025 - Flatirons, description= Sep 6, 2024  ·  A staging environment is a pre-production setting that mimics the production environment where your application will ultimately reside. )\n",
      "SearchResult(url=https://serverfault.com/questions/1025188/staging-environment-keeping-up-to-date-with-new-prod-data, title=Staging environment keeping up to date with new prod data, description= Jul 14, 2020  ·  The only way to do so is to create a staging environment based on a snapshot of prod database, and test the new feature on it. )\n",
      "SearchResult(url=https://serverfault.com/questions/391541/how-to-set-up-development-staging-production-and-qa-environments, title=How to set up Development, Staging, Production, and QA ..., description= May 22, 2012  ·  What are the standards or best practices for setting up a new environment with Development, Testing, Staging, and Production? )\n",
      "SearchResult(url=https://simonwillison.net/2024/Aug/6/staging/, title=Weeknotes: a staging environment, a Datasette alpha and a bunch ..., description= Aug 6, 2024  ·  Any code pushed to the main branch of both the core repositories for Datasette Cloud will be deployed to both production and staging... ... These ... )\n",
      "SearchResult(url=https://docs.pega.com/bundle/platform/page/platform/devops/deploying-app-changes-to-staging-or-prod.html, title=Deploying application changes to your staging or production ..., description= As part of the Standard Release process, after you set up and package a release on your shared development environment, you can deploy your application ... )\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_malkonbj) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_xxad7tan) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_nuzmoble) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_d8qgjq4c) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_orrfdz67) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Research_Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_zb3mk0p7) *****\u001b[0m\n",
      "Error: Object of type generator is not JSON serializable\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mResearch_Assistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_n050mzu2): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Kubernetes operators for long-running batch jobs best practices\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_o9e13wfk): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Design principles for Kubernetes operators\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_ydv26snh): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Kubernetes operator development best practices\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_zk3717q9): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Project management techniques for software development\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_8j4zpfeh): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Generative AI models for text summarization comparison\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_2hp786k2): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Best practices for implementing user feedback mechanisms in applications\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_o33jj0dt): web_search *****\u001b[0m\n",
      "Arguments: \n",
      "{\"search_instruction\":\"Guidelines for deploying applications to staging environments\"}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Generic_Assistant):\n",
      "\n",
      "The instruction is: 1. For each identified action item, search the internet for potential solutions or best practices. Please directly answer the instruction given the following data: []\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGeneric_Assistant\u001b[0m (to User):\n",
      "\n",
      "I'm sorry for the confusion, but it seems there's no specific action item provided in your message. To assist you effectively, I would need a clear task or problem to research. For example, if you asked about \"best practices for time management,\" I could provide a list of strategies and resources based on my knowledge base.\n",
      "\n",
      "However, without an actual action item, I can't perform the requested search. Please provide more details so I can help you better.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Generic_Assistant):\n",
      "\n",
      "The previous instruction was 1. For each identified action item, search the internet for potential solutions or best practices. \n",
      "The following is the output of that instruction.\n",
      "    if the output of the instruction completely satisfies the instruction, then reply with ##YES##.\n",
      "    For example, if the instruction is to list companies that use AI, then the output contains a list of companies that use AI.\n",
      "    If the output contains the phrase 'I'm sorry but...' then it is likely not fulfilling the instruction. \n",
      "\n",
      "    If the output of the instruction does not properly satisfy the instruction, then reply with ##NO## and the reason why.\n",
      "    For example, if the instruction was to list companies that use AI but the output does not contain a list of companies, or states that a list of companies is not available, then the output did not properly satisfy the instruction.\n",
      "    If it does not satisfy the instruction, please think about what went wrong with the previous instruction and give me an explanation along with the text ##NO##. \n",
      "\n",
      "    Previous step output: \n",
      " I'm sorry for the confusion, but it seems there's no specific action item provided in your message. To assist you effectively, I would need a clear task or problem to research. For example, if you asked about \"best practices for time management,\" I could provide a list of strategies and resources based on my knowledge base.\n",
      "\n",
      "However, without an actual action item, I can't perform the requested search. Please provide more details so I can help you better.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGeneric_Assistant\u001b[0m (to User):\n",
      "\n",
      "##NO##. The output does not satisfy the instruction because it does not provide potential solutions or best practices for any identified action item. The response indicates that there is no specific task or problem provided to research, which is why it cannot perform the requested search. To properly fulfill the instruction, a clear task or problem should be given so the AI can find and present relevant information.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to ReflectionAssistant):\n",
      "\n",
      "{'Goal': 'Identify open action items in my projects and see if you can search the internet for soluitons for each', 'Plan': '{\\'plan\\': [\"Query documents for all open action items in user\\'s projects\", \\'For each identified action item, search the internet for potential solutions or best practices\\']}', 'Last Step': 'The previous step was 1. For each identified action item, search the internet for potential solutions or best practices. but it was not accomplished satisfactorily due to the following reason: \\n ##NO##. The output does not satisfy the instruction because it does not provide potential solutions or best practices for any identified action item. The response indicates that there is no specific task or problem provided to research, which is why it cannot perform the requested search. To properly fulfill the instruction, a clear task or problem should be given so the AI can find and present relevant information..', 'Last Step Output': 'I\\'m sorry for the confusion, but it seems there\\'s no specific action item provided in your message. To assist you effectively, I would need a clear task or problem to research. For example, if you asked about \"best practices for time management,\" I could provide a list of strategies and resources based on my knowledge base.\\n\\nHowever, without an actual action item, I can\\'t perform the requested search. Please provide more details so I can help you better.', 'Steps Taken': '[\"Query documents for all open action items in user\\'s projects\"]'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_agentic_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentify open action items in my projects and see if you can search the internet for soluitons for each\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[0;32mIn[24], line 41\u001b[0m, in \u001b[0;36mrun_agentic_workflow\u001b[0;34m(user_message)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Then, ask the reflection agent for the next step\u001b[39;00m\n\u001b[1;32m     34\u001b[0m message \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoal\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_message,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlan\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(plan_dict),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps Taken\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(steps_taken),\n\u001b[1;32m     40\u001b[0m }\n\u001b[0;32m---> 41\u001b[0m instruction \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreflection_assistant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchat_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Only append the previous step and its output to the record if it accomplished its task successfully.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# It was found that storing information about unsuccesful steps causes more confusion than help to the agents\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##NO##\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m was_job_accomplished:\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1108\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:749\u001b[0m, in \u001b[0;36msend\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:915\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2070\u001b[0m, in \u001b[0;36mgenerate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m reply\n\u001b[1;32m   2068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_auto_reply\n\u001b[0;32m-> 2070\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ma_generate_reply\u001b[39m(\n\u001b[1;32m   2071\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2072\u001b[0m     messages: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2073\u001b[0m     sender: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2074\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2075\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"(async) Reply based on the conversation history and the sender.\u001b[39;00m\n\u001b[1;32m   2077\u001b[0m \n\u001b[1;32m   2078\u001b[0m \u001b[38;5;124;03m    Either messages or sender must be provided.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;124;03m        str or dict or None: reply. None if no reply is generated.\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, sender \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1437\u001b[0m, in \u001b[0;36mgenerate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1456\u001b[0m, in \u001b[0;36m_generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m   1453\u001b[0m     context\u001b[38;5;241m=\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1454\u001b[0m     messages\u001b[38;5;241m=\u001b[39mall_messages,\n\u001b[1;32m   1455\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m-> 1456\u001b[0m     agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1457\u001b[0m )\n\u001b[1;32m   1458\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/oai/client.py:777\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    770\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate(prompt, context, allow_format_str_template)\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m context:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;66;03m# Instantiate the messages\u001b[39;00m\n\u001b[1;32m    773\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    774\u001b[0m         (\n\u001b[1;32m    775\u001b[0m             {\n\u001b[1;32m    776\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mm,\n\u001b[0;32m--> 777\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate(m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m], context, allow_format_str_template),\n\u001b[1;32m    778\u001b[0m             }\n\u001b[1;32m    779\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    780\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m m\n\u001b[1;32m    781\u001b[0m         )\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages  \u001b[38;5;66;03m# type: ignore [union-attr]\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     ]\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m params\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/autogen/oai/client.py:342\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    340\u001b[0m     if not content:\n\u001b[1;32m    341\u001b[0m         continue\n\u001b[0;32m--> 342\u001b[0m # end block\n\u001b[1;32m    343\u001b[0m \n\u001b[1;32m    344\u001b[0m # Handle tool calls\n\u001b[1;32m    345\u001b[0m if tool_calls_chunks:\n\u001b[1;32m    346\u001b[0m     for tool_calls_chunk in tool_calls_chunks:\n\u001b[1;32m    347\u001b[0m         # the current tool call to be reconstructed\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(variants[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m given_params)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 275\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhuman_join([quote(arg)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39marg\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmissing])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    Learn more in the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    821\u001b[0m     messages: Iterable[ChatCompletionMessageParam],\n\u001b[1;32m    822\u001b[0m     model: Union[\u001b[38;5;28mstr\u001b[39m, ChatModel],\n\u001b[1;32m    823\u001b[0m     audio: Optional[ChatCompletionAudioParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    824\u001b[0m     frequency_penalty: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    825\u001b[0m     function_call: completion_create_params\u001b[38;5;241m.\u001b[39mFunctionCall \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    826\u001b[0m     functions: Iterable[completion_create_params\u001b[38;5;241m.\u001b[39mFunction] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    828\u001b[0m     logprobs: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m--> 829\u001b[0m     max_completion_tokens: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    830\u001b[0m     max_tokens: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    831\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    832\u001b[0m     modalities: Optional[List[ChatCompletionModality]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    833\u001b[0m     n: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    834\u001b[0m     parallel_tool_calls: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    835\u001b[0m     prediction: Optional[ChatCompletionPredictionContentParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    836\u001b[0m     presence_penalty: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    837\u001b[0m     reasoning_effort: ChatCompletionReasoningEffort \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    838\u001b[0m     response_format: completion_create_params\u001b[38;5;241m.\u001b[39mResponseFormat \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    839\u001b[0m     seed: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    840\u001b[0m     service_tier: Optional[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    841\u001b[0m     stop: Union[Optional[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    842\u001b[0m     store: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    843\u001b[0m     stream: Optional[Literal[\u001b[38;5;28;01mFalse\u001b[39;00m]] \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    844\u001b[0m     stream_options: Optional[ChatCompletionStreamOptionsParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    845\u001b[0m     temperature: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    846\u001b[0m     tool_choice: ChatCompletionToolChoiceOptionParam \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    847\u001b[0m     tools: Iterable[ChatCompletionToolParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    848\u001b[0m     top_logprobs: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    849\u001b[0m     top_p: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    850\u001b[0m     user: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# The extra values given here take precedence over values defined on the client or passed to this method.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     extra_headers: Headers \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    854\u001b[0m     extra_query: Query \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    855\u001b[0m     extra_body: Body \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    860\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    901\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    902\u001b[0m     )\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m-> 1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    955\u001b[0m if remaining_retries is not None:\n\u001b[1;32m    956\u001b[0m     retries_taken = options.get_max_retries(self.max_retries) - remaining_retries\n\u001b[0;32m--> 957\u001b[0m else:\n\u001b[1;32m    958\u001b[0m     retries_taken = 0\n\u001b[1;32m    960\u001b[0m return self._request(\n\u001b[1;32m    961\u001b[0m     cast_to=cast_to,\n\u001b[1;32m    962\u001b[0m     options=options,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    965\u001b[0m     retries_taken=retries_taken,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    991\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[0;32m--> 993\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    996\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    997\u001b[0m         request,\n\u001b[1;32m    998\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1000\u001b[0m     )\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/git/autogen-experiment/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "answer = run_agentic_workflow(user_message=\"Identify open action items in my projects and see if you can search the internet for soluitons for each\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
